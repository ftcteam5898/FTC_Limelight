{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b694aee4",
   "metadata": {
    "id": "05N8FeXHcQp3",
    "papermill": {
     "duration": 0.006511,
     "end_time": "2025-04-01T18:59:13.031862",
     "exception": false,
     "start_time": "2025-04-01T18:59:13.025351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1. Install The Object Detection Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4bd1db5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T18:59:13.044481Z",
     "iopub.status.busy": "2025-04-01T18:59:13.044192Z",
     "iopub.status.idle": "2025-04-01T18:59:29.015531Z",
     "shell.execute_reply": "2025-04-01T18:59:29.014655Z"
    },
    "id": "ypWGYdPlLRUN",
    "papermill": {
     "duration": 15.979858,
     "end_time": "2025-04-01T18:59:29.017674",
     "exception": false,
     "start_time": "2025-04-01T18:59:13.037816",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\r\n",
      "remote: Enumerating objects: 4326, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (4326/4326), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (3345/3345), done.\u001b[K\r\n",
      "remote: Total 4326 (delta 1208), reused 2043 (delta 909), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (4326/4326), 53.64 MiB | 9.31 MiB/s, done.\r\n",
      "Resolving deltas: 100% (1208/1208), done.\r\n",
      "remote: Enumerating objects: 3089, done.\u001b[K\r\n",
      "remote: Counting objects: 100% (3089/3089), done.\u001b[K\r\n",
      "remote: Compressing objects: 100% (1379/1379), done.\u001b[K\r\n",
      "remote: Total 1844 (delta 1238), reused 702 (delta 446), pack-reused 0 (from 0)\u001b[K\r\n",
      "Receiving objects: 100% (1844/1844), 10.07 MiB | 20.42 MiB/s, done.\r\n",
      "Resolving deltas: 100% (1238/1238), completed with 753 local objects.\r\n",
      "From https://github.com/tensorflow/models\r\n",
      " * branch            ad1f7b56943998864db8f5db0706950e93bb7d81 -> FETCH_HEAD\r\n",
      "Note: switching to 'ad1f7b56943998864db8f5db0706950e93bb7d81'.\r\n",
      "\r\n",
      "You are in 'detached HEAD' state. You can look around, make experimental\r\n",
      "changes and commit them, and you can discard any commits you make in this\r\n",
      "state without impacting any branches by switching back to a branch.\r\n",
      "\r\n",
      "If you want to create a new branch to retain commits you create, you may\r\n",
      "do so (now or later) by using -c with the switch command. Example:\r\n",
      "\r\n",
      "  git switch -c <new-branch-name>\r\n",
      "\r\n",
      "Or undo this operation with:\r\n",
      "\r\n",
      "  git switch -\r\n",
      "\r\n",
      "Turn off this advice by setting config variable advice.detachedHead to false\r\n",
      "\r\n",
      "HEAD is now at ad1f7b5 adjust folder path\r\n",
      "Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/dist-packages (3.20.3)\r\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "tmpModelPath ='/kaggle/working/models'\n",
    "if os.path.exists(tmpModelPath) and os.path.isdir(tmpModelPath):\n",
    "  shutil.rmtree(tmpModelPath)\n",
    "\n",
    "MLENVIRONMENT=\"KAGGLE\"\n",
    "!git clone --depth 1 https://github.com/tensorflow/models\n",
    "!cd models && git fetch --depth 1 origin ad1f7b56943998864db8f5db0706950e93bb7d81 && git checkout ad1f7b56943998864db8f5db0706950e93bb7d81\n",
    "!pip install protobuf==3.20.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c2f805b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T18:59:29.040506Z",
     "iopub.status.busy": "2025-04-01T18:59:29.040253Z",
     "iopub.status.idle": "2025-04-01T18:59:29.238789Z",
     "shell.execute_reply": "2025-04-01T18:59:29.237894Z"
    },
    "id": "6QPmVBSlLTzM",
    "papermill": {
     "duration": 0.212019,
     "end_time": "2025-04-01T18:59:29.240485",
     "exception": false,
     "start_time": "2025-04-01T18:59:29.028466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]\n",
      " env setup\n",
      "/kaggle/working/\n",
      "/kaggle/working/models/research\r\n"
     ]
    }
   ],
   "source": [
    "# Environment Setup\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "\n",
    "print(sys.version)\n",
    "if(MLENVIRONMENT == \"KAGGLE\"):\n",
    "    print(\" env setup\")\n",
    "    os.environ[\"HOMEFOLDER\"] = \"/kaggle/working/\"\n",
    "    HOMEFOLDER = '{HOMEFOLDER}'.format(**os.environ)\n",
    "    FINALOUTPUTFOLDER_DIRNAME = '/kaggle/output/final_output'\n",
    "    FINALOUTPUTFOLDER = '/kaggle/output'\n",
    "    print(HOMEFOLDER)\n",
    "\n",
    "# Copy setup files into models/research folder\n",
    "!cd {HOMEFOLDER}models/research && pwd && protoc object_detection/protos/*.proto --python_out=.\n",
    "\n",
    "# Modify setup.py\n",
    "with open(HOMEFOLDER+'models/research/object_detection/packages/tf2/setup.py') as f:\n",
    "    s = f.read()\n",
    "\n",
    "with open(HOMEFOLDER+'models/research/setup.py', 'w') as f:\n",
    "    if(MLENVIRONMENT == \"KAGGLE\"):\n",
    "        s = re.sub('tf-models-official>=2.5.1','tf-models-official==2.15.0', s)\n",
    "        f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "534e3605",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T18:59:29.262289Z",
     "iopub.status.busy": "2025-04-01T18:59:29.262048Z",
     "iopub.status.idle": "2025-04-01T19:01:48.496902Z",
     "shell.execute_reply": "2025-04-01T19:01:48.495981Z"
    },
    "id": "OLDnCkLLwLr6",
    "papermill": {
     "duration": 139.247725,
     "end_time": "2025-04-01T19:01:48.499132",
     "exception": false,
     "start_time": "2025-04-01T18:59:29.251407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./models/research\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting avro-python3 (from object_detection==0.1)\r\n",
      "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting apache-beam (from object_detection==0.1)\r\n",
      "  Downloading apache_beam-2.64.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.4 kB)\r\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (11.0.0)\r\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (5.3.0)\r\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (3.7.5)\r\n",
      "Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (3.0.11)\r\n",
      "Collecting contextlib2 (from object_detection==0.1)\r\n",
      "  Downloading contextlib2-21.6.0-py2.py3-none-any.whl.metadata (4.1 kB)\r\n",
      "Requirement already satisfied: tf-slim in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.1.0)\r\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.17.0)\r\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.0.8)\r\n",
      "Collecting lvis (from object_detection==0.1)\r\n",
      "  Downloading lvis-0.5.3-py3-none-any.whl.metadata (856 bytes)\r\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (1.13.1)\r\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (2.2.3)\r\n",
      "Collecting tf-models-official==2.15.0 (from object_detection==0.1)\r\n",
      "  Downloading tf_models_official-2.15.0-py2.py3-none-any.whl.metadata (1.4 kB)\r\n",
      "Requirement already satisfied: tensorflow_io in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (0.37.1)\r\n",
      "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from object_detection==0.1) (3.5.0)\r\n",
      "Collecting pyparsing==2.4.7 (from object_detection==0.1)\r\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl.metadata (3.6 kB)\r\n",
      "Collecting sacrebleu<=2.2.0 (from object_detection==0.1)\r\n",
      "  Downloading sacrebleu-2.2.0-py3-none-any.whl.metadata (55 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/55.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (0.5.0)\r\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (2.155.0)\r\n",
      "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (4.2.1)\r\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (1.6.17)\r\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (1.26.4)\r\n",
      "Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (4.1.3)\r\n",
      "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (4.10.0.84)\r\n",
      "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (5.9.5)\r\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (9.0.0)\r\n",
      "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (6.0.2)\r\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (0.2.0)\r\n",
      "Collecting seqeval (from tf-models-official==2.15.0->object_detection==0.1)\r\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (4.9.7)\r\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official==2.15.0->object_detection==0.1) (0.16.1)\r\n",
      "Collecting tensorflow-model-optimization>=0.4.1 (from tf-models-official==2.15.0->object_detection==0.1)\r\n",
      "  Downloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl.metadata (904 bytes)\r\n",
      "Collecting tensorflow-text~=2.15.0 (from tf-models-official==2.15.0->object_detection==0.1)\r\n",
      "  Downloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.9 kB)\r\n",
      "Collecting tensorflow~=2.15.0 (from tf-models-official==2.15.0->object_detection==0.1)\r\n",
      "  Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->object_detection==0.1) (2.9.0.post0)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->object_detection==0.1) (2025.1)\r\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->object_detection==0.1) (2025.1)\r\n",
      "Collecting portalocker (from sacrebleu<=2.2.0->object_detection==0.1)\r\n",
      "  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\r\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (2024.11.6)\r\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.9.0)\r\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.10/dist-packages (from sacrebleu<=2.2.0->object_detection==0.1) (0.4.6)\r\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim->object_detection==0.1) (1.4.0)\r\n",
      "Collecting crcmod<2.0,>=1.7 (from apache-beam->object_detection==0.1)\r\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (3.10.12)\r\n",
      "Collecting dill<0.3.2,>=0.3.1.1 (from apache-beam->object_detection==0.1)\r\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Collecting cloudpickle~=2.2.1 (from apache-beam->object_detection==0.1)\r\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\r\n",
      "Collecting fastavro<2,>=0.23.6 (from apache-beam->object_detection==0.1)\r\n",
      "  Downloading fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\r\n",
      "Collecting fasteners<1.0,>=0.3 (from apache-beam->object_detection==0.1)\r\n",
      "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\r\n",
      "Collecting grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 (from apache-beam->object_detection==0.1)\r\n",
      "  Downloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\r\n",
      "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam->object_detection==0.1)\r\n",
      "  Downloading hdfs-2.7.3.tar.gz (43 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (0.22.0)\r\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.23.0)\r\n",
      "Collecting jsonpickle<4.0.0,>=3.0.0 (from apache-beam->object_detection==0.1)\r\n",
      "  Downloading jsonpickle-3.4.2-py3-none-any.whl.metadata (8.1 kB)\r\n",
      "Collecting objsize<0.8.0,>=0.6.1 (from apache-beam->object_detection==0.1)\r\n",
      "  Downloading objsize-0.7.1-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (24.2)\r\n",
      "Requirement already satisfied: pymongo<5.0.0,>=3.8.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.11.1)\r\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (1.25.0)\r\n",
      "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<6.0.0.dev0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (3.20.3)\r\n",
      "Collecting pydot<2,>=1.2.0 (from apache-beam->object_detection==0.1)\r\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\r\n",
      "Collecting redis<6,>=5.0.0 (from apache-beam->object_detection==0.1)\r\n",
      "  Downloading redis-5.2.1-py3-none-any.whl.metadata (9.1 kB)\r\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (2.32.3)\r\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (2.4.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam->object_detection==0.1) (4.12.2)\r\n",
      "Collecting zstandard<1,>=0.18.0 (from apache-beam->object_detection==0.1)\r\n",
      "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\r\n",
      "Collecting pyarrow<17.0.0,>=3.0.0 (from apache-beam->object_detection==0.1)\r\n",
      "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\r\n",
      "Collecting pyarrow-hotfix<1 (from apache-beam->object_detection==0.1)\r\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\r\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (13.9.4)\r\n",
      "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (0.0.8)\r\n",
      "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (3.12.1)\r\n",
      "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (0.13.1)\r\n",
      "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->object_detection==0.1) (0.4.1)\r\n",
      "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object_detection==0.1) (0.12.1)\r\n",
      "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lvis->object_detection==0.1) (1.4.7)\r\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from lvis->object_detection==0.1) (4.10.0.84)\r\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object_detection==0.1) (1.3.1)\r\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->object_detection==0.1) (4.55.3)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.37.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io->object_detection==0.1) (0.37.1)\r\n",
      "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.15.0->object_detection==0.1) (2.27.0)\r\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.15.0->object_detection==0.1) (0.2.0)\r\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.15.0->object_detection==0.1) (1.34.1)\r\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client>=1.6.7->tf-models-official==2.15.0->object_detection==0.1) (4.1.1)\r\n",
      "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam->object_detection==0.1)\r\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (25.1.0)\r\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (2024.10.1)\r\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.35.1)\r\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam->object_detection==0.1) (0.22.3)\r\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.15.0->object_detection==0.1) (2025.1.31)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.15.0->object_detection==0.1) (4.67.1)\r\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.15.0->object_detection==0.1) (8.0.4)\r\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.15.0->object_detection==0.1) (2.3.0)\r\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle>=1.3.9->tf-models-official==2.15.0->object_detection==0.1) (6.2.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->tf-models-official==2.15.0->object_detection==0.1) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->tf-models-official==2.15.0->object_detection==0.1) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->tf-models-official==2.15.0->object_detection==0.1) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->tf-models-official==2.15.0->object_detection==0.1) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->tf-models-official==2.15.0->object_detection==0.1) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20->tf-models-official==2.15.0->object_detection==0.1) (2.4.1)\r\n",
      "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo<5.0.0,>=3.8.0->apache-beam->object_detection==0.1) (2.7.0)\r\n",
      "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis<6,>=5.0.0->apache-beam->object_detection==0.1) (5.0.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection==0.1) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object_detection==0.1) (3.10)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (24.3.25)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (0.6.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (0.2.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (18.1.1)\r\n",
      "Collecting ml-dtypes (from keras->object_detection==0.1)\r\n",
      "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (3.4.0)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (75.1.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (2.5.0)\r\n",
      "Collecting wrapt<1.15,>=1.11.0 (from tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1)\r\n",
      "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\r\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1)\r\n",
      "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\r\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1)\r\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\r\n",
      "Collecting keras (from object_detection==0.1)\r\n",
      "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub>=0.6.0->tf-models-official==2.15.0->object_detection==0.1) (2.17.0)\r\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official==2.15.0->object_detection==0.1) (0.1.8)\r\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.15.0->object_detection==0.1) (0.6.1)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.15.0->object_detection==0.1) (0.4.1)\r\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client->tf-models-official==2.15.0->object_detection==0.1) (4.9)\r\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval->tf-models-official==2.15.0->object_detection==0.1) (1.2.2)\r\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.15.0->object_detection==0.1) (8.1.7)\r\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.15.0->object_detection==0.1) (2.3)\r\n",
      "Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.15.0->object_detection==0.1) (0.1.6)\r\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.15.0->object_detection==0.1) (1.13.1)\r\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.15.0->object_detection==0.1) (0.10.2)\r\n",
      "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets->tf-models-official==2.15.0->object_detection==0.1) (0.5.1)\r\n",
      "Requirement already satisfied: etils>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official==2.15.0->object_detection==0.1) (1.11.0)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (0.45.1)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official==2.15.0->object_detection==0.1) (2024.12.0)\r\n",
      "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official==2.15.0->object_detection==0.1) (5.13.0)\r\n",
      "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < \"3.11\"->tensorflow-datasets->tf-models-official==2.15.0->object_detection==0.1) (3.21.0)\r\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official==2.15.0->object_detection==0.1) (1.66.0)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client>=1.6.7->tf-models-official==2.15.0->object_detection==0.1) (5.5.0)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.15.0->object_detection==0.1) (1.4.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official==2.15.0->object_detection==0.1) (3.5.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (1.2.1)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (3.7)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (3.1.3)\r\n",
      "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\r\n",
      "Collecting tf-keras>=2.14.1 (from tensorflow-hub>=0.6.0->tf-models-official==2.15.0->object_detection==0.1)\r\n",
      "  Downloading tf_keras-2.19.0-py3-none-any.whl.metadata (1.8 kB)\r\n",
      "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\r\n",
      "  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\r\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle>=1.3.9->tf-models-official==2.15.0->object_detection==0.1) (0.5.1)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.20->tf-models-official==2.15.0->object_detection==0.1) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.20->tf-models-official==2.15.0->object_detection==0.1) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.20->tf-models-official==2.15.0->object_detection==0.1) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.20->tf-models-official==2.15.0->object_detection==0.1) (2024.2.0)\r\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official==2.15.0->object_detection==0.1) (1.3)\r\n",
      "Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.10/dist-packages (from simple-parsing->tensorflow-datasets->tf-models-official==2.15.0->object_detection==0.1) (0.16)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (1.3.1)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.20->tf-models-official==2.15.0->object_detection==0.1) (2024.2.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (3.0.2)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tf-models-official==2.15.0->object_detection==0.1) (3.2.2)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->object_detection==0.1) (3.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->object_detection==0.1) (2.19.1)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->object_detection==0.1) (0.1.2)\r\n",
      "Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tf_models_official-2.15.0-py2.py3-none-any.whl (2.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m61.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading apache_beam-2.64.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.3 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m95.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\r\n",
      "Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\r\n",
      "Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\r\n",
      "Downloading fastavro-1.10.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\r\n",
      "Downloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading jsonpickle-3.4.2-py3-none-any.whl (46 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading objsize-0.7.1-py3-none-any.whl (11 kB)\r\n",
      "Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\r\n",
      "Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\r\n",
      "Downloading redis-5.2.1-py3-none-any.whl (261 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.5/261.5 kB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorflow_model_optimization-0.8.0-py2.py3-none-any.whl (242 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\r\n",
      "Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tf_keras-2.15.1-py3-none-any.whl (1.7 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: object_detection, avro-python3, crcmod, dill, hdfs, seqeval, docopt\r\n",
      "  Building wheel for object_detection (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for object_detection: filename=object_detection-0.1-py3-none-any.whl size=21920558 sha256=eb086aad97f18eab6041101800cef58ea4cdee01ff2a2ff81aba05583b9d9c12\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-olhh3f46/wheels/e6/5c/1f/32444df4025257dccdc9eafab2d06b65752494ee9ca01a388c\r\n",
      "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43994 sha256=49cd27296e17308409a24458e3a2aff86834ffacc36e092c1a0d62dc8263e513\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/85/62/6cdd81c56f923946b401cecff38055b94c9b766927f7d8ca82\r\n",
      "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31406 sha256=8685180468ff1f19edc9298446726d303e5926f9f7ac70ea84aec2faa0d6a247\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\r\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78542 sha256=8387f9e67acf2673cd2ac1fc1a50fa7d6a89afb733d354efcde77b1e08df0516\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\r\n",
      "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34324 sha256=3a612bab0d4459f9053dbb14dbfc6fded41dad60c49e75462e4ed05e108b8492\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\r\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=c7fff1a83eb2c73beff35da42792b1fcf8a7a77bc258d4058d6640867468da4d\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\r\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\r\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=bc6182fe25314209d54422f73a7f23c39cf2283d491071746744a38761094335\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\r\n",
      "Successfully built object_detection avro-python3 crcmod dill hdfs seqeval docopt\r\n",
      "Installing collected packages: docopt, crcmod, zstandard, wrapt, tensorflow-estimator, redis, pyparsing, pyarrow-hotfix, portalocker, objsize, keras, jsonpickle, grpcio, fasteners, fastavro, dill, contextlib2, cloudpickle, avro-python3, pydot, hdfs, tensorboard, ml-dtypes, tensorflow, tf-keras, pyarrow, tensorflow-text, tensorflow-model-optimization, seqeval, sacrebleu, tf-models-official, lvis, apache-beam, object_detection\r\n",
      "  Attempting uninstall: wrapt\r\n",
      "    Found existing installation: wrapt 1.17.0\r\n",
      "    Uninstalling wrapt-1.17.0:\r\n",
      "      Successfully uninstalled wrapt-1.17.0\r\n",
      "  Attempting uninstall: pyparsing\r\n",
      "    Found existing installation: pyparsing 3.2.0\r\n",
      "    Uninstalling pyparsing-3.2.0:\r\n",
      "      Successfully uninstalled pyparsing-3.2.0\r\n",
      "  Attempting uninstall: keras\r\n",
      "    Found existing installation: keras 3.5.0\r\n",
      "    Uninstalling keras-3.5.0:\r\n",
      "      Successfully uninstalled keras-3.5.0\r\n",
      "  Attempting uninstall: jsonpickle\r\n",
      "    Found existing installation: jsonpickle 4.0.1\r\n",
      "    Uninstalling jsonpickle-4.0.1:\r\n",
      "      Successfully uninstalled jsonpickle-4.0.1\r\n",
      "  Attempting uninstall: grpcio\r\n",
      "    Found existing installation: grpcio 1.68.1\r\n",
      "    Uninstalling grpcio-1.68.1:\r\n",
      "      Successfully uninstalled grpcio-1.68.1\r\n",
      "  Attempting uninstall: dill\r\n",
      "    Found existing installation: dill 0.3.8\r\n",
      "    Uninstalling dill-0.3.8:\r\n",
      "      Successfully uninstalled dill-0.3.8\r\n",
      "  Attempting uninstall: cloudpickle\r\n",
      "    Found existing installation: cloudpickle 3.1.0\r\n",
      "    Uninstalling cloudpickle-3.1.0:\r\n",
      "      Successfully uninstalled cloudpickle-3.1.0\r\n",
      "  Attempting uninstall: pydot\r\n",
      "    Found existing installation: pydot 3.0.3\r\n",
      "    Uninstalling pydot-3.0.3:\r\n",
      "      Successfully uninstalled pydot-3.0.3\r\n",
      "  Attempting uninstall: tensorboard\r\n",
      "    Found existing installation: tensorboard 2.17.1\r\n",
      "    Uninstalling tensorboard-2.17.1:\r\n",
      "      Successfully uninstalled tensorboard-2.17.1\r\n",
      "  Attempting uninstall: ml-dtypes\r\n",
      "    Found existing installation: ml-dtypes 0.4.1\r\n",
      "    Uninstalling ml-dtypes-0.4.1:\r\n",
      "      Successfully uninstalled ml-dtypes-0.4.1\r\n",
      "  Attempting uninstall: tensorflow\r\n",
      "    Found existing installation: tensorflow 2.17.1\r\n",
      "    Uninstalling tensorflow-2.17.1:\r\n",
      "      Successfully uninstalled tensorflow-2.17.1\r\n",
      "  Attempting uninstall: tf-keras\r\n",
      "    Found existing installation: tf_keras 2.17.0\r\n",
      "    Uninstalling tf_keras-2.17.0:\r\n",
      "      Successfully uninstalled tf_keras-2.17.0\r\n",
      "  Attempting uninstall: pyarrow\r\n",
      "    Found existing installation: pyarrow 19.0.1\r\n",
      "    Uninstalling pyarrow-19.0.1:\r\n",
      "      Successfully uninstalled pyarrow-19.0.1\r\n",
      "  Attempting uninstall: tensorflow-text\r\n",
      "    Found existing installation: tensorflow-text 2.17.0\r\n",
      "    Uninstalling tensorflow-text-2.17.0:\r\n",
      "      Successfully uninstalled tensorflow-text-2.17.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "dask 2024.12.1 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\r\n",
      "distributed 2024.12.1 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\r\n",
      "mlxtend 0.23.3 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\r\n",
      "multiprocess 0.70.16 requires dill>=0.3.8, but you have dill 0.3.1.1 which is incompatible.\r\n",
      "pandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\r\n",
      "pathos 0.3.2 requires dill>=0.3.8, but you have dill 0.3.1.1 which is incompatible.\r\n",
      "plotnine 0.14.4 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\r\n",
      "tensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.15.1 which is incompatible.\r\n",
      "tensorflow-decision-forests 1.10.0 requires tf-keras~=2.17, but you have tf-keras 2.15.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed apache-beam-2.64.0 avro-python3-1.10.2 cloudpickle-2.2.1 contextlib2-21.6.0 crcmod-1.7 dill-0.3.1.1 docopt-0.6.2 fastavro-1.10.0 fasteners-0.19 grpcio-1.65.5 hdfs-2.7.3 jsonpickle-3.4.2 keras-2.15.0 lvis-0.5.3 ml-dtypes-0.3.2 object_detection-0.1 objsize-0.7.1 portalocker-3.1.1 pyarrow-16.1.0 pyarrow-hotfix-0.6 pydot-1.4.2 pyparsing-2.4.7 redis-5.2.1 sacrebleu-2.2.0 seqeval-1.2.2 tensorboard-2.15.2 tensorflow-2.15.1 tensorflow-estimator-2.15.0 tensorflow-model-optimization-0.8.0 tensorflow-text-2.15.0 tf-keras-2.15.1 tf-models-official-2.15.0 wrapt-1.14.1 zstandard-0.23.0\r\n",
      "Collecting tensorflow==2.15.0\r\n",
      "  Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.4.0)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.3.25)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.6.0)\r\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.2.0)\r\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.12.1)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (18.1.1)\r\n",
      "Collecting ml-dtypes~=0.2.0 (from tensorflow==2.15.0)\r\n",
      "  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\r\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.26.4)\r\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.4.0)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (24.2)\r\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (3.20.3)\r\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (75.1.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.17.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.5.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (4.12.2)\r\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.14.1)\r\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (0.37.1)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (1.65.5)\r\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.2)\r\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.0)\r\n",
      "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.15.0) (2.15.0)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.45.1)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.15.0) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.15.0) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.15.0) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.15.0) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.15.0) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy<2.0.0,>=1.23.5->tensorflow==2.15.0) (2.4.1)\r\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.27.0)\r\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.1)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.7)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.32.3)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.1.3)\r\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.5.0)\r\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.1)\r\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\r\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.3.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.4.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.10)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.3.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2025.1.31)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.2)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.15.0) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.15.0) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.15.0) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy<2.0.0,>=1.23.5->tensorflow==2.15.0) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy<2.0.0,>=1.23.5->tensorflow==2.15.0) (2024.2.0)\r\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.1)\r\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\r\n",
      "Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: ml-dtypes, tensorflow\r\n",
      "  Attempting uninstall: ml-dtypes\r\n",
      "    Found existing installation: ml-dtypes 0.3.2\r\n",
      "    Uninstalling ml-dtypes-0.3.2:\r\n",
      "      Successfully uninstalled ml-dtypes-0.3.2\r\n",
      "  Attempting uninstall: tensorflow\r\n",
      "    Found existing installation: tensorflow 2.15.1\r\n",
      "    Uninstalling tensorflow-2.15.1:\r\n",
      "      Successfully uninstalled tensorflow-2.15.1\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.15.0 which is incompatible.\r\n",
      "tensorflow-decision-forests 1.10.0 requires tf-keras~=2.17, but you have tf-keras 2.15.1 which is incompatible.\r\n",
      "tensorstore 0.1.71 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed ml-dtypes-0.2.0 tensorflow-2.15.0\r\n",
      "Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/dist-packages (3.20.3)\r\n"
     ]
    }
   ],
   "source": [
    "# Install\n",
    "!pip install {HOMEFOLDER}models/research/\n",
    "if(MLENVIRONMENT == \"KAGGLE\"):\n",
    "    !pip install tensorflow==2.15.0\n",
    "    !pip install protobuf==3.20.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe35e78",
   "metadata": {
    "id": "6V7TrfUos-9E",
    "papermill": {
     "duration": 0.027129,
     "end_time": "2025-04-01T19:01:48.554656",
     "exception": false,
     "start_time": "2025-04-01T19:01:48.527527",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Test the environment by running `model_builder_tf2_test.py` to make sure everything is working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "985fda46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T19:01:48.610414Z",
     "iopub.status.busy": "2025-04-01T19:01:48.610107Z",
     "iopub.status.idle": "2025-04-01T19:02:32.181695Z",
     "shell.execute_reply": "2025-04-01T19:02:32.180822Z"
    },
    "id": "wh_HPMOqWH9z",
    "papermill": {
     "duration": 43.601211,
     "end_time": "2025-04-01T19:02:32.183297",
     "exception": false,
     "start_time": "2025-04-01T19:01:48.582086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-01 19:01:49.306788: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2025-04-01 19:01:49.306856: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2025-04-01 19:01:49.308657: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "Running tests under Python 3.10.12: /usr/bin/python3\r\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\r\n",
      "W0401 19:01:56.866208 134065620653184 batch_normalization.py:1531] `tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\r\n",
      "/usr/local/lib/python3.10/dist-packages/object_detection/builders/model_builder.py:1112: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\r\n",
      "  logging.warn(('Building experimental DeepMAC meta-arch.'\r\n",
      "W0401 19:01:57.141047 134065620653184 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\r\n",
      "I0401 19:01:57.450012 134065620653184 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.75s\r\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\r\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\r\n",
      "I0401 19:01:58.263004 134065620653184 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.81s\r\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\r\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\r\n",
      "I0401 19:01:58.577242 134065620653184 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.31s\r\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\r\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\r\n",
      "I0401 19:01:58.868979 134065620653184 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.29s\r\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\r\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\r\n",
      "I0401 19:02:01.076671 134065620653184 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.21s\r\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\r\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\r\n",
      "I0401 19:02:01.089831 134065620653184 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\r\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\r\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\r\n",
      "I0401 19:02:01.117686 134065620653184 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\r\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\r\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\r\n",
      "I0401 19:02:01.136354 134065620653184 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\r\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\r\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\r\n",
      "I0401 19:02:01.154757 134065620653184 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\r\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\r\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\r\n",
      "I0401 19:02:01.263984 134065620653184 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.11s\r\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\r\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\r\n",
      "I0401 19:02:01.368752 134065620653184 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.1s\r\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\r\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\r\n",
      "I0401 19:02:01.478526 134065620653184 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.11s\r\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\r\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\r\n",
      "I0401 19:02:01.585732 134065620653184 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.11s\r\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\r\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\r\n",
      "I0401 19:02:01.690030 134065620653184 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.1s\r\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\r\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\r\n",
      "I0401 19:02:01.721939 134065620653184 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\r\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\r\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\r\n",
      "I0401 19:02:01.917469 134065620653184 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b0\r\n",
      "I0401 19:02:01.917698 134065620653184 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 64\r\n",
      "I0401 19:02:01.917772 134065620653184 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 3\r\n",
      "I0401 19:02:01.920440 134065620653184 efficientnet_model.py:143] round_filter input=32 output=32\r\n",
      "I0401 19:02:01.952324 134065620653184 efficientnet_model.py:143] round_filter input=32 output=32\r\n",
      "I0401 19:02:01.952493 134065620653184 efficientnet_model.py:143] round_filter input=16 output=16\r\n",
      "I0401 19:02:02.046566 134065620653184 efficientnet_model.py:143] round_filter input=16 output=16\r\n",
      "I0401 19:02:02.046804 134065620653184 efficientnet_model.py:143] round_filter input=24 output=24\r\n",
      "I0401 19:02:02.307806 134065620653184 efficientnet_model.py:143] round_filter input=24 output=24\r\n",
      "I0401 19:02:02.308042 134065620653184 efficientnet_model.py:143] round_filter input=40 output=40\r\n",
      "I0401 19:02:02.746869 134065620653184 efficientnet_model.py:143] round_filter input=40 output=40\r\n",
      "I0401 19:02:02.747110 134065620653184 efficientnet_model.py:143] round_filter input=80 output=80\r\n",
      "I0401 19:02:03.076201 134065620653184 efficientnet_model.py:143] round_filter input=80 output=80\r\n",
      "I0401 19:02:03.076427 134065620653184 efficientnet_model.py:143] round_filter input=112 output=112\r\n",
      "I0401 19:02:03.397216 134065620653184 efficientnet_model.py:143] round_filter input=112 output=112\r\n",
      "I0401 19:02:03.397457 134065620653184 efficientnet_model.py:143] round_filter input=192 output=192\r\n",
      "I0401 19:02:03.803823 134065620653184 efficientnet_model.py:143] round_filter input=192 output=192\r\n",
      "I0401 19:02:03.804059 134065620653184 efficientnet_model.py:143] round_filter input=320 output=320\r\n",
      "I0401 19:02:03.903484 134065620653184 efficientnet_model.py:143] round_filter input=1280 output=1280\r\n",
      "I0401 19:02:03.952479 134065620653184 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\r\n",
      "I0401 19:02:04.008655 134065620653184 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\r\n",
      "I0401 19:02:04.008839 134065620653184 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\r\n",
      "I0401 19:02:04.008912 134065620653184 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\r\n",
      "I0401 19:02:04.010795 134065620653184 efficientnet_model.py:143] round_filter input=32 output=32\r\n",
      "I0401 19:02:04.035368 134065620653184 efficientnet_model.py:143] round_filter input=32 output=32\r\n",
      "I0401 19:02:04.035533 134065620653184 efficientnet_model.py:143] round_filter input=16 output=16\r\n",
      "I0401 19:02:04.266357 134065620653184 efficientnet_model.py:143] round_filter input=16 output=16\r\n",
      "I0401 19:02:04.266667 134065620653184 efficientnet_model.py:143] round_filter input=24 output=24\r\n",
      "I0401 19:02:04.604382 134065620653184 efficientnet_model.py:143] round_filter input=24 output=24\r\n",
      "I0401 19:02:04.604585 134065620653184 efficientnet_model.py:143] round_filter input=40 output=40\r\n",
      "I0401 19:02:04.876969 134065620653184 efficientnet_model.py:143] round_filter input=40 output=40\r\n",
      "I0401 19:02:04.877191 134065620653184 efficientnet_model.py:143] round_filter input=80 output=80\r\n",
      "I0401 19:02:05.244667 134065620653184 efficientnet_model.py:143] round_filter input=80 output=80\r\n",
      "I0401 19:02:05.244885 134065620653184 efficientnet_model.py:143] round_filter input=112 output=112\r\n",
      "I0401 19:02:05.621153 134065620653184 efficientnet_model.py:143] round_filter input=112 output=112\r\n",
      "I0401 19:02:05.621373 134065620653184 efficientnet_model.py:143] round_filter input=192 output=192\r\n",
      "I0401 19:02:06.077829 134065620653184 efficientnet_model.py:143] round_filter input=192 output=192\r\n",
      "I0401 19:02:06.078063 134065620653184 efficientnet_model.py:143] round_filter input=320 output=320\r\n",
      "I0401 19:02:06.268255 134065620653184 efficientnet_model.py:143] round_filter input=1280 output=1280\r\n",
      "I0401 19:02:06.303105 134065620653184 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\r\n",
      "I0401 19:02:06.366900 134065620653184 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b2\r\n",
      "I0401 19:02:06.367094 134065620653184 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 112\r\n",
      "I0401 19:02:06.367200 134065620653184 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 5\r\n",
      "I0401 19:02:06.369210 134065620653184 efficientnet_model.py:143] round_filter input=32 output=32\r\n",
      "I0401 19:02:06.386287 134065620653184 efficientnet_model.py:143] round_filter input=32 output=32\r\n",
      "I0401 19:02:06.386423 134065620653184 efficientnet_model.py:143] round_filter input=16 output=16\r\n",
      "I0401 19:02:06.524652 134065620653184 efficientnet_model.py:143] round_filter input=16 output=16\r\n",
      "I0401 19:02:06.524823 134065620653184 efficientnet_model.py:143] round_filter input=24 output=24\r\n",
      "I0401 19:02:06.819529 134065620653184 efficientnet_model.py:143] round_filter input=24 output=24\r\n",
      "I0401 19:02:06.819736 134065620653184 efficientnet_model.py:143] round_filter input=40 output=48\r\n",
      "I0401 19:02:07.115901 134065620653184 efficientnet_model.py:143] round_filter input=40 output=48\r\n",
      "I0401 19:02:07.116138 134065620653184 efficientnet_model.py:143] round_filter input=80 output=88\r\n",
      "I0401 19:02:07.526700 134065620653184 efficientnet_model.py:143] round_filter input=80 output=88\r\n",
      "I0401 19:02:07.526937 134065620653184 efficientnet_model.py:143] round_filter input=112 output=120\r\n",
      "I0401 19:02:07.948343 134065620653184 efficientnet_model.py:143] round_filter input=112 output=120\r\n",
      "I0401 19:02:07.948597 134065620653184 efficientnet_model.py:143] round_filter input=192 output=208\r\n",
      "I0401 19:02:08.460447 134065620653184 efficientnet_model.py:143] round_filter input=192 output=208\r\n",
      "I0401 19:02:08.460671 134065620653184 efficientnet_model.py:143] round_filter input=320 output=352\r\n",
      "I0401 19:02:08.666095 134065620653184 efficientnet_model.py:143] round_filter input=1280 output=1408\r\n",
      "I0401 19:02:08.707118 134065620653184 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\r\n",
      "I0401 19:02:08.771890 134065620653184 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b3\r\n",
      "I0401 19:02:08.772105 134065620653184 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 160\r\n",
      "I0401 19:02:08.772212 134065620653184 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 6\r\n",
      "I0401 19:02:08.774126 134065620653184 efficientnet_model.py:143] round_filter input=32 output=40\r\n",
      "I0401 19:02:08.795689 134065620653184 efficientnet_model.py:143] round_filter input=32 output=40\r\n",
      "I0401 19:02:08.795841 134065620653184 efficientnet_model.py:143] round_filter input=16 output=24\r\n",
      "I0401 19:02:08.959560 134065620653184 efficientnet_model.py:143] round_filter input=16 output=24\r\n",
      "I0401 19:02:08.959790 134065620653184 efficientnet_model.py:143] round_filter input=24 output=32\r\n",
      "I0401 19:02:09.271757 134065620653184 efficientnet_model.py:143] round_filter input=24 output=32\r\n",
      "I0401 19:02:09.271993 134065620653184 efficientnet_model.py:143] round_filter input=40 output=48\r\n",
      "I0401 19:02:09.539916 134065620653184 efficientnet_model.py:143] round_filter input=40 output=48\r\n",
      "I0401 19:02:09.540124 134065620653184 efficientnet_model.py:143] round_filter input=80 output=96\r\n",
      "I0401 19:02:10.041886 134065620653184 efficientnet_model.py:143] round_filter input=80 output=96\r\n",
      "I0401 19:02:10.042117 134065620653184 efficientnet_model.py:143] round_filter input=112 output=136\r\n",
      "I0401 19:02:10.569571 134065620653184 efficientnet_model.py:143] round_filter input=112 output=136\r\n",
      "I0401 19:02:10.569836 134065620653184 efficientnet_model.py:143] round_filter input=192 output=232\r\n",
      "I0401 19:02:11.484393 134065620653184 efficientnet_model.py:143] round_filter input=192 output=232\r\n",
      "I0401 19:02:11.484617 134065620653184 efficientnet_model.py:143] round_filter input=320 output=384\r\n",
      "I0401 19:02:11.717847 134065620653184 efficientnet_model.py:143] round_filter input=1280 output=1536\r\n",
      "I0401 19:02:11.758725 134065620653184 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\r\n",
      "I0401 19:02:11.828300 134065620653184 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b4\r\n",
      "I0401 19:02:11.828473 134065620653184 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 224\r\n",
      "I0401 19:02:11.828588 134065620653184 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\r\n",
      "I0401 19:02:11.830489 134065620653184 efficientnet_model.py:143] round_filter input=32 output=48\r\n",
      "I0401 19:02:11.853028 134065620653184 efficientnet_model.py:143] round_filter input=32 output=48\r\n",
      "I0401 19:02:11.853178 134065620653184 efficientnet_model.py:143] round_filter input=16 output=24\r\n",
      "I0401 19:02:12.002599 134065620653184 efficientnet_model.py:143] round_filter input=16 output=24\r\n",
      "I0401 19:02:12.002816 134065620653184 efficientnet_model.py:143] round_filter input=24 output=32\r\n",
      "I0401 19:02:12.378484 134065620653184 efficientnet_model.py:143] round_filter input=24 output=32\r\n",
      "I0401 19:02:12.378719 134065620653184 efficientnet_model.py:143] round_filter input=40 output=56\r\n",
      "I0401 19:02:12.790357 134065620653184 efficientnet_model.py:143] round_filter input=40 output=56\r\n",
      "I0401 19:02:12.790612 134065620653184 efficientnet_model.py:143] round_filter input=80 output=112\r\n",
      "I0401 19:02:13.429635 134065620653184 efficientnet_model.py:143] round_filter input=80 output=112\r\n",
      "I0401 19:02:13.429887 134065620653184 efficientnet_model.py:143] round_filter input=112 output=160\r\n",
      "I0401 19:02:14.046745 134065620653184 efficientnet_model.py:143] round_filter input=112 output=160\r\n",
      "I0401 19:02:14.047032 134065620653184 efficientnet_model.py:143] round_filter input=192 output=272\r\n",
      "I0401 19:02:14.892759 134065620653184 efficientnet_model.py:143] round_filter input=192 output=272\r\n",
      "I0401 19:02:14.893015 134065620653184 efficientnet_model.py:143] round_filter input=320 output=448\r\n",
      "I0401 19:02:15.099295 134065620653184 efficientnet_model.py:143] round_filter input=1280 output=1792\r\n",
      "I0401 19:02:15.140293 134065620653184 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\r\n",
      "I0401 19:02:15.219437 134065620653184 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b5\r\n",
      "I0401 19:02:15.219618 134065620653184 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 288\r\n",
      "I0401 19:02:15.219742 134065620653184 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\r\n",
      "I0401 19:02:15.221828 134065620653184 efficientnet_model.py:143] round_filter input=32 output=48\r\n",
      "I0401 19:02:15.239441 134065620653184 efficientnet_model.py:143] round_filter input=32 output=48\r\n",
      "I0401 19:02:15.239589 134065620653184 efficientnet_model.py:143] round_filter input=16 output=24\r\n",
      "I0401 19:02:15.474040 134065620653184 efficientnet_model.py:143] round_filter input=16 output=24\r\n",
      "I0401 19:02:15.474256 134065620653184 efficientnet_model.py:143] round_filter input=24 output=40\r\n",
      "I0401 19:02:15.968930 134065620653184 efficientnet_model.py:143] round_filter input=24 output=40\r\n",
      "I0401 19:02:15.969166 134065620653184 efficientnet_model.py:143] round_filter input=40 output=64\r\n",
      "I0401 19:02:16.479702 134065620653184 efficientnet_model.py:143] round_filter input=40 output=64\r\n",
      "I0401 19:02:16.479957 134065620653184 efficientnet_model.py:143] round_filter input=80 output=128\r\n",
      "I0401 19:02:17.218324 134065620653184 efficientnet_model.py:143] round_filter input=80 output=128\r\n",
      "I0401 19:02:17.218543 134065620653184 efficientnet_model.py:143] round_filter input=112 output=176\r\n",
      "I0401 19:02:17.939384 134065620653184 efficientnet_model.py:143] round_filter input=112 output=176\r\n",
      "I0401 19:02:17.939603 134065620653184 efficientnet_model.py:143] round_filter input=192 output=304\r\n",
      "I0401 19:02:18.872424 134065620653184 efficientnet_model.py:143] round_filter input=192 output=304\r\n",
      "I0401 19:02:18.872667 134065620653184 efficientnet_model.py:143] round_filter input=320 output=512\r\n",
      "I0401 19:02:19.198226 134065620653184 efficientnet_model.py:143] round_filter input=1280 output=2048\r\n",
      "I0401 19:02:19.243983 134065620653184 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\r\n",
      "I0401 19:02:19.344759 134065620653184 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b6\r\n",
      "I0401 19:02:19.344938 134065620653184 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\r\n",
      "I0401 19:02:19.345086 134065620653184 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\r\n",
      "I0401 19:02:19.347084 134065620653184 efficientnet_model.py:143] round_filter input=32 output=56\r\n",
      "I0401 19:02:19.368500 134065620653184 efficientnet_model.py:143] round_filter input=32 output=56\r\n",
      "I0401 19:02:19.368658 134065620653184 efficientnet_model.py:143] round_filter input=16 output=32\r\n",
      "I0401 19:02:19.613017 134065620653184 efficientnet_model.py:143] round_filter input=16 output=32\r\n",
      "I0401 19:02:19.613196 134065620653184 efficientnet_model.py:143] round_filter input=24 output=40\r\n",
      "I0401 19:02:20.467576 134065620653184 efficientnet_model.py:143] round_filter input=24 output=40\r\n",
      "I0401 19:02:20.467810 134065620653184 efficientnet_model.py:143] round_filter input=40 output=72\r\n",
      "I0401 19:02:21.080914 134065620653184 efficientnet_model.py:143] round_filter input=40 output=72\r\n",
      "I0401 19:02:21.081168 134065620653184 efficientnet_model.py:143] round_filter input=80 output=144\r\n",
      "I0401 19:02:21.913968 134065620653184 efficientnet_model.py:143] round_filter input=80 output=144\r\n",
      "I0401 19:02:21.914206 134065620653184 efficientnet_model.py:143] round_filter input=112 output=200\r\n",
      "I0401 19:02:22.763288 134065620653184 efficientnet_model.py:143] round_filter input=112 output=200\r\n",
      "I0401 19:02:22.763512 134065620653184 efficientnet_model.py:143] round_filter input=192 output=344\r\n",
      "I0401 19:02:23.900911 134065620653184 efficientnet_model.py:143] round_filter input=192 output=344\r\n",
      "I0401 19:02:23.901153 134065620653184 efficientnet_model.py:143] round_filter input=320 output=576\r\n",
      "I0401 19:02:24.213904 134065620653184 efficientnet_model.py:143] round_filter input=1280 output=2304\r\n",
      "I0401 19:02:24.253613 134065620653184 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\r\n",
      "I0401 19:02:24.359880 134065620653184 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b7\r\n",
      "I0401 19:02:24.360135 134065620653184 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\r\n",
      "I0401 19:02:24.360244 134065620653184 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\r\n",
      "I0401 19:02:24.362286 134065620653184 efficientnet_model.py:143] round_filter input=32 output=64\r\n",
      "I0401 19:02:24.385423 134065620653184 efficientnet_model.py:143] round_filter input=32 output=64\r\n",
      "I0401 19:02:24.385586 134065620653184 efficientnet_model.py:143] round_filter input=16 output=32\r\n",
      "I0401 19:02:24.686547 134065620653184 efficientnet_model.py:143] round_filter input=16 output=32\r\n",
      "I0401 19:02:24.686769 134065620653184 efficientnet_model.py:143] round_filter input=24 output=48\r\n",
      "I0401 19:02:25.419597 134065620653184 efficientnet_model.py:143] round_filter input=24 output=48\r\n",
      "I0401 19:02:25.419881 134065620653184 efficientnet_model.py:143] round_filter input=40 output=80\r\n",
      "I0401 19:02:26.145851 134065620653184 efficientnet_model.py:143] round_filter input=40 output=80\r\n",
      "I0401 19:02:26.146087 134065620653184 efficientnet_model.py:143] round_filter input=80 output=160\r\n",
      "I0401 19:02:27.199341 134065620653184 efficientnet_model.py:143] round_filter input=80 output=160\r\n",
      "I0401 19:02:27.199576 134065620653184 efficientnet_model.py:143] round_filter input=112 output=224\r\n",
      "I0401 19:02:28.243225 134065620653184 efficientnet_model.py:143] round_filter input=112 output=224\r\n",
      "I0401 19:02:28.243455 134065620653184 efficientnet_model.py:143] round_filter input=192 output=384\r\n",
      "I0401 19:02:29.581422 134065620653184 efficientnet_model.py:143] round_filter input=192 output=384\r\n",
      "I0401 19:02:29.581665 134065620653184 efficientnet_model.py:143] round_filter input=320 output=640\r\n",
      "I0401 19:02:30.009968 134065620653184 efficientnet_model.py:143] round_filter input=1280 output=2560\r\n",
      "I0401 19:02:30.050562 134065620653184 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\r\n",
      "I0401 19:02:30.481694 134065620653184 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 28.76s\r\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\r\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\r\n",
      "I0401 19:02:30.654354 134065620653184 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.01s\r\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\r\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\r\n",
      "I0401 19:02:30.656531 134065620653184 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\r\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\r\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\r\n",
      "I0401 19:02:30.657240 134065620653184 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\r\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\r\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\r\n",
      "I0401 19:02:30.658740 134065620653184 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\r\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\r\n",
      "[ RUN      ] ModelBuilderTF2Test.test_session\r\n",
      "[  SKIPPED ] ModelBuilderTF2Test.test_session\r\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\r\n",
      "I0401 19:02:30.660155 134065620653184 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\r\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\r\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\r\n",
      "I0401 19:02:30.660600 134065620653184 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\r\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\r\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\r\n",
      "I0401 19:02:30.661613 134065620653184 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\r\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 24 tests in 33.963s\r\n",
      "\r\n",
      "OK (skipped=1)\r\n"
     ]
    }
   ],
   "source": [
    "!python {HOMEFOLDER}models/research/object_detection/builders/model_builder_tf2_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e2922e",
   "metadata": {
    "id": "xmROIG9zaS9G",
    "papermill": {
     "duration": 0.031674,
     "end_time": "2025-04-01T19:02:32.247351",
     "exception": false,
     "start_time": "2025-04-01T19:02:32.215677",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 1.1. Get Dataset From Google Drive\n",
    "\n",
    "1. Expand this section\n",
    "2. Upload your RoboFlow .tfrecord.zip to Google Drive\n",
    "3. Share the uploaded .tfrecord.zip such that anyone with the link can access the file.\n",
    "4. Run this block\n",
    "5. Paste your Google Drive file share link into the text box that appears after running this block\n",
    "6. Click the \"Process Dataset\" Buttton\n",
    "7. Click the Refresh button in the \"Files\" pane to ensure dataset.zip exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88d1218a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T19:02:32.312848Z",
     "iopub.status.busy": "2025-04-01T19:02:32.312530Z",
     "iopub.status.idle": "2025-04-01T19:02:40.286192Z",
     "shell.execute_reply": "2025-04-01T19:02:40.285199Z"
    },
    "id": "tLgAPsQsfTLs",
    "papermill": {
     "duration": 8.008431,
     "end_time": "2025-04-01T19:02:40.287637",
     "exception": false,
     "start_time": "2025-04-01T19:02:32.279206",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1Kq1w6e60OsyS13zUtYLdEWUoBQ9fZWIe\n",
      "From (redirected): https://drive.google.com/uc?id=1Kq1w6e60OsyS13zUtYLdEWUoBQ9fZWIe&confirm=t&uuid=5dc7b76a-166d-4235-b0ea-3626aab88872\n",
      "To: /kaggle/working/dataset.zip\n",
      "100%|██████████| 79.7M/79.7M [00:00<00:00, 187MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "import os\n",
    "\n",
    "def download_dataset():\n",
    "    try:\n",
    "        print(\"Downloading dataset...\")\n",
    "        url = 'https://drive.google.com/file/d/1Kq1w6e60OsyS13zUtYLdEWUoBQ9fZWIe/view?usp=drive_link'\n",
    "        output = '/kaggle/working/dataset.zip'\n",
    "        gdown.download(url, output, fuzzy=True)\n",
    "        print(\"Download complete!\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {str(e)}\")\n",
    "\n",
    "# Install gdown if not already installed\n",
    "!pip install -q gdown --upgrade\n",
    "\n",
    "# Execute\n",
    "download_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8269c70",
   "metadata": {
    "id": "m6kMXxVJo5za",
    "papermill": {
     "duration": 0.032511,
     "end_time": "2025-04-01T19:02:40.353286",
     "exception": false,
     "start_time": "2025-04-01T19:02:40.320775",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 2. Auto-detect relevant tfrecord components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53865418",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T19:02:40.418061Z",
     "iopub.status.busy": "2025-04-01T19:02:40.417626Z",
     "iopub.status.idle": "2025-04-01T19:02:41.016314Z",
     "shell.execute_reply": "2025-04-01T19:02:41.015303Z"
    },
    "id": "n9bd6VsJf2wl",
    "papermill": {
     "duration": 0.632594,
     "end_time": "2025-04-01T19:02:41.017704",
     "exception": false,
     "start_time": "2025-04-01T19:02:40.385110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/dataset.zip\n",
      "Archive:  /kaggle/working/dataset.zip\r\n",
      "  inflating: README.dataset.txt      \r\n",
      "  inflating: README.roboflow.txt     \r\n",
      "   creating: test/\r\n",
      " extracting: test/Samples.tfrecord   \r\n",
      "  inflating: test/Samples_label_map.pbtxt  \r\n",
      "   creating: train/\r\n",
      " extracting: train/Samples.tfrecord  \r\n",
      "  inflating: train/Samples_label_map.pbtxt  \r\n",
      "   creating: valid/\r\n",
      " extracting: valid/Samples.tfrecord  \r\n",
      "  inflating: valid/Samples_label_map.pbtxt  \r\n",
      "  inflating: negative/blank.tfrecord  \r\n",
      " extracting: negative/blank_label_map.pbtxt  \r\n"
     ]
    }
   ],
   "source": [
    "datasetPath = '/kaggle/working/dataset.zip'\n",
    "print(datasetPath)\n",
    "!unzip $datasetPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0512d38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T19:02:41.083498Z",
     "iopub.status.busy": "2025-04-01T19:02:41.083251Z",
     "iopub.status.idle": "2025-04-01T19:02:41.113503Z",
     "shell.execute_reply": "2025-04-01T19:02:41.112914Z"
    },
    "id": "YUd2wtfrqedy",
    "papermill": {
     "duration": 0.064165,
     "end_time": "2025-04-01T19:02:41.114630",
     "exception": false,
     "start_time": "2025-04-01T19:02:41.050465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Record File: /kaggle/working/train/Samples.tfrecord\n",
      "Validation Record File: /kaggle/working/valid/Samples.tfrecord\n",
      "Negative Samples Record File: /kaggle/working/negative/blank.tfrecord\n",
      "Label Map File: /kaggle/working/train/Samples_label_map.pbtxt\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "\n",
    "def find_files(directory, pattern):\n",
    "    \"\"\"Find files matching a pattern in a directory and its subdirectories.\"\"\"\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for filename in fnmatch.filter(files, pattern):\n",
    "            yield os.path.join(root, filename)\n",
    "\n",
    "def set_tfrecord_variables(directory):\n",
    "    train_record_fname = ''\n",
    "    val_record_fname = ''\n",
    "    negative_record_fname = ''\n",
    "    label_map_pbtxt_fname = ''\n",
    "\n",
    "    for tfrecord_file in find_files(directory, '*.tfrecord'):\n",
    "        if '/train/' in tfrecord_file:\n",
    "            train_record_fname = tfrecord_file\n",
    "        elif '/valid/' in tfrecord_file:\n",
    "            val_record_fname = tfrecord_file\n",
    "        elif '/negative/' in tfrecord_file:\n",
    "            negative_record_fname = tfrecord_file\n",
    "        elif '/test/' in tfrecord_file:\n",
    "            pass\n",
    "\n",
    "    # 使用自定义的label map文件\n",
    "    for label_map_file in find_files(directory, '*_label_map.pbtxt'):\n",
    "        if '/train/' in label_map_file:  # 优先使用train目录下的label map\n",
    "            label_map_pbtxt_fname = label_map_file\n",
    "            break\n",
    "        label_map_pbtxt_fname = label_map_file  # 如果找不到train目录下的，就用找到的第一个\n",
    "\n",
    "    return train_record_fname, val_record_fname, negative_record_fname, label_map_pbtxt_fname\n",
    "\n",
    "\n",
    "# Update the function call\n",
    "train_record_fname, val_record_fname, negative_record_fname, label_map_pbtxt_fname = set_tfrecord_variables('/kaggle/working')\n",
    "\n",
    "print(\"Train Record File:\", train_record_fname)\n",
    "print(\"Validation Record File:\", val_record_fname)\n",
    "print(\"Negative Samples Record File:\", negative_record_fname)\n",
    "print(\"Label Map File:\", label_map_pbtxt_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317f62ee",
   "metadata": {
    "id": "eGEUZYAMEZ6f",
    "papermill": {
     "duration": 0.03193,
     "end_time": "2025-04-01T19:02:41.178651",
     "exception": false,
     "start_time": "2025-04-01T19:02:41.146721",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 3.&nbsp;Training Configuration and Labels File Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763fb507",
   "metadata": {
    "id": "I2MAcgJ53STW",
    "papermill": {
     "duration": 0.031747,
     "end_time": "2025-04-01T19:02:41.242558",
     "exception": false,
     "start_time": "2025-04-01T19:02:41.210811",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Download the pre-trained Limelight Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37458675",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T19:02:41.348416Z",
     "iopub.status.busy": "2025-04-01T19:02:41.348126Z",
     "iopub.status.idle": "2025-04-01T19:02:42.759160Z",
     "shell.execute_reply": "2025-04-01T19:02:42.757961Z"
    },
    "id": "gN0EUEa3e5Un",
    "papermill": {
     "duration": 1.446684,
     "end_time": "2025-04-01T19:02:42.760919",
     "exception": false,
     "start_time": "2025-04-01T19:02:41.314235",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root\n",
      "/kaggle/working/models/mymodel\n",
      "--2025-04-01 19:02:41--  https://downloads.limelightvision.io/models/limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz\r\n",
      "Resolving downloads.limelightvision.io (downloads.limelightvision.io)... 52.84.162.6, 52.84.162.60, 52.84.162.104, ...\r\n",
      "Connecting to downloads.limelightvision.io (downloads.limelightvision.io)|52.84.162.6|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 46042990 (44M) [application/x-gzip]\r\n",
      "Saving to: ‘limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz’\r\n",
      "\r\n",
      "limelight_ssd_mobil 100%[===================>]  43.91M   177MB/s    in 0.2s    \r\n",
      "\r\n",
      "2025-04-01 19:02:41 (177 MB/s) - ‘limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz’ saved [46042990/46042990]\r\n",
      "\r\n",
      "--2025-04-01 19:02:42--  https://downloads.limelightvision.io/models/limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.config\r\n",
      "Resolving downloads.limelightvision.io (downloads.limelightvision.io)... 52.84.162.60, 52.84.162.6, 52.84.162.104, ...\r\n",
      "Connecting to downloads.limelightvision.io (downloads.limelightvision.io)|52.84.162.60|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 4681 (4.6K) [binary/octet-stream]\r\n",
      "Saving to: ‘limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.config’\r\n",
      "\r\n",
      "limelight_ssd_mobil 100%[===================>]   4.57K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2025-04-01 19:02:42 (261 MB/s) - ‘limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.config’ saved [4681/4681]\r\n",
      "\r\n",
      "/root\n"
     ]
    }
   ],
   "source": [
    "chosen_model = 'ssd-mobilenet-v2'\n",
    "MODELS_CONFIG = {\n",
    "    'ssd-mobilenet-v2': {\n",
    "        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n",
    "        'base_pipeline_file': 'limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'limelight_ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',\n",
    "    },\n",
    "}\n",
    "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
    "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
    "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\n",
    "\n",
    "# Create \"mymodel\" folder for pre-trained weights and configuration files\n",
    "%cd ~\n",
    "%mkdir {HOMEFOLDER}models/mymodel/\n",
    "%cd {HOMEFOLDER}models/mymodel/\n",
    "%pwd\n",
    "\n",
    "# Download pre-trained model weights\n",
    "import tarfile\n",
    "download_tar = 'https://downloads.limelightvision.io/models/' + pretrained_checkpoint\n",
    "!wget {download_tar}\n",
    "tar = tarfile.open(pretrained_checkpoint)\n",
    "tar.extractall()\n",
    "tar.close()\n",
    "\n",
    "# Download training configuration file for model\n",
    "download_config = 'https://downloads.limelightvision.io/models/' + base_pipeline_file\n",
    "!wget {download_config}\n",
    "%cd ~\n",
    "\n",
    "# Set training parameters for the model\n",
    "num_steps = 40000\n",
    "checkpoint_every = 2000\n",
    "batch_size = 16\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cc9dcf",
   "metadata": {
    "id": "XMbr89qqgTVW",
    "papermill": {
     "duration": 0.040844,
     "end_time": "2025-04-01T19:02:42.843612",
     "exception": false,
     "start_time": "2025-04-01T19:02:42.802768",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Generate Labels File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b8b5d9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T19:02:42.913760Z",
     "iopub.status.busy": "2025-04-01T19:02:42.913445Z",
     "iopub.status.idle": "2025-04-01T19:02:45.728467Z",
     "shell.execute_reply": "2025-04-01T19:02:45.727539Z"
    },
    "id": "DDyH_i3MgP1D",
    "papermill": {
     "duration": 2.851289,
     "end_time": "2025-04-01T19:02:45.729769",
     "exception": false,
     "start_time": "2025-04-01T19:02:42.878480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total classes: 3\n",
      "['blue sample', 'red sample', 'yellow sample']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set file locations and get number of classes for config file\n",
    "pipeline_fname = HOMEFOLDER+'models/mymodel/' + base_pipeline_file\n",
    "fine_tune_checkpoint = HOMEFOLDER+'models/mymodel/' + model_name + '/checkpoint/ckpt-0'\n",
    "\n",
    "def get_num_classes(pbtxt_fname):\n",
    "    from object_detection.utils import label_map_util\n",
    "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
    "    categories = label_map_util.convert_label_map_to_categories(\n",
    "        label_map, max_num_classes=90, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "    return len(category_index.keys())\n",
    "\n",
    "def get_classes(pbtxt_fname):\n",
    "    from object_detection.utils import label_map_util\n",
    "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
    "    categories = label_map_util.convert_label_map_to_categories(\n",
    "        label_map, max_num_classes=90, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "\n",
    "    class_names = [category['name'] for category in category_index.values()]\n",
    "    return class_names\n",
    "\n",
    "def create_label_file(filename, labels):\n",
    "    with open(filename, 'w') as file:\n",
    "        for label in labels:\n",
    "            file.write(label + '\\n')\n",
    "\n",
    "\n",
    "num_classes = get_num_classes(label_map_pbtxt_fname)\n",
    "classes = get_classes(label_map_pbtxt_fname)\n",
    "\n",
    "print('Total classes:', num_classes)\n",
    "print(classes)\n",
    "\n",
    "\n",
    "#Generate labels file\n",
    "create_label_file(HOMEFOLDER + \"limelight_neural_detector_labels.txt\", classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad37498",
   "metadata": {
    "id": "cwPyaIAXxyKu",
    "papermill": {
     "duration": 0.033023,
     "end_time": "2025-04-01T19:02:45.796579",
     "exception": false,
     "start_time": "2025-04-01T19:02:45.763556",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Modify the base Limelight Model Configuration File\n",
    "\n",
    "Augmentation Options: https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ee0795b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T19:02:45.865984Z",
     "iopub.status.busy": "2025-04-01T19:02:45.865374Z",
     "iopub.status.idle": "2025-04-01T19:02:45.875905Z",
     "shell.execute_reply": "2025-04-01T19:02:45.875034Z"
    },
    "id": "5eA5ht3_yukT",
    "papermill": {
     "duration": 0.04674,
     "end_time": "2025-04-01T19:02:45.877313",
     "exception": false,
     "start_time": "2025-04-01T19:02:45.830573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing custom configuration file\n",
      " \n",
      "/kaggle/working/training_progress/\n"
     ]
    }
   ],
   "source": [
    "# Create custom configuration file by writing the dataset, model checkpoint, and training parameters into the base pipeline file\n",
    "import re\n",
    "\n",
    "print('writing custom configuration file')\n",
    "\n",
    "\n",
    "\n",
    "with open(pipeline_fname) as f:\n",
    "    s = f.read()\n",
    "with open('pipeline_file.config', 'w') as f:\n",
    "\n",
    "    # Set fine_tune_checkpoint path\n",
    "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
    "\n",
    "    # Set tfrecord files for train and test datasets\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(val_record_fname), s)\n",
    "    s = re.sub(\n",
    "        'input_path: \"{}\"'.format(train_record_fname),\n",
    "        'input_path: \"{}\"\\n      input_path: \"{}\"'.format(train_record_fname, negative_record_fname),\n",
    "        s)\n",
    "\n",
    "    # Set label_map_path\n",
    "    s = re.sub(\n",
    "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n",
    "\n",
    "    # Set batch_size\n",
    "    s = re.sub('batch_size: [0-9]+',\n",
    "               'batch_size: {}'.format(batch_size), s)\n",
    "\n",
    "    # Set training steps, num_steps\n",
    "    s = re.sub('num_steps: [0-9]+',\n",
    "               'num_steps: {}'.format(num_steps), s)\n",
    "\n",
    "    # Set number of classes num_classes\n",
    "    s = re.sub('checkpoint_every_n: [0-9]+',\n",
    "               'num_classes: {}'.format(num_classes), s)\n",
    "\n",
    "    # Change fine-tune checkpoint type from \"classification\" to \"detection\"\n",
    "    s = re.sub(\n",
    "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
    "\n",
    "    # If using ssd-mobilenet-v2, reduce learning rate\n",
    "    if chosen_model == 'ssd-mobilenet-v2':\n",
    "      s = re.sub('learning_rate_base: .8',\n",
    "                 'learning_rate_base: .004', s)\n",
    "\n",
    "      s = re.sub('warmup_learning_rate: 0.13333',\n",
    "                 'warmup_learning_rate: .0016666', s)\n",
    "\n",
    "    # If using efficientdet-d0, use fixed_shape_resizer instead of keep_aspect_ratio_resizer (because it isn't supported by TFLite)\n",
    "    if chosen_model == 'efficientdet-d0':\n",
    "      s = re.sub('keep_aspect_ratio_resizer', 'fixed_shape_resizer', s)\n",
    "      s = re.sub('pad_to_max_dimension: true', '', s)\n",
    "      s = re.sub('min_dimension', 'height', s)\n",
    "      s = re.sub('max_dimension', 'width', s)\n",
    "\n",
    "    f.write(s)\n",
    "\n",
    "# (Optional) Display the custom configuration file's contents\n",
    "# !cat pipeline_file.config\n",
    "# Set the path to the custom config file and the directory to store training checkpoints in\n",
    "pipeline_file = 'pipeline_file.config'\n",
    "model_dir = HOMEFOLDER+'training_progress/'\n",
    "print(\" \")\n",
    "print(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9a7d8a",
   "metadata": {
    "id": "-19zML6oEO7l",
    "papermill": {
     "duration": 0.03256,
     "end_time": "2025-04-01T19:02:45.943456",
     "exception": false,
     "start_time": "2025-04-01T19:02:45.910896",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 4.&nbsp;Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a095f0",
   "metadata": {
    "id": "XxPj_QV43qD5",
    "papermill": {
     "duration": 0.033444,
     "end_time": "2025-04-01T19:02:46.010161",
     "exception": false,
     "start_time": "2025-04-01T19:02:45.976717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Once training starts, come back and click the refresh button within the tensorboard window to check training progress.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c0e599b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T19:02:46.077345Z",
     "iopub.status.busy": "2025-04-01T19:02:46.077040Z",
     "iopub.status.idle": "2025-04-01T19:02:51.140834Z",
     "shell.execute_reply": "2025-04-01T19:02:51.140055Z"
    },
    "id": "TI9iCCxoNlAL",
    "papermill": {
     "duration": 5.099227,
     "end_time": "2025-04-01T19:02:51.142241",
     "exception": false,
     "start_time": "2025-04-01T19:02:46.043014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        (async () => {\n",
       "            const url = new URL(await google.colab.kernel.proxyPort(6006, {'cache': true}));\n",
       "            url.searchParams.set('tensorboardColab', 'true');\n",
       "            const iframe = document.createElement('iframe');\n",
       "            iframe.src = url;\n",
       "            iframe.setAttribute('width', '100%');\n",
       "            iframe.setAttribute('height', '800');\n",
       "            iframe.setAttribute('frameborder', 0);\n",
       "            document.body.appendChild(iframe);\n",
       "        })();\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir '/kaggle/working/training_progress/train'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4e7cb1",
   "metadata": {
    "id": "ejo07C1zXHzY",
    "papermill": {
     "duration": 0.033026,
     "end_time": "2025-04-01T19:02:51.209480",
     "exception": false,
     "start_time": "2025-04-01T19:02:51.176454",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Fix TF 2.15 breaking changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ab76fc26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T19:02:51.276377Z",
     "iopub.status.busy": "2025-04-01T19:02:51.276067Z",
     "iopub.status.idle": "2025-04-01T19:02:54.697531Z",
     "shell.execute_reply": "2025-04-01T19:02:54.696446Z"
    },
    "id": "k6OTOB6r-tIj",
    "papermill": {
     "duration": 3.456828,
     "end_time": "2025-04-01T19:02:54.699192",
     "exception": false,
     "start_time": "2025-04-01T19:02:51.242364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tf_slim in /usr/local/lib/python3.10/dist-packages (1.1.0)\r\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf_slim) (1.4.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install tf_slim --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d814244",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T19:02:54.767988Z",
     "iopub.status.busy": "2025-04-01T19:02:54.767679Z",
     "iopub.status.idle": "2025-04-01T19:02:54.773884Z",
     "shell.execute_reply": "2025-04-01T19:02:54.773261Z"
    },
    "id": "Ltvi224axv3Y",
    "papermill": {
     "duration": 0.04151,
     "end_time": "2025-04-01T19:02:54.775151",
     "exception": false,
     "start_time": "2025-04-01T19:02:54.733641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File /usr/local/lib/python3.10/dist-packages/tf_slim/data/tfexample_decoder.py fixed.\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import re\n",
    "\n",
    "original_path = '/usr/local/lib/python3.10/dist-packages/tf_slim/data/tfexample_decoder.py'\n",
    "with open(original_path, 'r') as file:\n",
    "  content = file.read()\n",
    "  content = re.sub(r'import abc', 'import tensorflow as tf\\n\\nimport abc', content)\n",
    "  content = re.sub(r'control_flow_ops.case', 'tf.case', content)\n",
    "  content = re.sub(r'control_flow_ops.cond', 'tf.compat.v1.cond', content)\n",
    "with open(original_path, 'w') as file:\n",
    "  file.write(content)\n",
    "\n",
    "print(f\"File {original_path} fixed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f8f850",
   "metadata": {
    "id": "AjqYo9r9ffVx",
    "papermill": {
     "duration": 0.032836,
     "end_time": "2025-04-01T19:02:54.841085",
     "exception": false,
     "start_time": "2025-04-01T19:02:54.808249",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba74867e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T19:02:54.907476Z",
     "iopub.status.busy": "2025-04-01T19:02:54.907254Z",
     "iopub.status.idle": "2025-04-01T20:15:43.332059Z",
     "shell.execute_reply": "2025-04-01T20:15:43.330877Z"
    },
    "id": "tQTfZChVzzpZ",
    "papermill": {
     "duration": 4368.460015,
     "end_time": "2025-04-01T20:15:43.333779",
     "exception": false,
     "start_time": "2025-04-01T19:02:54.873764",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-01 19:02:55.575282: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2025-04-01 19:02:55.575334: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2025-04-01 19:02:55.576808: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "W0401 19:02:59.517235 134477283476608 deprecation.py:50] From /kaggle/working/models/research/object_detection/model_main_tf2.py:100: _CollectiveAllReduceStrategyExperimental.__init__ (from tensorflow.python.distribute.collective_all_reduce_strategy) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "use distribute.MultiWorkerMirroredStrategy instead\r\n",
      "I0401 19:02:59.621837 134477283476608 mirrored_strategy.py:423] Using MirroredStrategy with devices ('/device:GPU:0',)\r\n",
      "I0401 19:02:59.622101 134477283476608 collective_all_reduce_strategy.py:446] Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:GPU:0',), communication = CommunicationImplementation.AUTO\r\n",
      "I0401 19:02:59.625559 134477283476608 config_util.py:552] Maybe overwriting train_steps: 40000\r\n",
      "I0401 19:02:59.625716 134477283476608 config_util.py:552] Maybe overwriting use_bfloat16: False\r\n",
      "W0401 19:02:59.667007 134477283476608 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "rename to distribute_datasets_from_function\r\n",
      "I0401 19:02:59.673624 134477283476608 dataset_builder.py:162] Reading unweighted datasets: ['/kaggle/working/train/Samples.tfrecord', '/kaggle/working/negative/blank.tfrecord']\r\n",
      "I0401 19:02:59.673786 134477283476608 dataset_builder.py:79] Reading record datasets for input file: ['/kaggle/working/train/Samples.tfrecord', '/kaggle/working/negative/blank.tfrecord']\r\n",
      "I0401 19:02:59.673861 134477283476608 dataset_builder.py:80] Number of filenames to read: 2\r\n",
      "W0401 19:02:59.673921 134477283476608 dataset_builder.py:86] num_readers has been reduced to 2 to match input file shards.\r\n",
      "W0401 19:02:59.680477 134477283476608 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\r\n",
      "W0401 19:02:59.698690 134477283476608 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Use `tf.data.Dataset.map()\r\n",
      "W0401 19:03:05.538565 134477283476608 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\r\n",
      "W0401 19:03:08.421533 134477283476608 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\r\n",
      "W0401 19:03:10.963346 134477283476608 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py:1260: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\r\n",
      "Instructions for updating:\r\n",
      "Use `tf.cast` instead.\r\n",
      "/usr/local/lib/python3.10/dist-packages/keras/src/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\r\n",
      "  warnings.warn(\r\n",
      "I0401 19:03:18.766853 134471852480064 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\r\n",
      "I0401 19:03:20.389583 134471852480064 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\r\n",
      "I0401 19:03:20.389872 134471852480064 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\r\n",
      "I0401 19:03:20.390000 134471852480064 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\r\n",
      "I0401 19:03:20.390116 134471852480064 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\r\n",
      "I0401 19:03:20.390211 134471852480064 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\r\n",
      "I0401 19:03:20.390300 134471852480064 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\r\n",
      "I0401 19:03:27.451449 134471852480064 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\r\n",
      "I0401 19:03:40.221045 134472892667456 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\r\n",
      "I0401 19:03:47.202347 134472892667456 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\r\n",
      "I0401 19:03:53.308820 134472892667456 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\r\n",
      "I0401 19:03:59.718380 134472892667456 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\r\n",
      "I0401 19:04:25.254538 134477283476608 model_lib_v2.py:705] Step 100 per-step time 0.463s\r\n",
      "I0401 19:04:25.254919 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.38124594,\r\n",
      " 'Loss/localization_loss': 0.253047,\r\n",
      " 'Loss/regularization_loss': 0.088077106,\r\n",
      " 'Loss/total_loss': 0.7223701,\r\n",
      " 'learning_rate': 0.00178327}\r\n",
      "I0401 19:04:35.912778 134477283476608 model_lib_v2.py:705] Step 200 per-step time 0.107s\r\n",
      "I0401 19:04:35.913098 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.18344744,\r\n",
      " 'Loss/localization_loss': 0.13583186,\r\n",
      " 'Loss/regularization_loss': 0.08807763,\r\n",
      " 'Loss/total_loss': 0.40735695,\r\n",
      " 'learning_rate': 0.0018999401}\r\n",
      "I0401 19:04:46.547338 134477283476608 model_lib_v2.py:705] Step 300 per-step time 0.106s\r\n",
      "I0401 19:04:46.547757 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.17922945,\r\n",
      " 'Loss/localization_loss': 0.12840538,\r\n",
      " 'Loss/regularization_loss': 0.08807272,\r\n",
      " 'Loss/total_loss': 0.39570755,\r\n",
      " 'learning_rate': 0.00201661}\r\n",
      "I0401 19:04:57.301389 134477283476608 model_lib_v2.py:705] Step 400 per-step time 0.108s\r\n",
      "I0401 19:04:57.301748 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.18437299,\r\n",
      " 'Loss/localization_loss': 0.08862859,\r\n",
      " 'Loss/regularization_loss': 0.088065825,\r\n",
      " 'Loss/total_loss': 0.3610674,\r\n",
      " 'learning_rate': 0.00213328}\r\n",
      "I0401 19:05:08.004010 134477283476608 model_lib_v2.py:705] Step 500 per-step time 0.107s\r\n",
      "I0401 19:05:08.004344 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.14883864,\r\n",
      " 'Loss/localization_loss': 0.06933139,\r\n",
      " 'Loss/regularization_loss': 0.088058755,\r\n",
      " 'Loss/total_loss': 0.3062288,\r\n",
      " 'learning_rate': 0.00224995}\r\n",
      "I0401 19:05:18.731200 134477283476608 model_lib_v2.py:705] Step 600 per-step time 0.107s\r\n",
      "I0401 19:05:18.731554 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.14410765,\r\n",
      " 'Loss/localization_loss': 0.08596196,\r\n",
      " 'Loss/regularization_loss': 0.0880491,\r\n",
      " 'Loss/total_loss': 0.3181187,\r\n",
      " 'learning_rate': 0.00236662}\r\n",
      "I0401 19:05:29.458221 134477283476608 model_lib_v2.py:705] Step 700 per-step time 0.107s\r\n",
      "I0401 19:05:29.458538 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.1282924,\r\n",
      " 'Loss/localization_loss': 0.05316405,\r\n",
      " 'Loss/regularization_loss': 0.088038646,\r\n",
      " 'Loss/total_loss': 0.2694951,\r\n",
      " 'learning_rate': 0.0024832902}\r\n",
      "I0401 19:05:40.094114 134477283476608 model_lib_v2.py:705] Step 800 per-step time 0.106s\r\n",
      "I0401 19:05:40.094417 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.15006287,\r\n",
      " 'Loss/localization_loss': 0.07520975,\r\n",
      " 'Loss/regularization_loss': 0.08802748,\r\n",
      " 'Loss/total_loss': 0.3133001,\r\n",
      " 'learning_rate': 0.0025999602}\r\n",
      "I0401 19:05:50.729615 134477283476608 model_lib_v2.py:705] Step 900 per-step time 0.106s\r\n",
      "I0401 19:05:50.729933 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.11545115,\r\n",
      " 'Loss/localization_loss': 0.031856522,\r\n",
      " 'Loss/regularization_loss': 0.088015616,\r\n",
      " 'Loss/total_loss': 0.23532328,\r\n",
      " 'learning_rate': 0.0027166302}\r\n",
      "I0401 19:06:01.485345 134477283476608 model_lib_v2.py:705] Step 1000 per-step time 0.108s\r\n",
      "I0401 19:06:01.485669 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.15783499,\r\n",
      " 'Loss/localization_loss': 0.062112074,\r\n",
      " 'Loss/regularization_loss': 0.088002674,\r\n",
      " 'Loss/total_loss': 0.30794975,\r\n",
      " 'learning_rate': 0.0028333003}\r\n",
      "I0401 19:06:12.151326 134477283476608 model_lib_v2.py:705] Step 1100 per-step time 0.107s\r\n",
      "I0401 19:06:12.151638 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.1288102,\r\n",
      " 'Loss/localization_loss': 0.04375503,\r\n",
      " 'Loss/regularization_loss': 0.087989286,\r\n",
      " 'Loss/total_loss': 0.2605545,\r\n",
      " 'learning_rate': 0.0029499703}\r\n",
      "I0401 19:06:23.010810 134477283476608 model_lib_v2.py:705] Step 1200 per-step time 0.109s\r\n",
      "I0401 19:06:23.011156 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07160423,\r\n",
      " 'Loss/localization_loss': 0.029408516,\r\n",
      " 'Loss/regularization_loss': 0.087974705,\r\n",
      " 'Loss/total_loss': 0.18898745,\r\n",
      " 'learning_rate': 0.0030666403}\r\n",
      "I0401 19:06:33.709594 134477283476608 model_lib_v2.py:705] Step 1300 per-step time 0.107s\r\n",
      "I0401 19:06:33.709960 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.22500148,\r\n",
      " 'Loss/localization_loss': 0.106642276,\r\n",
      " 'Loss/regularization_loss': 0.087960415,\r\n",
      " 'Loss/total_loss': 0.41960418,\r\n",
      " 'learning_rate': 0.0031833102}\r\n",
      "I0401 19:06:44.472222 134477283476608 model_lib_v2.py:705] Step 1400 per-step time 0.108s\r\n",
      "I0401 19:06:44.472541 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.117947765,\r\n",
      " 'Loss/localization_loss': 0.06950328,\r\n",
      " 'Loss/regularization_loss': 0.08794604,\r\n",
      " 'Loss/total_loss': 0.27539706,\r\n",
      " 'learning_rate': 0.0032999802}\r\n",
      "I0401 19:06:55.125806 134477283476608 model_lib_v2.py:705] Step 1500 per-step time 0.107s\r\n",
      "I0401 19:06:55.126176 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.10399995,\r\n",
      " 'Loss/localization_loss': 0.028036442,\r\n",
      " 'Loss/regularization_loss': 0.08792936,\r\n",
      " 'Loss/total_loss': 0.21996576,\r\n",
      " 'learning_rate': 0.0034166502}\r\n",
      "I0401 19:07:05.818465 134477283476608 model_lib_v2.py:705] Step 1600 per-step time 0.107s\r\n",
      "I0401 19:07:05.818787 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.088788755,\r\n",
      " 'Loss/localization_loss': 0.036918562,\r\n",
      " 'Loss/regularization_loss': 0.087913275,\r\n",
      " 'Loss/total_loss': 0.21362059,\r\n",
      " 'learning_rate': 0.0035333203}\r\n",
      "I0401 19:07:16.546702 134477283476608 model_lib_v2.py:705] Step 1700 per-step time 0.107s\r\n",
      "I0401 19:07:16.547103 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.08997731,\r\n",
      " 'Loss/localization_loss': 0.04593683,\r\n",
      " 'Loss/regularization_loss': 0.08789487,\r\n",
      " 'Loss/total_loss': 0.22380902,\r\n",
      " 'learning_rate': 0.00364999}\r\n",
      "I0401 19:07:27.204516 134477283476608 model_lib_v2.py:705] Step 1800 per-step time 0.107s\r\n",
      "I0401 19:07:27.204859 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05281266,\r\n",
      " 'Loss/localization_loss': 0.017406518,\r\n",
      " 'Loss/regularization_loss': 0.08787606,\r\n",
      " 'Loss/total_loss': 0.15809524,\r\n",
      " 'learning_rate': 0.00376666}\r\n",
      "I0401 19:07:37.917283 134477283476608 model_lib_v2.py:705] Step 1900 per-step time 0.107s\r\n",
      "I0401 19:07:37.917578 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.14983916,\r\n",
      " 'Loss/localization_loss': 0.03454556,\r\n",
      " 'Loss/regularization_loss': 0.08785702,\r\n",
      " 'Loss/total_loss': 0.27224174,\r\n",
      " 'learning_rate': 0.0038833302}\r\n",
      "I0401 19:07:48.541702 134477283476608 model_lib_v2.py:705] Step 2000 per-step time 0.106s\r\n",
      "I0401 19:07:48.542036 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07119241,\r\n",
      " 'Loss/localization_loss': 0.020856984,\r\n",
      " 'Loss/regularization_loss': 0.087838344,\r\n",
      " 'Loss/total_loss': 0.17988774,\r\n",
      " 'learning_rate': 0.004}\r\n",
      "I0401 19:07:59.930161 134477283476608 model_lib_v2.py:705] Step 2100 per-step time 0.114s\r\n",
      "I0401 19:07:59.930513 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.11033756,\r\n",
      " 'Loss/localization_loss': 0.0907121,\r\n",
      " 'Loss/regularization_loss': 0.08781962,\r\n",
      " 'Loss/total_loss': 0.28886926,\r\n",
      " 'learning_rate': 0.0039999573}\r\n",
      "I0401 19:08:10.658306 134477283476608 model_lib_v2.py:705] Step 2200 per-step time 0.107s\r\n",
      "I0401 19:08:10.658651 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.084191754,\r\n",
      " 'Loss/localization_loss': 0.03569623,\r\n",
      " 'Loss/regularization_loss': 0.087799564,\r\n",
      " 'Loss/total_loss': 0.20768756,\r\n",
      " 'learning_rate': 0.003999829}\r\n",
      "I0401 19:08:21.331926 134477283476608 model_lib_v2.py:705] Step 2300 per-step time 0.107s\r\n",
      "I0401 19:08:21.332242 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.16520073,\r\n",
      " 'Loss/localization_loss': 0.049573682,\r\n",
      " 'Loss/regularization_loss': 0.087780915,\r\n",
      " 'Loss/total_loss': 0.30255532,\r\n",
      " 'learning_rate': 0.0039996146}\r\n",
      "I0401 19:08:31.965219 134477283476608 model_lib_v2.py:705] Step 2400 per-step time 0.106s\r\n",
      "I0401 19:08:31.965545 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07917047,\r\n",
      " 'Loss/localization_loss': 0.024489379,\r\n",
      " 'Loss/regularization_loss': 0.08776186,\r\n",
      " 'Loss/total_loss': 0.19142172,\r\n",
      " 'learning_rate': 0.003999315}\r\n",
      "I0401 19:08:42.708155 134477283476608 model_lib_v2.py:705] Step 2500 per-step time 0.107s\r\n",
      "I0401 19:08:42.708495 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.0784015,\r\n",
      " 'Loss/localization_loss': 0.017879473,\r\n",
      " 'Loss/regularization_loss': 0.08774187,\r\n",
      " 'Loss/total_loss': 0.18402284,\r\n",
      " 'learning_rate': 0.003998929}\r\n",
      "I0401 19:08:53.383224 134477283476608 model_lib_v2.py:705] Step 2600 per-step time 0.107s\r\n",
      "I0401 19:08:53.383547 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.06840762,\r\n",
      " 'Loss/localization_loss': 0.017654944,\r\n",
      " 'Loss/regularization_loss': 0.08772141,\r\n",
      " 'Loss/total_loss': 0.17378397,\r\n",
      " 'learning_rate': 0.003998458}\r\n",
      "I0401 19:09:04.036097 134477283476608 model_lib_v2.py:705] Step 2700 per-step time 0.107s\r\n",
      "I0401 19:09:04.036420 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.0655903,\r\n",
      " 'Loss/localization_loss': 0.025340855,\r\n",
      " 'Loss/regularization_loss': 0.08769995,\r\n",
      " 'Loss/total_loss': 0.1786311,\r\n",
      " 'learning_rate': 0.0039979015}\r\n",
      "I0401 19:09:14.796179 134477283476608 model_lib_v2.py:705] Step 2800 per-step time 0.108s\r\n",
      "I0401 19:09:14.796513 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.075092286,\r\n",
      " 'Loss/localization_loss': 0.024309693,\r\n",
      " 'Loss/regularization_loss': 0.08768028,\r\n",
      " 'Loss/total_loss': 0.18708226,\r\n",
      " 'learning_rate': 0.0039972593}\r\n",
      "I0401 19:09:25.493017 134477283476608 model_lib_v2.py:705] Step 2900 per-step time 0.107s\r\n",
      "I0401 19:09:25.493348 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.17063406,\r\n",
      " 'Loss/localization_loss': 0.05140191,\r\n",
      " 'Loss/regularization_loss': 0.08765954,\r\n",
      " 'Loss/total_loss': 0.3096955,\r\n",
      " 'learning_rate': 0.0039965315}\r\n",
      "I0401 19:09:36.123226 134477283476608 model_lib_v2.py:705] Step 3000 per-step time 0.106s\r\n",
      "I0401 19:09:36.123580 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.122030124,\r\n",
      " 'Loss/localization_loss': 0.036778282,\r\n",
      " 'Loss/regularization_loss': 0.08764369,\r\n",
      " 'Loss/total_loss': 0.2464521,\r\n",
      " 'learning_rate': 0.003995718}\r\n",
      "I0401 19:09:46.866524 134477283476608 model_lib_v2.py:705] Step 3100 per-step time 0.107s\r\n",
      "I0401 19:09:46.866865 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.23976077,\r\n",
      " 'Loss/localization_loss': 0.028139398,\r\n",
      " 'Loss/regularization_loss': 0.087622784,\r\n",
      " 'Loss/total_loss': 0.35552296,\r\n",
      " 'learning_rate': 0.0039948192}\r\n",
      "I0401 19:09:57.548742 134477283476608 model_lib_v2.py:705] Step 3200 per-step time 0.107s\r\n",
      "I0401 19:09:57.549091 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07650325,\r\n",
      " 'Loss/localization_loss': 0.012653364,\r\n",
      " 'Loss/regularization_loss': 0.087601274,\r\n",
      " 'Loss/total_loss': 0.17675789,\r\n",
      " 'learning_rate': 0.003993835}\r\n",
      "I0401 19:10:08.179983 134477283476608 model_lib_v2.py:705] Step 3300 per-step time 0.106s\r\n",
      "I0401 19:10:08.180317 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.06837902,\r\n",
      " 'Loss/localization_loss': 0.020701073,\r\n",
      " 'Loss/regularization_loss': 0.087581135,\r\n",
      " 'Loss/total_loss': 0.17666122,\r\n",
      " 'learning_rate': 0.003992765}\r\n",
      "I0401 19:10:18.866310 134477283476608 model_lib_v2.py:705] Step 3400 per-step time 0.107s\r\n",
      "I0401 19:10:18.866611 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.18569775,\r\n",
      " 'Loss/localization_loss': 0.011490072,\r\n",
      " 'Loss/regularization_loss': 0.08755975,\r\n",
      " 'Loss/total_loss': 0.28474757,\r\n",
      " 'learning_rate': 0.00399161}\r\n",
      "I0401 19:10:29.517647 134477283476608 model_lib_v2.py:705] Step 3500 per-step time 0.107s\r\n",
      "I0401 19:10:29.517991 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.10418624,\r\n",
      " 'Loss/localization_loss': 0.018396705,\r\n",
      " 'Loss/regularization_loss': 0.08753885,\r\n",
      " 'Loss/total_loss': 0.2101218,\r\n",
      " 'learning_rate': 0.0039903694}\r\n",
      "I0401 19:10:40.125086 134477283476608 model_lib_v2.py:705] Step 3600 per-step time 0.106s\r\n",
      "I0401 19:10:40.125395 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.09638819,\r\n",
      " 'Loss/localization_loss': 0.03920245,\r\n",
      " 'Loss/regularization_loss': 0.08751828,\r\n",
      " 'Loss/total_loss': 0.22310892,\r\n",
      " 'learning_rate': 0.003989044}\r\n",
      "I0401 19:10:50.838858 134477283476608 model_lib_v2.py:705] Step 3700 per-step time 0.107s\r\n",
      "I0401 19:10:50.839258 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.060329504,\r\n",
      " 'Loss/localization_loss': 0.030771581,\r\n",
      " 'Loss/regularization_loss': 0.08749854,\r\n",
      " 'Loss/total_loss': 0.17859963,\r\n",
      " 'learning_rate': 0.003987633}\r\n",
      "I0401 19:11:01.488080 134477283476608 model_lib_v2.py:705] Step 3800 per-step time 0.106s\r\n",
      "I0401 19:11:01.488407 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07414927,\r\n",
      " 'Loss/localization_loss': 0.018133268,\r\n",
      " 'Loss/regularization_loss': 0.08747664,\r\n",
      " 'Loss/total_loss': 0.17975917,\r\n",
      " 'learning_rate': 0.003986137}\r\n",
      "I0401 19:11:12.137011 134477283476608 model_lib_v2.py:705] Step 3900 per-step time 0.106s\r\n",
      "I0401 19:11:12.137341 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07893013,\r\n",
      " 'Loss/localization_loss': 0.011016217,\r\n",
      " 'Loss/regularization_loss': 0.08745613,\r\n",
      " 'Loss/total_loss': 0.17740248,\r\n",
      " 'learning_rate': 0.003984556}\r\n",
      "I0401 19:11:22.876515 134477283476608 model_lib_v2.py:705] Step 4000 per-step time 0.107s\r\n",
      "I0401 19:11:22.876851 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.11501072,\r\n",
      " 'Loss/localization_loss': 0.03861034,\r\n",
      " 'Loss/regularization_loss': 0.08743472,\r\n",
      " 'Loss/total_loss': 0.24105579,\r\n",
      " 'learning_rate': 0.00398289}\r\n",
      "I0401 19:11:34.229920 134477283476608 model_lib_v2.py:705] Step 4100 per-step time 0.114s\r\n",
      "I0401 19:11:34.230247 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.09991274,\r\n",
      " 'Loss/localization_loss': 0.04949698,\r\n",
      " 'Loss/regularization_loss': 0.0874134,\r\n",
      " 'Loss/total_loss': 0.23682311,\r\n",
      " 'learning_rate': 0.003981139}\r\n",
      "I0401 19:11:44.908382 134477283476608 model_lib_v2.py:705] Step 4200 per-step time 0.107s\r\n",
      "I0401 19:11:44.908700 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.06723847,\r\n",
      " 'Loss/localization_loss': 0.016309096,\r\n",
      " 'Loss/regularization_loss': 0.08739219,\r\n",
      " 'Loss/total_loss': 0.17093976,\r\n",
      " 'learning_rate': 0.003979303}\r\n",
      "I0401 19:11:55.671544 134477283476608 model_lib_v2.py:705] Step 4300 per-step time 0.108s\r\n",
      "I0401 19:11:55.671921 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.115766294,\r\n",
      " 'Loss/localization_loss': 0.026056416,\r\n",
      " 'Loss/regularization_loss': 0.08737201,\r\n",
      " 'Loss/total_loss': 0.22919473,\r\n",
      " 'learning_rate': 0.0039773826}\r\n",
      "I0401 19:12:06.380656 134477283476608 model_lib_v2.py:705] Step 4400 per-step time 0.107s\r\n",
      "I0401 19:12:06.380991 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.04948635,\r\n",
      " 'Loss/localization_loss': 0.008204078,\r\n",
      " 'Loss/regularization_loss': 0.087351665,\r\n",
      " 'Loss/total_loss': 0.14504209,\r\n",
      " 'learning_rate': 0.003975377}\r\n",
      "I0401 19:12:16.993725 134477283476608 model_lib_v2.py:705] Step 4500 per-step time 0.106s\r\n",
      "I0401 19:12:16.994083 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.09987572,\r\n",
      " 'Loss/localization_loss': 0.021733597,\r\n",
      " 'Loss/regularization_loss': 0.08733043,\r\n",
      " 'Loss/total_loss': 0.20893975,\r\n",
      " 'learning_rate': 0.0039732866}\r\n",
      "I0401 19:12:27.695698 134477283476608 model_lib_v2.py:705] Step 4600 per-step time 0.107s\r\n",
      "I0401 19:12:27.696042 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.069621325,\r\n",
      " 'Loss/localization_loss': 0.017655054,\r\n",
      " 'Loss/regularization_loss': 0.08730862,\r\n",
      " 'Loss/total_loss': 0.174585,\r\n",
      " 'learning_rate': 0.0039711124}\r\n",
      "I0401 19:12:38.257393 134477283476608 model_lib_v2.py:705] Step 4700 per-step time 0.106s\r\n",
      "I0401 19:12:38.257700 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.08945586,\r\n",
      " 'Loss/localization_loss': 0.041404564,\r\n",
      " 'Loss/regularization_loss': 0.08728966,\r\n",
      " 'Loss/total_loss': 0.21815008,\r\n",
      " 'learning_rate': 0.003968853}\r\n",
      "I0401 19:12:48.918441 134477283476608 model_lib_v2.py:705] Step 4800 per-step time 0.107s\r\n",
      "I0401 19:12:48.918785 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.102884635,\r\n",
      " 'Loss/localization_loss': 0.016094206,\r\n",
      " 'Loss/regularization_loss': 0.08726722,\r\n",
      " 'Loss/total_loss': 0.20624606,\r\n",
      " 'learning_rate': 0.00396651}\r\n",
      "I0401 19:12:59.637440 134477283476608 model_lib_v2.py:705] Step 4900 per-step time 0.107s\r\n",
      "I0401 19:12:59.637796 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.09036227,\r\n",
      " 'Loss/localization_loss': 0.02232184,\r\n",
      " 'Loss/regularization_loss': 0.08724558,\r\n",
      " 'Loss/total_loss': 0.1999297,\r\n",
      " 'learning_rate': 0.0039640823}\r\n",
      "I0401 19:13:10.308109 134477283476608 model_lib_v2.py:705] Step 5000 per-step time 0.107s\r\n",
      "I0401 19:13:10.308434 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.055273384,\r\n",
      " 'Loss/localization_loss': 0.019311676,\r\n",
      " 'Loss/regularization_loss': 0.087225445,\r\n",
      " 'Loss/total_loss': 0.1618105,\r\n",
      " 'learning_rate': 0.0039615706}\r\n",
      "I0401 19:13:20.958282 134477283476608 model_lib_v2.py:705] Step 5100 per-step time 0.107s\r\n",
      "I0401 19:13:20.958590 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.081374586,\r\n",
      " 'Loss/localization_loss': 0.017401287,\r\n",
      " 'Loss/regularization_loss': 0.087203026,\r\n",
      " 'Loss/total_loss': 0.18597889,\r\n",
      " 'learning_rate': 0.003958975}\r\n",
      "I0401 19:13:31.686448 134477283476608 model_lib_v2.py:705] Step 5200 per-step time 0.107s\r\n",
      "I0401 19:13:31.686762 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07650364,\r\n",
      " 'Loss/localization_loss': 0.0154046295,\r\n",
      " 'Loss/regularization_loss': 0.08718147,\r\n",
      " 'Loss/total_loss': 0.17908974,\r\n",
      " 'learning_rate': 0.0039562955}\r\n",
      "I0401 19:13:42.320724 134477283476608 model_lib_v2.py:705] Step 5300 per-step time 0.106s\r\n",
      "I0401 19:13:42.321072 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.054645546,\r\n",
      " 'Loss/localization_loss': 0.01742147,\r\n",
      " 'Loss/regularization_loss': 0.08716265,\r\n",
      " 'Loss/total_loss': 0.15922967,\r\n",
      " 'learning_rate': 0.003953532}\r\n",
      "I0401 19:13:52.959438 134477283476608 model_lib_v2.py:705] Step 5400 per-step time 0.106s\r\n",
      "I0401 19:13:52.959827 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.046789,\r\n",
      " 'Loss/localization_loss': 0.017874325,\r\n",
      " 'Loss/regularization_loss': 0.087141715,\r\n",
      " 'Loss/total_loss': 0.15180504,\r\n",
      " 'learning_rate': 0.003950685}\r\n",
      "I0401 19:14:03.679719 134477283476608 model_lib_v2.py:705] Step 5500 per-step time 0.107s\r\n",
      "I0401 19:14:03.680111 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.13529615,\r\n",
      " 'Loss/localization_loss': 0.044362593,\r\n",
      " 'Loss/regularization_loss': 0.087120555,\r\n",
      " 'Loss/total_loss': 0.2667793,\r\n",
      " 'learning_rate': 0.003947754}\r\n",
      "I0401 19:14:14.304360 134477283476608 model_lib_v2.py:705] Step 5600 per-step time 0.106s\r\n",
      "I0401 19:14:14.304714 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.095575295,\r\n",
      " 'Loss/localization_loss': 0.032459654,\r\n",
      " 'Loss/regularization_loss': 0.087098435,\r\n",
      " 'Loss/total_loss': 0.21513338,\r\n",
      " 'learning_rate': 0.00394474}\r\n",
      "I0401 19:14:24.972681 134477283476608 model_lib_v2.py:705] Step 5700 per-step time 0.107s\r\n",
      "I0401 19:14:24.973031 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05130067,\r\n",
      " 'Loss/localization_loss': 0.014674327,\r\n",
      " 'Loss/regularization_loss': 0.08707893,\r\n",
      " 'Loss/total_loss': 0.15305392,\r\n",
      " 'learning_rate': 0.0039416426}\r\n",
      "I0401 19:14:35.643756 134477283476608 model_lib_v2.py:705] Step 5800 per-step time 0.107s\r\n",
      "I0401 19:14:35.644107 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.058359906,\r\n",
      " 'Loss/localization_loss': 0.016468683,\r\n",
      " 'Loss/regularization_loss': 0.08705668,\r\n",
      " 'Loss/total_loss': 0.16188526,\r\n",
      " 'learning_rate': 0.003938462}\r\n",
      "I0401 19:14:46.319692 134477283476608 model_lib_v2.py:705] Step 5900 per-step time 0.107s\r\n",
      "I0401 19:14:46.320038 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05957277,\r\n",
      " 'Loss/localization_loss': 0.008727667,\r\n",
      " 'Loss/regularization_loss': 0.08703477,\r\n",
      " 'Loss/total_loss': 0.15533522,\r\n",
      " 'learning_rate': 0.0039351983}\r\n",
      "I0401 19:14:56.975055 134477283476608 model_lib_v2.py:705] Step 6000 per-step time 0.107s\r\n",
      "I0401 19:14:56.975378 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.040436998,\r\n",
      " 'Loss/localization_loss': 0.01982487,\r\n",
      " 'Loss/regularization_loss': 0.08701332,\r\n",
      " 'Loss/total_loss': 0.14727518,\r\n",
      " 'learning_rate': 0.0039318516}\r\n",
      "I0401 19:15:08.469908 134477283476608 model_lib_v2.py:705] Step 6100 per-step time 0.115s\r\n",
      "I0401 19:15:08.470277 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.076977246,\r\n",
      " 'Loss/localization_loss': 0.009699418,\r\n",
      " 'Loss/regularization_loss': 0.08699205,\r\n",
      " 'Loss/total_loss': 0.17366871,\r\n",
      " 'learning_rate': 0.0039284225}\r\n",
      "I0401 19:15:19.192770 134477283476608 model_lib_v2.py:705] Step 6200 per-step time 0.107s\r\n",
      "I0401 19:15:19.193150 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.070034154,\r\n",
      " 'Loss/localization_loss': 0.01625486,\r\n",
      " 'Loss/regularization_loss': 0.08697046,\r\n",
      " 'Loss/total_loss': 0.17325948,\r\n",
      " 'learning_rate': 0.003924911}\r\n",
      "I0401 19:15:29.923954 134477283476608 model_lib_v2.py:705] Step 6300 per-step time 0.107s\r\n",
      "I0401 19:15:29.924261 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.061890848,\r\n",
      " 'Loss/localization_loss': 0.008959277,\r\n",
      " 'Loss/regularization_loss': 0.08694824,\r\n",
      " 'Loss/total_loss': 0.15779836,\r\n",
      " 'learning_rate': 0.0039213165}\r\n",
      "I0401 19:15:40.636307 134477283476608 model_lib_v2.py:705] Step 6400 per-step time 0.107s\r\n",
      "I0401 19:15:40.636626 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07669064,\r\n",
      " 'Loss/localization_loss': 0.017287204,\r\n",
      " 'Loss/regularization_loss': 0.08692674,\r\n",
      " 'Loss/total_loss': 0.18090458,\r\n",
      " 'learning_rate': 0.0039176396}\r\n",
      "I0401 19:15:51.268725 134477283476608 model_lib_v2.py:705] Step 6500 per-step time 0.106s\r\n",
      "I0401 19:15:51.269066 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.08025572,\r\n",
      " 'Loss/localization_loss': 0.013515634,\r\n",
      " 'Loss/regularization_loss': 0.0869049,\r\n",
      " 'Loss/total_loss': 0.18067625,\r\n",
      " 'learning_rate': 0.003913881}\r\n",
      "I0401 19:16:01.998910 134477283476608 model_lib_v2.py:705] Step 6600 per-step time 0.107s\r\n",
      "I0401 19:16:01.999334 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.068297,\r\n",
      " 'Loss/localization_loss': 0.01986529,\r\n",
      " 'Loss/regularization_loss': 0.08688315,\r\n",
      " 'Loss/total_loss': 0.17504543,\r\n",
      " 'learning_rate': 0.00391004}\r\n",
      "I0401 19:16:12.717869 134477283476608 model_lib_v2.py:705] Step 6700 per-step time 0.107s\r\n",
      "I0401 19:16:12.718201 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.06583925,\r\n",
      " 'Loss/localization_loss': 0.025103943,\r\n",
      " 'Loss/regularization_loss': 0.086860605,\r\n",
      " 'Loss/total_loss': 0.1778038,\r\n",
      " 'learning_rate': 0.0039061175}\r\n",
      "I0401 19:16:23.365564 134477283476608 model_lib_v2.py:705] Step 6800 per-step time 0.106s\r\n",
      "I0401 19:16:23.365889 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.094302565,\r\n",
      " 'Loss/localization_loss': 0.05241531,\r\n",
      " 'Loss/regularization_loss': 0.08683986,\r\n",
      " 'Loss/total_loss': 0.23355773,\r\n",
      " 'learning_rate': 0.003902113}\r\n",
      "I0401 19:16:34.087015 134477283476608 model_lib_v2.py:705] Step 6900 per-step time 0.107s\r\n",
      "I0401 19:16:34.087354 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.051362712,\r\n",
      " 'Loss/localization_loss': 0.0132723795,\r\n",
      " 'Loss/regularization_loss': 0.08681965,\r\n",
      " 'Loss/total_loss': 0.15145475,\r\n",
      " 'learning_rate': 0.0038980276}\r\n",
      "I0401 19:16:44.769879 134477283476608 model_lib_v2.py:705] Step 7000 per-step time 0.107s\r\n",
      "I0401 19:16:44.770267 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.06440272,\r\n",
      " 'Loss/localization_loss': 0.032514166,\r\n",
      " 'Loss/regularization_loss': 0.08679711,\r\n",
      " 'Loss/total_loss': 0.183714,\r\n",
      " 'learning_rate': 0.0038938606}\r\n",
      "I0401 19:16:55.377367 134477283476608 model_lib_v2.py:705] Step 7100 per-step time 0.106s\r\n",
      "I0401 19:16:55.377703 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.12856025,\r\n",
      " 'Loss/localization_loss': 0.028848872,\r\n",
      " 'Loss/regularization_loss': 0.08677661,\r\n",
      " 'Loss/total_loss': 0.24418572,\r\n",
      " 'learning_rate': 0.0038896124}\r\n",
      "I0401 19:17:06.031220 134477283476608 model_lib_v2.py:705] Step 7200 per-step time 0.107s\r\n",
      "I0401 19:17:06.031561 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.0737341,\r\n",
      " 'Loss/localization_loss': 0.014251134,\r\n",
      " 'Loss/regularization_loss': 0.0867568,\r\n",
      " 'Loss/total_loss': 0.17474204,\r\n",
      " 'learning_rate': 0.0038852831}\r\n",
      "I0401 19:17:16.731605 134477283476608 model_lib_v2.py:705] Step 7300 per-step time 0.107s\r\n",
      "I0401 19:17:16.732011 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.054410703,\r\n",
      " 'Loss/localization_loss': 0.017131291,\r\n",
      " 'Loss/regularization_loss': 0.086734906,\r\n",
      " 'Loss/total_loss': 0.1582769,\r\n",
      " 'learning_rate': 0.0038808733}\r\n",
      "I0401 19:17:27.385431 134477283476608 model_lib_v2.py:705] Step 7400 per-step time 0.107s\r\n",
      "I0401 19:17:27.385770 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.103233054,\r\n",
      " 'Loss/localization_loss': 0.021443771,\r\n",
      " 'Loss/regularization_loss': 0.08671345,\r\n",
      " 'Loss/total_loss': 0.21139027,\r\n",
      " 'learning_rate': 0.003876383}\r\n",
      "I0401 19:17:38.135025 134477283476608 model_lib_v2.py:705] Step 7500 per-step time 0.107s\r\n",
      "I0401 19:17:38.135373 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.10036977,\r\n",
      " 'Loss/localization_loss': 0.0228118,\r\n",
      " 'Loss/regularization_loss': 0.086692035,\r\n",
      " 'Loss/total_loss': 0.2098736,\r\n",
      " 'learning_rate': 0.003871812}\r\n",
      "I0401 19:17:48.770121 134477283476608 model_lib_v2.py:705] Step 7600 per-step time 0.106s\r\n",
      "I0401 19:17:48.770478 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.10040322,\r\n",
      " 'Loss/localization_loss': 0.010033683,\r\n",
      " 'Loss/regularization_loss': 0.08666991,\r\n",
      " 'Loss/total_loss': 0.19710681,\r\n",
      " 'learning_rate': 0.003867161}\r\n",
      "I0401 19:17:59.495365 134477283476608 model_lib_v2.py:705] Step 7700 per-step time 0.107s\r\n",
      "I0401 19:17:59.495688 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.10291907,\r\n",
      " 'Loss/localization_loss': 0.007511264,\r\n",
      " 'Loss/regularization_loss': 0.08664921,\r\n",
      " 'Loss/total_loss': 0.19707954,\r\n",
      " 'learning_rate': 0.00386243}\r\n",
      "I0401 19:18:10.207616 134477283476608 model_lib_v2.py:705] Step 7800 per-step time 0.107s\r\n",
      "I0401 19:18:10.208038 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.054730687,\r\n",
      " 'Loss/localization_loss': 0.020840654,\r\n",
      " 'Loss/regularization_loss': 0.086627334,\r\n",
      " 'Loss/total_loss': 0.16219868,\r\n",
      " 'learning_rate': 0.0038576191}\r\n",
      "I0401 19:18:20.841117 134477283476608 model_lib_v2.py:705] Step 7900 per-step time 0.106s\r\n",
      "I0401 19:18:20.841406 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.13173483,\r\n",
      " 'Loss/localization_loss': 0.009168195,\r\n",
      " 'Loss/regularization_loss': 0.0866066,\r\n",
      " 'Loss/total_loss': 0.22750962,\r\n",
      " 'learning_rate': 0.003852729}\r\n",
      "I0401 19:18:31.503425 134477283476608 model_lib_v2.py:705] Step 8000 per-step time 0.107s\r\n",
      "I0401 19:18:31.503745 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.06768157,\r\n",
      " 'Loss/localization_loss': 0.025410565,\r\n",
      " 'Loss/regularization_loss': 0.086585045,\r\n",
      " 'Loss/total_loss': 0.17967719,\r\n",
      " 'learning_rate': 0.0038477594}\r\n",
      "I0401 19:18:42.910783 134477283476608 model_lib_v2.py:705] Step 8100 per-step time 0.114s\r\n",
      "I0401 19:18:42.911154 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.044764034,\r\n",
      " 'Loss/localization_loss': 0.007426437,\r\n",
      " 'Loss/regularization_loss': 0.08656332,\r\n",
      " 'Loss/total_loss': 0.13875379,\r\n",
      " 'learning_rate': 0.0038427105}\r\n",
      "I0401 19:18:53.555496 134477283476608 model_lib_v2.py:705] Step 8200 per-step time 0.106s\r\n",
      "I0401 19:18:53.555812 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.06073315,\r\n",
      " 'Loss/localization_loss': 0.01867878,\r\n",
      " 'Loss/regularization_loss': 0.08654274,\r\n",
      " 'Loss/total_loss': 0.16595468,\r\n",
      " 'learning_rate': 0.0038375824}\r\n",
      "I0401 19:19:04.277990 134477283476608 model_lib_v2.py:705] Step 8300 per-step time 0.107s\r\n",
      "I0401 19:19:04.278327 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.048201043,\r\n",
      " 'Loss/localization_loss': 0.016011633,\r\n",
      " 'Loss/regularization_loss': 0.08652122,\r\n",
      " 'Loss/total_loss': 0.1507339,\r\n",
      " 'learning_rate': 0.003832376}\r\n",
      "I0401 19:19:14.987551 134477283476608 model_lib_v2.py:705] Step 8400 per-step time 0.107s\r\n",
      "I0401 19:19:14.987859 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.045375973,\r\n",
      " 'Loss/localization_loss': 0.01049824,\r\n",
      " 'Loss/regularization_loss': 0.086498864,\r\n",
      " 'Loss/total_loss': 0.14237309,\r\n",
      " 'learning_rate': 0.003827091}\r\n",
      "I0401 19:19:25.606594 134477283476608 model_lib_v2.py:705] Step 8500 per-step time 0.106s\r\n",
      "I0401 19:19:25.606898 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.04067888,\r\n",
      " 'Loss/localization_loss': 0.00875659,\r\n",
      " 'Loss/regularization_loss': 0.08647831,\r\n",
      " 'Loss/total_loss': 0.13591377,\r\n",
      " 'learning_rate': 0.0038217278}\r\n",
      "I0401 19:19:36.266493 134477283476608 model_lib_v2.py:705] Step 8600 per-step time 0.107s\r\n",
      "I0401 19:19:36.266831 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.08169274,\r\n",
      " 'Loss/localization_loss': 0.022024304,\r\n",
      " 'Loss/regularization_loss': 0.08645678,\r\n",
      " 'Loss/total_loss': 0.19017383,\r\n",
      " 'learning_rate': 0.0038162866}\r\n",
      "I0401 19:19:46.975887 134477283476608 model_lib_v2.py:705] Step 8700 per-step time 0.107s\r\n",
      "I0401 19:19:46.976228 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.075644575,\r\n",
      " 'Loss/localization_loss': 0.030688776,\r\n",
      " 'Loss/regularization_loss': 0.08643596,\r\n",
      " 'Loss/total_loss': 0.19276932,\r\n",
      " 'learning_rate': 0.0038107673}\r\n",
      "I0401 19:19:57.613783 134477283476608 model_lib_v2.py:705] Step 8800 per-step time 0.106s\r\n",
      "I0401 19:19:57.614133 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.09634563,\r\n",
      " 'Loss/localization_loss': 0.07787077,\r\n",
      " 'Loss/regularization_loss': 0.086418055,\r\n",
      " 'Loss/total_loss': 0.26063445,\r\n",
      " 'learning_rate': 0.0038051708}\r\n",
      "I0401 19:20:08.349750 134477283476608 model_lib_v2.py:705] Step 8900 per-step time 0.107s\r\n",
      "I0401 19:20:08.350104 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07634164,\r\n",
      " 'Loss/localization_loss': 0.013084832,\r\n",
      " 'Loss/regularization_loss': 0.086396456,\r\n",
      " 'Loss/total_loss': 0.17582291,\r\n",
      " 'learning_rate': 0.003799497}\r\n",
      "I0401 19:20:19.035435 134477283476608 model_lib_v2.py:705] Step 9000 per-step time 0.107s\r\n",
      "I0401 19:20:19.035752 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07114896,\r\n",
      " 'Loss/localization_loss': 0.021838572,\r\n",
      " 'Loss/regularization_loss': 0.086375,\r\n",
      " 'Loss/total_loss': 0.17936254,\r\n",
      " 'learning_rate': 0.0037937458}\r\n",
      "I0401 19:20:29.702714 134477283476608 model_lib_v2.py:705] Step 9100 per-step time 0.107s\r\n",
      "I0401 19:20:29.703084 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.0411578,\r\n",
      " 'Loss/localization_loss': 0.013992386,\r\n",
      " 'Loss/regularization_loss': 0.08635345,\r\n",
      " 'Loss/total_loss': 0.14150363,\r\n",
      " 'learning_rate': 0.0037879178}\r\n",
      "I0401 19:20:40.351161 134477283476608 model_lib_v2.py:705] Step 9200 per-step time 0.106s\r\n",
      "I0401 19:20:40.351496 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.06599899,\r\n",
      " 'Loss/localization_loss': 0.020141456,\r\n",
      " 'Loss/regularization_loss': 0.08633294,\r\n",
      " 'Loss/total_loss': 0.17247337,\r\n",
      " 'learning_rate': 0.0037820132}\r\n",
      "I0401 19:20:51.060269 134477283476608 model_lib_v2.py:705] Step 9300 per-step time 0.107s\r\n",
      "I0401 19:20:51.060577 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05600818,\r\n",
      " 'Loss/localization_loss': 0.019140637,\r\n",
      " 'Loss/regularization_loss': 0.08631186,\r\n",
      " 'Loss/total_loss': 0.16146067,\r\n",
      " 'learning_rate': 0.0037760325}\r\n",
      "I0401 19:21:01.712554 134477283476608 model_lib_v2.py:705] Step 9400 per-step time 0.107s\r\n",
      "I0401 19:21:01.712900 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.082615,\r\n",
      " 'Loss/localization_loss': 0.007570663,\r\n",
      " 'Loss/regularization_loss': 0.0862899,\r\n",
      " 'Loss/total_loss': 0.17647555,\r\n",
      " 'learning_rate': 0.0037699754}\r\n",
      "I0401 19:21:12.323737 134477283476608 model_lib_v2.py:705] Step 9500 per-step time 0.106s\r\n",
      "I0401 19:21:12.324071 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.16375574,\r\n",
      " 'Loss/localization_loss': 0.05898775,\r\n",
      " 'Loss/regularization_loss': 0.08626939,\r\n",
      " 'Loss/total_loss': 0.3090129,\r\n",
      " 'learning_rate': 0.0037638429}\r\n",
      "I0401 19:21:23.028011 134477283476608 model_lib_v2.py:705] Step 9600 per-step time 0.107s\r\n",
      "I0401 19:21:23.028313 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.060860783,\r\n",
      " 'Loss/localization_loss': 0.008388307,\r\n",
      " 'Loss/regularization_loss': 0.086248465,\r\n",
      " 'Loss/total_loss': 0.15549755,\r\n",
      " 'learning_rate': 0.0037576344}\r\n",
      "I0401 19:21:33.713658 134477283476608 model_lib_v2.py:705] Step 9700 per-step time 0.107s\r\n",
      "I0401 19:21:33.714048 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.04375,\r\n",
      " 'Loss/localization_loss': 0.008910818,\r\n",
      " 'Loss/regularization_loss': 0.08622619,\r\n",
      " 'Loss/total_loss': 0.138887,\r\n",
      " 'learning_rate': 0.0037513508}\r\n",
      "I0401 19:21:44.391864 134477283476608 model_lib_v2.py:705] Step 9800 per-step time 0.107s\r\n",
      "I0401 19:21:44.392198 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.11679296,\r\n",
      " 'Loss/localization_loss': 0.009449372,\r\n",
      " 'Loss/regularization_loss': 0.08620602,\r\n",
      " 'Loss/total_loss': 0.21244836,\r\n",
      " 'learning_rate': 0.0037449922}\r\n",
      "I0401 19:21:55.109525 134477283476608 model_lib_v2.py:705] Step 9900 per-step time 0.107s\r\n",
      "I0401 19:21:55.109901 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07532749,\r\n",
      " 'Loss/localization_loss': 0.014345701,\r\n",
      " 'Loss/regularization_loss': 0.086185016,\r\n",
      " 'Loss/total_loss': 0.1758582,\r\n",
      " 'learning_rate': 0.0037385589}\r\n",
      "I0401 19:22:05.801732 134477283476608 model_lib_v2.py:705] Step 10000 per-step time 0.107s\r\n",
      "I0401 19:22:05.802067 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.055519048,\r\n",
      " 'Loss/localization_loss': 0.00809991,\r\n",
      " 'Loss/regularization_loss': 0.08616352,\r\n",
      " 'Loss/total_loss': 0.14978248,\r\n",
      " 'learning_rate': 0.003732051}\r\n",
      "I0401 19:22:17.197718 134477283476608 model_lib_v2.py:705] Step 10100 per-step time 0.114s\r\n",
      "I0401 19:22:17.198059 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05757887,\r\n",
      " 'Loss/localization_loss': 0.017603938,\r\n",
      " 'Loss/regularization_loss': 0.08614265,\r\n",
      " 'Loss/total_loss': 0.16132545,\r\n",
      " 'learning_rate': 0.003725469}\r\n",
      "I0401 19:22:27.915832 134477283476608 model_lib_v2.py:705] Step 10200 per-step time 0.107s\r\n",
      "I0401 19:22:27.916186 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.046777353,\r\n",
      " 'Loss/localization_loss': 0.008989201,\r\n",
      " 'Loss/regularization_loss': 0.08612183,\r\n",
      " 'Loss/total_loss': 0.14188838,\r\n",
      " 'learning_rate': 0.0037188132}\r\n",
      "I0401 19:22:38.592308 134477283476608 model_lib_v2.py:705] Step 10300 per-step time 0.107s\r\n",
      "I0401 19:22:38.592656 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.077171996,\r\n",
      " 'Loss/localization_loss': 0.025252827,\r\n",
      " 'Loss/regularization_loss': 0.08610128,\r\n",
      " 'Loss/total_loss': 0.1885261,\r\n",
      " 'learning_rate': 0.0037120834}\r\n",
      "I0401 19:22:49.243468 134477283476608 model_lib_v2.py:705] Step 10400 per-step time 0.107s\r\n",
      "I0401 19:22:49.243767 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.08449836,\r\n",
      " 'Loss/localization_loss': 0.021269802,\r\n",
      " 'Loss/regularization_loss': 0.08608093,\r\n",
      " 'Loss/total_loss': 0.19184908,\r\n",
      " 'learning_rate': 0.0037052804}\r\n",
      "I0401 19:23:00.028187 134477283476608 model_lib_v2.py:705] Step 10500 per-step time 0.108s\r\n",
      "I0401 19:23:00.028499 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.055000395,\r\n",
      " 'Loss/localization_loss': 0.013842267,\r\n",
      " 'Loss/regularization_loss': 0.08606091,\r\n",
      " 'Loss/total_loss': 0.15490358,\r\n",
      " 'learning_rate': 0.0036984044}\r\n",
      "I0401 19:23:10.667661 134477283476608 model_lib_v2.py:705] Step 10600 per-step time 0.106s\r\n",
      "I0401 19:23:10.668008 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.10854722,\r\n",
      " 'Loss/localization_loss': 0.03099641,\r\n",
      " 'Loss/regularization_loss': 0.08603909,\r\n",
      " 'Loss/total_loss': 0.22558272,\r\n",
      " 'learning_rate': 0.0036914558}\r\n",
      "I0401 19:23:21.324242 134477283476608 model_lib_v2.py:705] Step 10700 per-step time 0.107s\r\n",
      "I0401 19:23:21.324577 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.061187103,\r\n",
      " 'Loss/localization_loss': 0.010444369,\r\n",
      " 'Loss/regularization_loss': 0.086018644,\r\n",
      " 'Loss/total_loss': 0.15765011,\r\n",
      " 'learning_rate': 0.0036844346}\r\n",
      "I0401 19:23:31.991192 134477283476608 model_lib_v2.py:705] Step 10800 per-step time 0.107s\r\n",
      "I0401 19:23:31.991528 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.051284518,\r\n",
      " 'Loss/localization_loss': 0.013329086,\r\n",
      " 'Loss/regularization_loss': 0.08599862,\r\n",
      " 'Loss/total_loss': 0.15061222,\r\n",
      " 'learning_rate': 0.0036773412}\r\n",
      "I0401 19:23:42.770616 134477283476608 model_lib_v2.py:705] Step 10900 per-step time 0.108s\r\n",
      "I0401 19:23:42.771005 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05430131,\r\n",
      " 'Loss/localization_loss': 0.013530206,\r\n",
      " 'Loss/regularization_loss': 0.08597801,\r\n",
      " 'Loss/total_loss': 0.15380952,\r\n",
      " 'learning_rate': 0.0036701763}\r\n",
      "I0401 19:23:53.473780 134477283476608 model_lib_v2.py:705] Step 11000 per-step time 0.107s\r\n",
      "I0401 19:23:53.474127 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.049551804,\r\n",
      " 'Loss/localization_loss': 0.0076303976,\r\n",
      " 'Loss/regularization_loss': 0.08595745,\r\n",
      " 'Loss/total_loss': 0.14313966,\r\n",
      " 'learning_rate': 0.0036629394}\r\n",
      "I0401 19:24:04.266344 134477283476608 model_lib_v2.py:705] Step 11100 per-step time 0.108s\r\n",
      "I0401 19:24:04.266654 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.06038832,\r\n",
      " 'Loss/localization_loss': 0.016273886,\r\n",
      " 'Loss/regularization_loss': 0.08593569,\r\n",
      " 'Loss/total_loss': 0.1625979,\r\n",
      " 'learning_rate': 0.0036556316}\r\n",
      "I0401 19:24:14.945443 134477283476608 model_lib_v2.py:705] Step 11200 per-step time 0.107s\r\n",
      "I0401 19:24:14.945775 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.045013357,\r\n",
      " 'Loss/localization_loss': 0.014864785,\r\n",
      " 'Loss/regularization_loss': 0.08591444,\r\n",
      " 'Loss/total_loss': 0.14579257,\r\n",
      " 'learning_rate': 0.0036482527}\r\n",
      "I0401 19:24:25.572073 134477283476608 model_lib_v2.py:705] Step 11300 per-step time 0.106s\r\n",
      "I0401 19:24:25.572421 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.04314943,\r\n",
      " 'Loss/localization_loss': 0.014053032,\r\n",
      " 'Loss/regularization_loss': 0.08589459,\r\n",
      " 'Loss/total_loss': 0.14309706,\r\n",
      " 'learning_rate': 0.003640803}\r\n",
      "I0401 19:24:36.272103 134477283476608 model_lib_v2.py:705] Step 11400 per-step time 0.107s\r\n",
      "I0401 19:24:36.272440 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.056080367,\r\n",
      " 'Loss/localization_loss': 0.01149417,\r\n",
      " 'Loss/regularization_loss': 0.08587486,\r\n",
      " 'Loss/total_loss': 0.1534494,\r\n",
      " 'learning_rate': 0.0036332833}\r\n",
      "I0401 19:24:46.888073 134477283476608 model_lib_v2.py:705] Step 11500 per-step time 0.106s\r\n",
      "I0401 19:24:46.888406 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.0909391,\r\n",
      " 'Loss/localization_loss': 0.018564893,\r\n",
      " 'Loss/regularization_loss': 0.08585526,\r\n",
      " 'Loss/total_loss': 0.19535926,\r\n",
      " 'learning_rate': 0.0036256935}\r\n",
      "I0401 19:24:57.547501 134477283476608 model_lib_v2.py:705] Step 11600 per-step time 0.107s\r\n",
      "I0401 19:24:57.547845 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.047616355,\r\n",
      " 'Loss/localization_loss': 0.011472035,\r\n",
      " 'Loss/regularization_loss': 0.0858348,\r\n",
      " 'Loss/total_loss': 0.1449232,\r\n",
      " 'learning_rate': 0.003618034}\r\n",
      "I0401 19:25:08.280138 134477283476608 model_lib_v2.py:705] Step 11700 per-step time 0.107s\r\n",
      "I0401 19:25:08.280460 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.043472175,\r\n",
      " 'Loss/localization_loss': 0.016384142,\r\n",
      " 'Loss/regularization_loss': 0.085814096,\r\n",
      " 'Loss/total_loss': 0.14567041,\r\n",
      " 'learning_rate': 0.0036103055}\r\n",
      "I0401 19:25:18.990754 134477283476608 model_lib_v2.py:705] Step 11800 per-step time 0.107s\r\n",
      "I0401 19:25:18.991097 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.076575026,\r\n",
      " 'Loss/localization_loss': 0.06033765,\r\n",
      " 'Loss/regularization_loss': 0.08579296,\r\n",
      " 'Loss/total_loss': 0.22270563,\r\n",
      " 'learning_rate': 0.0036025078}\r\n",
      "I0401 19:25:29.660399 134477283476608 model_lib_v2.py:705] Step 11900 per-step time 0.107s\r\n",
      "I0401 19:25:29.660715 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.060997043,\r\n",
      " 'Loss/localization_loss': 0.0121506,\r\n",
      " 'Loss/regularization_loss': 0.08577219,\r\n",
      " 'Loss/total_loss': 0.15891983,\r\n",
      " 'learning_rate': 0.0035946413}\r\n",
      "I0401 19:25:40.414988 134477283476608 model_lib_v2.py:705] Step 12000 per-step time 0.108s\r\n",
      "I0401 19:25:40.415297 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.08207288,\r\n",
      " 'Loss/localization_loss': 0.01324287,\r\n",
      " 'Loss/regularization_loss': 0.08575124,\r\n",
      " 'Loss/total_loss': 0.18106699,\r\n",
      " 'learning_rate': 0.0035867067}\r\n",
      "I0401 19:25:51.756910 134477283476608 model_lib_v2.py:705] Step 12100 per-step time 0.113s\r\n",
      "I0401 19:25:51.757243 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07519958,\r\n",
      " 'Loss/localization_loss': 0.007637325,\r\n",
      " 'Loss/regularization_loss': 0.08573093,\r\n",
      " 'Loss/total_loss': 0.16856784,\r\n",
      " 'learning_rate': 0.0035787043}\r\n",
      "I0401 19:26:02.413739 134477283476608 model_lib_v2.py:705] Step 12200 per-step time 0.107s\r\n",
      "I0401 19:26:02.414096 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.058172572,\r\n",
      " 'Loss/localization_loss': 0.016269566,\r\n",
      " 'Loss/regularization_loss': 0.08570964,\r\n",
      " 'Loss/total_loss': 0.16015178,\r\n",
      " 'learning_rate': 0.0035706342}\r\n",
      "I0401 19:26:13.123843 134477283476608 model_lib_v2.py:705] Step 12300 per-step time 0.107s\r\n",
      "I0401 19:26:13.124181 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05355712,\r\n",
      " 'Loss/localization_loss': 0.006042884,\r\n",
      " 'Loss/regularization_loss': 0.08568865,\r\n",
      " 'Loss/total_loss': 0.14528865,\r\n",
      " 'learning_rate': 0.0035624965}\r\n",
      "I0401 19:26:23.817098 134477283476608 model_lib_v2.py:705] Step 12400 per-step time 0.107s\r\n",
      "I0401 19:26:23.817424 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.044148106,\r\n",
      " 'Loss/localization_loss': 0.0108848745,\r\n",
      " 'Loss/regularization_loss': 0.085668705,\r\n",
      " 'Loss/total_loss': 0.14070168,\r\n",
      " 'learning_rate': 0.003554292}\r\n",
      "I0401 19:26:34.416082 134477283476608 model_lib_v2.py:705] Step 12500 per-step time 0.106s\r\n",
      "I0401 19:26:34.416419 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.045213215,\r\n",
      " 'Loss/localization_loss': 0.0067546135,\r\n",
      " 'Loss/regularization_loss': 0.085648604,\r\n",
      " 'Loss/total_loss': 0.13761643,\r\n",
      " 'learning_rate': 0.0035460212}\r\n",
      "I0401 19:26:45.113328 134477283476608 model_lib_v2.py:705] Step 12600 per-step time 0.107s\r\n",
      "I0401 19:26:45.113623 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.079854004,\r\n",
      " 'Loss/localization_loss': 0.025344735,\r\n",
      " 'Loss/regularization_loss': 0.08562789,\r\n",
      " 'Loss/total_loss': 0.19082662,\r\n",
      " 'learning_rate': 0.003537684}\r\n",
      "I0401 19:26:55.852965 134477283476608 model_lib_v2.py:705] Step 12700 per-step time 0.107s\r\n",
      "I0401 19:26:55.853299 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.04313539,\r\n",
      " 'Loss/localization_loss': 0.009695875,\r\n",
      " 'Loss/regularization_loss': 0.08560666,\r\n",
      " 'Loss/total_loss': 0.13843793,\r\n",
      " 'learning_rate': 0.003529281}\r\n",
      "I0401 19:27:06.537728 134477283476608 model_lib_v2.py:705] Step 12800 per-step time 0.107s\r\n",
      "I0401 19:27:06.538074 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.043367922,\r\n",
      " 'Loss/localization_loss': 0.006691196,\r\n",
      " 'Loss/regularization_loss': 0.08558766,\r\n",
      " 'Loss/total_loss': 0.13564678,\r\n",
      " 'learning_rate': 0.0035208121}\r\n",
      "I0401 19:27:17.248775 134477283476608 model_lib_v2.py:705] Step 12900 per-step time 0.107s\r\n",
      "I0401 19:27:17.249117 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.049286466,\r\n",
      " 'Loss/localization_loss': 0.016114878,\r\n",
      " 'Loss/regularization_loss': 0.08556919,\r\n",
      " 'Loss/total_loss': 0.15097053,\r\n",
      " 'learning_rate': 0.0035122782}\r\n",
      "I0401 19:27:27.899355 134477283476608 model_lib_v2.py:705] Step 13000 per-step time 0.107s\r\n",
      "I0401 19:27:27.899692 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.065673046,\r\n",
      " 'Loss/localization_loss': 0.026877796,\r\n",
      " 'Loss/regularization_loss': 0.08554951,\r\n",
      " 'Loss/total_loss': 0.17810035,\r\n",
      " 'learning_rate': 0.00350368}\r\n",
      "I0401 19:27:38.582712 134477283476608 model_lib_v2.py:705] Step 13100 per-step time 0.107s\r\n",
      "I0401 19:27:38.583053 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.06886678,\r\n",
      " 'Loss/localization_loss': 0.017024606,\r\n",
      " 'Loss/regularization_loss': 0.08552882,\r\n",
      " 'Loss/total_loss': 0.17142022,\r\n",
      " 'learning_rate': 0.0034950168}\r\n",
      "I0401 19:27:49.322826 134477283476608 model_lib_v2.py:705] Step 13200 per-step time 0.107s\r\n",
      "I0401 19:27:49.323171 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.040186502,\r\n",
      " 'Loss/localization_loss': 0.007372115,\r\n",
      " 'Loss/regularization_loss': 0.08550821,\r\n",
      " 'Loss/total_loss': 0.13306683,\r\n",
      " 'learning_rate': 0.0034862896}\r\n",
      "I0401 19:28:00.001453 134477283476608 model_lib_v2.py:705] Step 13300 per-step time 0.107s\r\n",
      "I0401 19:28:00.001800 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.041288942,\r\n",
      " 'Loss/localization_loss': 0.017259598,\r\n",
      " 'Loss/regularization_loss': 0.085487664,\r\n",
      " 'Loss/total_loss': 0.1440362,\r\n",
      " 'learning_rate': 0.0034774991}\r\n",
      "I0401 19:28:10.688283 134477283476608 model_lib_v2.py:705] Step 13400 per-step time 0.107s\r\n",
      "I0401 19:28:10.688616 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07397256,\r\n",
      " 'Loss/localization_loss': 0.009360862,\r\n",
      " 'Loss/regularization_loss': 0.0854685,\r\n",
      " 'Loss/total_loss': 0.16880193,\r\n",
      " 'learning_rate': 0.0034686453}\r\n",
      "I0401 19:28:21.408192 134477283476608 model_lib_v2.py:705] Step 13500 per-step time 0.107s\r\n",
      "I0401 19:28:21.408509 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.06707688,\r\n",
      " 'Loss/localization_loss': 0.017993407,\r\n",
      " 'Loss/regularization_loss': 0.08544831,\r\n",
      " 'Loss/total_loss': 0.17051859,\r\n",
      " 'learning_rate': 0.0034597283}\r\n",
      "I0401 19:28:32.050725 134477283476608 model_lib_v2.py:705] Step 13600 per-step time 0.106s\r\n",
      "I0401 19:28:32.051069 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.065848894,\r\n",
      " 'Loss/localization_loss': 0.012227228,\r\n",
      " 'Loss/regularization_loss': 0.085428104,\r\n",
      " 'Loss/total_loss': 0.16350423,\r\n",
      " 'learning_rate': 0.0034507487}\r\n",
      "I0401 19:28:42.756938 134477283476608 model_lib_v2.py:705] Step 13700 per-step time 0.107s\r\n",
      "I0401 19:28:42.757276 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.06735594,\r\n",
      " 'Loss/localization_loss': 0.020262748,\r\n",
      " 'Loss/regularization_loss': 0.08541046,\r\n",
      " 'Loss/total_loss': 0.17302915,\r\n",
      " 'learning_rate': 0.0034417072}\r\n",
      "I0401 19:28:53.475559 134477283476608 model_lib_v2.py:705] Step 13800 per-step time 0.107s\r\n",
      "I0401 19:28:53.475885 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.050466068,\r\n",
      " 'Loss/localization_loss': 0.0117600905,\r\n",
      " 'Loss/regularization_loss': 0.08539109,\r\n",
      " 'Loss/total_loss': 0.14761725,\r\n",
      " 'learning_rate': 0.003432604}\r\n",
      "I0401 19:29:04.102003 134477283476608 model_lib_v2.py:705] Step 13900 per-step time 0.106s\r\n",
      "I0401 19:29:04.102331 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.064261325,\r\n",
      " 'Loss/localization_loss': 0.013076223,\r\n",
      " 'Loss/regularization_loss': 0.08537089,\r\n",
      " 'Loss/total_loss': 0.16270843,\r\n",
      " 'learning_rate': 0.0034234393}\r\n",
      "I0401 19:29:14.725790 134477283476608 model_lib_v2.py:705] Step 14000 per-step time 0.106s\r\n",
      "I0401 19:29:14.726143 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.043925278,\r\n",
      " 'Loss/localization_loss': 0.012510427,\r\n",
      " 'Loss/regularization_loss': 0.08535227,\r\n",
      " 'Loss/total_loss': 0.14178798,\r\n",
      " 'learning_rate': 0.003414214}\r\n",
      "I0401 19:29:26.081078 134477283476608 model_lib_v2.py:705] Step 14100 per-step time 0.114s\r\n",
      "I0401 19:29:26.081400 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.061503727,\r\n",
      " 'Loss/localization_loss': 0.00574807,\r\n",
      " 'Loss/regularization_loss': 0.08533155,\r\n",
      " 'Loss/total_loss': 0.15258335,\r\n",
      " 'learning_rate': 0.0034049274}\r\n",
      "I0401 19:29:36.725639 134477283476608 model_lib_v2.py:705] Step 14200 per-step time 0.106s\r\n",
      "I0401 19:29:36.726014 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.067081966,\r\n",
      " 'Loss/localization_loss': 0.01362408,\r\n",
      " 'Loss/regularization_loss': 0.085312285,\r\n",
      " 'Loss/total_loss': 0.16601834,\r\n",
      " 'learning_rate': 0.003395581}\r\n",
      "I0401 19:29:47.396865 134477283476608 model_lib_v2.py:705] Step 14300 per-step time 0.107s\r\n",
      "I0401 19:29:47.397191 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.082080625,\r\n",
      " 'Loss/localization_loss': 0.018274216,\r\n",
      " 'Loss/regularization_loss': 0.08529319,\r\n",
      " 'Loss/total_loss': 0.18564802,\r\n",
      " 'learning_rate': 0.0033861748}\r\n",
      "I0401 19:29:58.097680 134477283476608 model_lib_v2.py:705] Step 14400 per-step time 0.107s\r\n",
      "I0401 19:29:58.098044 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.051177107,\r\n",
      " 'Loss/localization_loss': 0.0059184916,\r\n",
      " 'Loss/regularization_loss': 0.0852734,\r\n",
      " 'Loss/total_loss': 0.142369,\r\n",
      " 'learning_rate': 0.003376709}\r\n",
      "I0401 19:30:08.808130 134477283476608 model_lib_v2.py:705] Step 14500 per-step time 0.107s\r\n",
      "I0401 19:30:08.808465 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05381956,\r\n",
      " 'Loss/localization_loss': 0.012858645,\r\n",
      " 'Loss/regularization_loss': 0.0852535,\r\n",
      " 'Loss/total_loss': 0.1519317,\r\n",
      " 'learning_rate': 0.003367185}\r\n",
      "I0401 19:30:19.464233 134477283476608 model_lib_v2.py:705] Step 14600 per-step time 0.107s\r\n",
      "I0401 19:30:19.464537 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.079241484,\r\n",
      " 'Loss/localization_loss': 0.0332165,\r\n",
      " 'Loss/regularization_loss': 0.08523419,\r\n",
      " 'Loss/total_loss': 0.19769217,\r\n",
      " 'learning_rate': 0.0033576016}\r\n",
      "I0401 19:30:30.201880 134477283476608 model_lib_v2.py:705] Step 14700 per-step time 0.107s\r\n",
      "I0401 19:30:30.202231 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.08725521,\r\n",
      " 'Loss/localization_loss': 0.030201497,\r\n",
      " 'Loss/regularization_loss': 0.08521446,\r\n",
      " 'Loss/total_loss': 0.20267117,\r\n",
      " 'learning_rate': 0.0033479603}\r\n",
      "I0401 19:30:40.908912 134477283476608 model_lib_v2.py:705] Step 14800 per-step time 0.107s\r\n",
      "I0401 19:30:40.909230 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.031783782,\r\n",
      " 'Loss/localization_loss': 0.005255433,\r\n",
      " 'Loss/regularization_loss': 0.08519481,\r\n",
      " 'Loss/total_loss': 0.122234024,\r\n",
      " 'learning_rate': 0.0033382613}\r\n",
      "I0401 19:30:51.537732 134477283476608 model_lib_v2.py:705] Step 14900 per-step time 0.106s\r\n",
      "I0401 19:30:51.538074 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.06277206,\r\n",
      " 'Loss/localization_loss': 0.013853451,\r\n",
      " 'Loss/regularization_loss': 0.08517578,\r\n",
      " 'Loss/total_loss': 0.1618013,\r\n",
      " 'learning_rate': 0.003328505}\r\n",
      "I0401 19:31:02.261549 134477283476608 model_lib_v2.py:705] Step 15000 per-step time 0.107s\r\n",
      "I0401 19:31:02.261877 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.15127242,\r\n",
      " 'Loss/localization_loss': 0.03279538,\r\n",
      " 'Loss/regularization_loss': 0.08515627,\r\n",
      " 'Loss/total_loss': 0.26922408,\r\n",
      " 'learning_rate': 0.0033186916}\r\n",
      "I0401 19:31:12.929906 134477283476608 model_lib_v2.py:705] Step 15100 per-step time 0.107s\r\n",
      "I0401 19:31:12.930256 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.13696285,\r\n",
      " 'Loss/localization_loss': 0.006797976,\r\n",
      " 'Loss/regularization_loss': 0.08513699,\r\n",
      " 'Loss/total_loss': 0.22889781,\r\n",
      " 'learning_rate': 0.0033088222}\r\n",
      "I0401 19:31:23.574643 134477283476608 model_lib_v2.py:705] Step 15200 per-step time 0.106s\r\n",
      "I0401 19:31:23.575025 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.04867447,\r\n",
      " 'Loss/localization_loss': 0.015472499,\r\n",
      " 'Loss/regularization_loss': 0.085118815,\r\n",
      " 'Loss/total_loss': 0.1492658,\r\n",
      " 'learning_rate': 0.0032988961}\r\n",
      "I0401 19:31:34.296815 134477283476608 model_lib_v2.py:705] Step 15300 per-step time 0.107s\r\n",
      "I0401 19:31:34.297160 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.04844367,\r\n",
      " 'Loss/localization_loss': 0.009793839,\r\n",
      " 'Loss/regularization_loss': 0.08510022,\r\n",
      " 'Loss/total_loss': 0.14333773,\r\n",
      " 'learning_rate': 0.003288915}\r\n",
      "I0401 19:31:44.975584 134477283476608 model_lib_v2.py:705] Step 15400 per-step time 0.107s\r\n",
      "I0401 19:31:44.975926 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.062729985,\r\n",
      " 'Loss/localization_loss': 0.008001704,\r\n",
      " 'Loss/regularization_loss': 0.08508126,\r\n",
      " 'Loss/total_loss': 0.15581295,\r\n",
      " 'learning_rate': 0.003278878}\r\n",
      "I0401 19:31:55.599370 134477283476608 model_lib_v2.py:705] Step 15500 per-step time 0.106s\r\n",
      "I0401 19:31:55.599711 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05413298,\r\n",
      " 'Loss/localization_loss': 0.012146794,\r\n",
      " 'Loss/regularization_loss': 0.08506357,\r\n",
      " 'Loss/total_loss': 0.15134335,\r\n",
      " 'learning_rate': 0.0032687865}\r\n",
      "I0401 19:32:06.364553 134477283476608 model_lib_v2.py:705] Step 15600 per-step time 0.108s\r\n",
      "I0401 19:32:06.364868 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.029990416,\r\n",
      " 'Loss/localization_loss': 0.00624253,\r\n",
      " 'Loss/regularization_loss': 0.08504465,\r\n",
      " 'Loss/total_loss': 0.1212776,\r\n",
      " 'learning_rate': 0.0032586409}\r\n",
      "I0401 19:32:17.061099 134477283476608 model_lib_v2.py:705] Step 15700 per-step time 0.107s\r\n",
      "I0401 19:32:17.061416 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.062533416,\r\n",
      " 'Loss/localization_loss': 0.020327993,\r\n",
      " 'Loss/regularization_loss': 0.085025415,\r\n",
      " 'Loss/total_loss': 0.16788682,\r\n",
      " 'learning_rate': 0.003248441}\r\n",
      "I0401 19:32:27.720185 134477283476608 model_lib_v2.py:705] Step 15800 per-step time 0.107s\r\n",
      "I0401 19:32:27.720504 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.06516592,\r\n",
      " 'Loss/localization_loss': 0.013778851,\r\n",
      " 'Loss/regularization_loss': 0.08500645,\r\n",
      " 'Loss/total_loss': 0.16395122,\r\n",
      " 'learning_rate': 0.0032381879}\r\n",
      "I0401 19:32:38.451600 134477283476608 model_lib_v2.py:705] Step 15900 per-step time 0.107s\r\n",
      "I0401 19:32:38.451939 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.042468105,\r\n",
      " 'Loss/localization_loss': 0.0074097095,\r\n",
      " 'Loss/regularization_loss': 0.08498834,\r\n",
      " 'Loss/total_loss': 0.13486615,\r\n",
      " 'learning_rate': 0.0032278819}\r\n",
      "I0401 19:32:49.027445 134477283476608 model_lib_v2.py:705] Step 16000 per-step time 0.106s\r\n",
      "I0401 19:32:49.027796 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.056053445,\r\n",
      " 'Loss/localization_loss': 0.0065882723,\r\n",
      " 'Loss/regularization_loss': 0.08497034,\r\n",
      " 'Loss/total_loss': 0.14761207,\r\n",
      " 'learning_rate': 0.003217523}\r\n",
      "I0401 19:33:00.338247 134477283476608 model_lib_v2.py:705] Step 16100 per-step time 0.113s\r\n",
      "I0401 19:33:00.338607 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.044701915,\r\n",
      " 'Loss/localization_loss': 0.007481077,\r\n",
      " 'Loss/regularization_loss': 0.08495313,\r\n",
      " 'Loss/total_loss': 0.13713612,\r\n",
      " 'learning_rate': 0.003207112}\r\n",
      "I0401 19:33:11.160975 134477283476608 model_lib_v2.py:705] Step 16200 per-step time 0.108s\r\n",
      "I0401 19:33:11.161339 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.073172726,\r\n",
      " 'Loss/localization_loss': 0.014903972,\r\n",
      " 'Loss/regularization_loss': 0.08493356,\r\n",
      " 'Loss/total_loss': 0.17301026,\r\n",
      " 'learning_rate': 0.0031966493}\r\n",
      "I0401 19:33:21.808877 134477283476608 model_lib_v2.py:705] Step 16300 per-step time 0.106s\r\n",
      "I0401 19:33:21.809201 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.04596086,\r\n",
      " 'Loss/localization_loss': 0.019940125,\r\n",
      " 'Loss/regularization_loss': 0.08491534,\r\n",
      " 'Loss/total_loss': 0.15081632,\r\n",
      " 'learning_rate': 0.0031861356}\r\n",
      "I0401 19:33:32.486206 134477283476608 model_lib_v2.py:705] Step 16400 per-step time 0.107s\r\n",
      "I0401 19:33:32.486520 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.06140024,\r\n",
      " 'Loss/localization_loss': 0.005071578,\r\n",
      " 'Loss/regularization_loss': 0.08489734,\r\n",
      " 'Loss/total_loss': 0.15136915,\r\n",
      " 'learning_rate': 0.0031755706}\r\n",
      "I0401 19:33:43.235958 134477283476608 model_lib_v2.py:705] Step 16500 per-step time 0.107s\r\n",
      "I0401 19:33:43.236312 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.056992285,\r\n",
      " 'Loss/localization_loss': 0.030838303,\r\n",
      " 'Loss/regularization_loss': 0.08487856,\r\n",
      " 'Loss/total_loss': 0.17270914,\r\n",
      " 'learning_rate': 0.0031649554}\r\n",
      "I0401 19:33:53.867142 134477283476608 model_lib_v2.py:705] Step 16600 per-step time 0.106s\r\n",
      "I0401 19:33:53.867472 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.065004714,\r\n",
      " 'Loss/localization_loss': 0.017521325,\r\n",
      " 'Loss/regularization_loss': 0.08486011,\r\n",
      " 'Loss/total_loss': 0.16738614,\r\n",
      " 'learning_rate': 0.0031542904}\r\n",
      "I0401 19:34:04.553438 134477283476608 model_lib_v2.py:705] Step 16700 per-step time 0.107s\r\n",
      "I0401 19:34:04.553797 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.11844956,\r\n",
      " 'Loss/localization_loss': 0.01431329,\r\n",
      " 'Loss/regularization_loss': 0.084841385,\r\n",
      " 'Loss/total_loss': 0.21760423,\r\n",
      " 'learning_rate': 0.003143576}\r\n",
      "I0401 19:34:15.316967 134477283476608 model_lib_v2.py:705] Step 16800 per-step time 0.108s\r\n",
      "I0401 19:34:15.317309 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.046141576,\r\n",
      " 'Loss/localization_loss': 0.011243712,\r\n",
      " 'Loss/regularization_loss': 0.08482311,\r\n",
      " 'Loss/total_loss': 0.1422084,\r\n",
      " 'learning_rate': 0.0031328127}\r\n",
      "I0401 19:34:26.022527 134477283476608 model_lib_v2.py:705] Step 16900 per-step time 0.107s\r\n",
      "I0401 19:34:26.022877 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.048850335,\r\n",
      " 'Loss/localization_loss': 0.01133623,\r\n",
      " 'Loss/regularization_loss': 0.08480573,\r\n",
      " 'Loss/total_loss': 0.14499229,\r\n",
      " 'learning_rate': 0.0031220005}\r\n",
      "I0401 19:34:36.605482 134477283476608 model_lib_v2.py:705] Step 17000 per-step time 0.106s\r\n",
      "I0401 19:34:36.605812 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.040561434,\r\n",
      " 'Loss/localization_loss': 0.0055899466,\r\n",
      " 'Loss/regularization_loss': 0.08478831,\r\n",
      " 'Loss/total_loss': 0.13093969,\r\n",
      " 'learning_rate': 0.0031111403}\r\n",
      "I0401 19:34:47.338681 134477283476608 model_lib_v2.py:705] Step 17100 per-step time 0.107s\r\n",
      "I0401 19:34:47.339053 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.034340248,\r\n",
      " 'Loss/localization_loss': 0.0071518617,\r\n",
      " 'Loss/regularization_loss': 0.08477103,\r\n",
      " 'Loss/total_loss': 0.12626314,\r\n",
      " 'learning_rate': 0.0031002327}\r\n",
      "I0401 19:34:57.974678 134477283476608 model_lib_v2.py:705] Step 17200 per-step time 0.106s\r\n",
      "I0401 19:34:57.975025 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.082345165,\r\n",
      " 'Loss/localization_loss': 0.008812469,\r\n",
      " 'Loss/regularization_loss': 0.08475265,\r\n",
      " 'Loss/total_loss': 0.1759103,\r\n",
      " 'learning_rate': 0.0030892782}\r\n",
      "I0401 19:35:08.670983 134477283476608 model_lib_v2.py:705] Step 17300 per-step time 0.107s\r\n",
      "I0401 19:35:08.671313 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.03561671,\r\n",
      " 'Loss/localization_loss': 0.017650098,\r\n",
      " 'Loss/regularization_loss': 0.08473484,\r\n",
      " 'Loss/total_loss': 0.13800165,\r\n",
      " 'learning_rate': 0.0030782768}\r\n",
      "I0401 19:35:19.268602 134477283476608 model_lib_v2.py:705] Step 17400 per-step time 0.106s\r\n",
      "I0401 19:35:19.268916 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.06204069,\r\n",
      " 'Loss/localization_loss': 0.021809496,\r\n",
      " 'Loss/regularization_loss': 0.0847175,\r\n",
      " 'Loss/total_loss': 0.16856769,\r\n",
      " 'learning_rate': 0.0030672292}\r\n",
      "I0401 19:35:29.873654 134477283476608 model_lib_v2.py:705] Step 17500 per-step time 0.106s\r\n",
      "I0401 19:35:29.874012 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.03340128,\r\n",
      " 'Loss/localization_loss': 0.005250098,\r\n",
      " 'Loss/regularization_loss': 0.08469963,\r\n",
      " 'Loss/total_loss': 0.12335101,\r\n",
      " 'learning_rate': 0.0030561357}\r\n",
      "I0401 19:35:40.537737 134477283476608 model_lib_v2.py:705] Step 17600 per-step time 0.107s\r\n",
      "I0401 19:35:40.538086 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.052990794,\r\n",
      " 'Loss/localization_loss': 0.07863293,\r\n",
      " 'Loss/regularization_loss': 0.08468212,\r\n",
      " 'Loss/total_loss': 0.21630584,\r\n",
      " 'learning_rate': 0.003044997}\r\n",
      "I0401 19:35:51.145480 134477283476608 model_lib_v2.py:705] Step 17700 per-step time 0.106s\r\n",
      "I0401 19:35:51.145789 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.053048458,\r\n",
      " 'Loss/localization_loss': 0.017419824,\r\n",
      " 'Loss/regularization_loss': 0.084663145,\r\n",
      " 'Loss/total_loss': 0.15513143,\r\n",
      " 'learning_rate': 0.0030338138}\r\n",
      "I0401 19:36:01.787208 134477283476608 model_lib_v2.py:705] Step 17800 per-step time 0.106s\r\n",
      "I0401 19:36:01.787509 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07717233,\r\n",
      " 'Loss/localization_loss': 0.029725743,\r\n",
      " 'Loss/regularization_loss': 0.08464703,\r\n",
      " 'Loss/total_loss': 0.1915451,\r\n",
      " 'learning_rate': 0.0030225865}\r\n",
      "I0401 19:36:12.464211 134477283476608 model_lib_v2.py:705] Step 17900 per-step time 0.107s\r\n",
      "I0401 19:36:12.464555 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.06653968,\r\n",
      " 'Loss/localization_loss': 0.016538678,\r\n",
      " 'Loss/regularization_loss': 0.08462927,\r\n",
      " 'Loss/total_loss': 0.16770762,\r\n",
      " 'learning_rate': 0.0030113147}\r\n",
      "I0401 19:36:23.094675 134477283476608 model_lib_v2.py:705] Step 18000 per-step time 0.106s\r\n",
      "I0401 19:36:23.095028 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05465154,\r\n",
      " 'Loss/localization_loss': 0.009224754,\r\n",
      " 'Loss/regularization_loss': 0.084612295,\r\n",
      " 'Loss/total_loss': 0.14848858,\r\n",
      " 'learning_rate': 0.003}\r\n",
      "I0401 19:36:34.428571 134477283476608 model_lib_v2.py:705] Step 18100 per-step time 0.113s\r\n",
      "I0401 19:36:34.428922 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.08279412,\r\n",
      " 'Loss/localization_loss': 0.008665838,\r\n",
      " 'Loss/regularization_loss': 0.08459446,\r\n",
      " 'Loss/total_loss': 0.17605442,\r\n",
      " 'learning_rate': 0.0029886423}\r\n",
      "I0401 19:36:45.023477 134477283476608 model_lib_v2.py:705] Step 18200 per-step time 0.106s\r\n",
      "I0401 19:36:45.023818 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.056872807,\r\n",
      " 'Loss/localization_loss': 0.0082061235,\r\n",
      " 'Loss/regularization_loss': 0.084577344,\r\n",
      " 'Loss/total_loss': 0.14965627,\r\n",
      " 'learning_rate': 0.0029772427}\r\n",
      "I0401 19:36:55.636433 134477283476608 model_lib_v2.py:705] Step 18300 per-step time 0.106s\r\n",
      "I0401 19:36:55.636765 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07493964,\r\n",
      " 'Loss/localization_loss': 0.013200745,\r\n",
      " 'Loss/regularization_loss': 0.08455992,\r\n",
      " 'Loss/total_loss': 0.1727003,\r\n",
      " 'learning_rate': 0.0029658007}\r\n",
      "I0401 19:37:06.305515 134477283476608 model_lib_v2.py:705] Step 18400 per-step time 0.107s\r\n",
      "I0401 19:37:06.305839 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.0620251,\r\n",
      " 'Loss/localization_loss': 0.016210854,\r\n",
      " 'Loss/regularization_loss': 0.08454234,\r\n",
      " 'Loss/total_loss': 0.16277829,\r\n",
      " 'learning_rate': 0.0029543177}\r\n",
      "I0401 19:37:16.963679 134477283476608 model_lib_v2.py:705] Step 18500 per-step time 0.107s\r\n",
      "I0401 19:37:16.964035 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.06301365,\r\n",
      " 'Loss/localization_loss': 0.0068979836,\r\n",
      " 'Loss/regularization_loss': 0.08452487,\r\n",
      " 'Loss/total_loss': 0.1544365,\r\n",
      " 'learning_rate': 0.0029427935}\r\n",
      "I0401 19:37:27.590581 134477283476608 model_lib_v2.py:705] Step 18600 per-step time 0.106s\r\n",
      "I0401 19:37:27.590931 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.037386216,\r\n",
      " 'Loss/localization_loss': 0.006836108,\r\n",
      " 'Loss/regularization_loss': 0.084508374,\r\n",
      " 'Loss/total_loss': 0.1287307,\r\n",
      " 'learning_rate': 0.0029312293}\r\n",
      "I0401 19:37:38.265522 134477283476608 model_lib_v2.py:705] Step 18700 per-step time 0.107s\r\n",
      "I0401 19:37:38.265858 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.033485427,\r\n",
      " 'Loss/localization_loss': 0.005504816,\r\n",
      " 'Loss/regularization_loss': 0.084490925,\r\n",
      " 'Loss/total_loss': 0.12348117,\r\n",
      " 'learning_rate': 0.002919625}\r\n",
      "I0401 19:37:48.898016 134477283476608 model_lib_v2.py:705] Step 18800 per-step time 0.106s\r\n",
      "I0401 19:37:48.898354 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.034996957,\r\n",
      " 'Loss/localization_loss': 0.0048747077,\r\n",
      " 'Loss/regularization_loss': 0.08447369,\r\n",
      " 'Loss/total_loss': 0.124345355,\r\n",
      " 'learning_rate': 0.0029079814}\r\n",
      "I0401 19:37:59.568259 134477283476608 model_lib_v2.py:705] Step 18900 per-step time 0.107s\r\n",
      "I0401 19:37:59.568559 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.055324793,\r\n",
      " 'Loss/localization_loss': 0.006229832,\r\n",
      " 'Loss/regularization_loss': 0.08445676,\r\n",
      " 'Loss/total_loss': 0.14601138,\r\n",
      " 'learning_rate': 0.0028962987}\r\n",
      "I0401 19:38:10.228709 134477283476608 model_lib_v2.py:705] Step 19000 per-step time 0.107s\r\n",
      "I0401 19:38:10.229055 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.082121834,\r\n",
      " 'Loss/localization_loss': 0.013219236,\r\n",
      " 'Loss/regularization_loss': 0.084439635,\r\n",
      " 'Loss/total_loss': 0.1797807,\r\n",
      " 'learning_rate': 0.0028845775}\r\n",
      "I0401 19:38:20.846257 134477283476608 model_lib_v2.py:705] Step 19100 per-step time 0.106s\r\n",
      "I0401 19:38:20.846595 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.050168704,\r\n",
      " 'Loss/localization_loss': 0.0090416055,\r\n",
      " 'Loss/regularization_loss': 0.08442292,\r\n",
      " 'Loss/total_loss': 0.14363323,\r\n",
      " 'learning_rate': 0.0028728186}\r\n",
      "I0401 19:38:31.509780 134477283476608 model_lib_v2.py:705] Step 19200 per-step time 0.107s\r\n",
      "I0401 19:38:31.510155 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.064204045,\r\n",
      " 'Loss/localization_loss': 0.024026953,\r\n",
      " 'Loss/regularization_loss': 0.0844063,\r\n",
      " 'Loss/total_loss': 0.1726373,\r\n",
      " 'learning_rate': 0.002861022}\r\n",
      "I0401 19:38:42.153572 134477283476608 model_lib_v2.py:705] Step 19300 per-step time 0.106s\r\n",
      "I0401 19:38:42.153923 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.053005815,\r\n",
      " 'Loss/localization_loss': 0.010268206,\r\n",
      " 'Loss/regularization_loss': 0.08438971,\r\n",
      " 'Loss/total_loss': 0.14766373,\r\n",
      " 'learning_rate': 0.002849189}\r\n",
      "I0401 19:38:52.850635 134477283476608 model_lib_v2.py:705] Step 19400 per-step time 0.107s\r\n",
      "I0401 19:38:52.850974 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05881691,\r\n",
      " 'Loss/localization_loss': 0.010756491,\r\n",
      " 'Loss/regularization_loss': 0.08437311,\r\n",
      " 'Loss/total_loss': 0.15394652,\r\n",
      " 'learning_rate': 0.0028373194}\r\n",
      "I0401 19:39:03.554920 134477283476608 model_lib_v2.py:705] Step 19500 per-step time 0.107s\r\n",
      "I0401 19:39:03.555268 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.041272607,\r\n",
      " 'Loss/localization_loss': 0.006684188,\r\n",
      " 'Loss/regularization_loss': 0.08435638,\r\n",
      " 'Loss/total_loss': 0.13231318,\r\n",
      " 'learning_rate': 0.0028254143}\r\n",
      "I0401 19:39:14.255490 134477283476608 model_lib_v2.py:705] Step 19600 per-step time 0.107s\r\n",
      "I0401 19:39:14.255788 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.06361766,\r\n",
      " 'Loss/localization_loss': 0.014886853,\r\n",
      " 'Loss/regularization_loss': 0.084340364,\r\n",
      " 'Loss/total_loss': 0.16284488,\r\n",
      " 'learning_rate': 0.0028134733}\r\n",
      "I0401 19:39:24.982650 134477283476608 model_lib_v2.py:705] Step 19700 per-step time 0.107s\r\n",
      "I0401 19:39:24.982982 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05213691,\r\n",
      " 'Loss/localization_loss': 0.008586731,\r\n",
      " 'Loss/regularization_loss': 0.08432317,\r\n",
      " 'Loss/total_loss': 0.1450468,\r\n",
      " 'learning_rate': 0.002801498}\r\n",
      "I0401 19:39:35.624327 134477283476608 model_lib_v2.py:705] Step 19800 per-step time 0.106s\r\n",
      "I0401 19:39:35.624671 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.030747315,\r\n",
      " 'Loss/localization_loss': 0.007764548,\r\n",
      " 'Loss/regularization_loss': 0.084307194,\r\n",
      " 'Loss/total_loss': 0.12281906,\r\n",
      " 'learning_rate': 0.0027894878}\r\n",
      "I0401 19:39:46.282479 134477283476608 model_lib_v2.py:705] Step 19900 per-step time 0.107s\r\n",
      "I0401 19:39:46.282824 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07224321,\r\n",
      " 'Loss/localization_loss': 0.013420278,\r\n",
      " 'Loss/regularization_loss': 0.084291406,\r\n",
      " 'Loss/total_loss': 0.1699549,\r\n",
      " 'learning_rate': 0.002777444}\r\n",
      "I0401 19:39:56.931518 134477283476608 model_lib_v2.py:705] Step 20000 per-step time 0.106s\r\n",
      "I0401 19:39:56.931859 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.058248427,\r\n",
      " 'Loss/localization_loss': 0.0047115693,\r\n",
      " 'Loss/regularization_loss': 0.08427522,\r\n",
      " 'Loss/total_loss': 0.14723521,\r\n",
      " 'learning_rate': 0.0027653673}\r\n",
      "I0401 19:40:08.275365 134477283476608 model_lib_v2.py:705] Step 20100 per-step time 0.113s\r\n",
      "I0401 19:40:08.275707 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.029070845,\r\n",
      " 'Loss/localization_loss': 0.009628212,\r\n",
      " 'Loss/regularization_loss': 0.08425912,\r\n",
      " 'Loss/total_loss': 0.12295818,\r\n",
      " 'learning_rate': 0.002753257}\r\n",
      "I0401 19:40:18.964713 134477283476608 model_lib_v2.py:705] Step 20200 per-step time 0.107s\r\n",
      "I0401 19:40:18.965131 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.031543586,\r\n",
      " 'Loss/localization_loss': 0.0064836135,\r\n",
      " 'Loss/regularization_loss': 0.08424309,\r\n",
      " 'Loss/total_loss': 0.122270286,\r\n",
      " 'learning_rate': 0.002741115}\r\n",
      "I0401 19:40:29.671678 134477283476608 model_lib_v2.py:705] Step 20300 per-step time 0.107s\r\n",
      "I0401 19:40:29.672036 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.037334107,\r\n",
      " 'Loss/localization_loss': 0.024901744,\r\n",
      " 'Loss/regularization_loss': 0.08422692,\r\n",
      " 'Loss/total_loss': 0.14646277,\r\n",
      " 'learning_rate': 0.0027289412}\r\n",
      "I0401 19:40:40.307846 134477283476608 model_lib_v2.py:705] Step 20400 per-step time 0.106s\r\n",
      "I0401 19:40:40.308201 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.047871485,\r\n",
      " 'Loss/localization_loss': 0.0075260513,\r\n",
      " 'Loss/regularization_loss': 0.08421042,\r\n",
      " 'Loss/total_loss': 0.13960795,\r\n",
      " 'learning_rate': 0.002716736}\r\n",
      "I0401 19:40:50.989689 134477283476608 model_lib_v2.py:705] Step 20500 per-step time 0.107s\r\n",
      "I0401 19:40:50.990093 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.04693912,\r\n",
      " 'Loss/localization_loss': 0.0067078355,\r\n",
      " 'Loss/regularization_loss': 0.08419501,\r\n",
      " 'Loss/total_loss': 0.13784197,\r\n",
      " 'learning_rate': 0.0027045}\r\n",
      "I0401 19:41:01.625063 134477283476608 model_lib_v2.py:705] Step 20600 per-step time 0.106s\r\n",
      "I0401 19:41:01.625379 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.050480768,\r\n",
      " 'Loss/localization_loss': 0.012113092,\r\n",
      " 'Loss/regularization_loss': 0.084179126,\r\n",
      " 'Loss/total_loss': 0.14677298,\r\n",
      " 'learning_rate': 0.0026922342}\r\n",
      "I0401 19:41:12.279133 134477283476608 model_lib_v2.py:705] Step 20700 per-step time 0.107s\r\n",
      "I0401 19:41:12.279451 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.10492804,\r\n",
      " 'Loss/localization_loss': 0.017410511,\r\n",
      " 'Loss/regularization_loss': 0.08416329,\r\n",
      " 'Loss/total_loss': 0.20650184,\r\n",
      " 'learning_rate': 0.0026799385}\r\n",
      "I0401 19:41:22.901025 134477283476608 model_lib_v2.py:705] Step 20800 per-step time 0.106s\r\n",
      "I0401 19:41:22.901400 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.057576563,\r\n",
      " 'Loss/localization_loss': 0.005415938,\r\n",
      " 'Loss/regularization_loss': 0.08414723,\r\n",
      " 'Loss/total_loss': 0.14713973,\r\n",
      " 'learning_rate': 0.0026676136}\r\n",
      "I0401 19:41:33.543772 134477283476608 model_lib_v2.py:705] Step 20900 per-step time 0.106s\r\n",
      "I0401 19:41:33.544120 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.042437006,\r\n",
      " 'Loss/localization_loss': 0.0063428394,\r\n",
      " 'Loss/regularization_loss': 0.08413175,\r\n",
      " 'Loss/total_loss': 0.1329116,\r\n",
      " 'learning_rate': 0.0026552605}\r\n",
      "I0401 19:41:44.172231 134477283476608 model_lib_v2.py:705] Step 21000 per-step time 0.106s\r\n",
      "I0401 19:41:44.172578 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.053765934,\r\n",
      " 'Loss/localization_loss': 0.008304368,\r\n",
      " 'Loss/regularization_loss': 0.08411611,\r\n",
      " 'Loss/total_loss': 0.14618641,\r\n",
      " 'learning_rate': 0.002642879}\r\n",
      "I0401 19:41:54.862931 134477283476608 model_lib_v2.py:705] Step 21100 per-step time 0.107s\r\n",
      "I0401 19:41:54.863356 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.09183104,\r\n",
      " 'Loss/localization_loss': 0.0118696205,\r\n",
      " 'Loss/regularization_loss': 0.084100544,\r\n",
      " 'Loss/total_loss': 0.18780121,\r\n",
      " 'learning_rate': 0.0026304699}\r\n",
      "I0401 19:42:05.538037 134477283476608 model_lib_v2.py:705] Step 21200 per-step time 0.107s\r\n",
      "I0401 19:42:05.538355 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.03978479,\r\n",
      " 'Loss/localization_loss': 0.007897978,\r\n",
      " 'Loss/regularization_loss': 0.084087305,\r\n",
      " 'Loss/total_loss': 0.13177007,\r\n",
      " 'learning_rate': 0.002618034}\r\n",
      "I0401 19:42:16.232681 134477283476608 model_lib_v2.py:705] Step 21300 per-step time 0.107s\r\n",
      "I0401 19:42:16.233024 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.04028694,\r\n",
      " 'Loss/localization_loss': 0.010817923,\r\n",
      " 'Loss/regularization_loss': 0.08407214,\r\n",
      " 'Loss/total_loss': 0.135177,\r\n",
      " 'learning_rate': 0.0026055716}\r\n",
      "I0401 19:42:26.945021 134477283476608 model_lib_v2.py:705] Step 21400 per-step time 0.107s\r\n",
      "I0401 19:42:26.945339 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.048747934,\r\n",
      " 'Loss/localization_loss': 0.010034091,\r\n",
      " 'Loss/regularization_loss': 0.08405705,\r\n",
      " 'Loss/total_loss': 0.14283907,\r\n",
      " 'learning_rate': 0.0025930835}\r\n",
      "I0401 19:42:37.629177 134477283476608 model_lib_v2.py:705] Step 21500 per-step time 0.107s\r\n",
      "I0401 19:42:37.629478 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.06615588,\r\n",
      " 'Loss/localization_loss': 0.05092652,\r\n",
      " 'Loss/regularization_loss': 0.084040835,\r\n",
      " 'Loss/total_loss': 0.20112324,\r\n",
      " 'learning_rate': 0.0025805694}\r\n",
      "I0401 19:42:48.254648 134477283476608 model_lib_v2.py:705] Step 21600 per-step time 0.106s\r\n",
      "I0401 19:42:48.255097 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.071008205,\r\n",
      " 'Loss/localization_loss': 0.010862545,\r\n",
      " 'Loss/regularization_loss': 0.0840259,\r\n",
      " 'Loss/total_loss': 0.16589665,\r\n",
      " 'learning_rate': 0.002568031}\r\n",
      "I0401 19:42:58.952910 134477283476608 model_lib_v2.py:705] Step 21700 per-step time 0.107s\r\n",
      "I0401 19:42:58.953252 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.032039404,\r\n",
      " 'Loss/localization_loss': 0.008736213,\r\n",
      " 'Loss/regularization_loss': 0.08401141,\r\n",
      " 'Loss/total_loss': 0.12478703,\r\n",
      " 'learning_rate': 0.0025554677}\r\n",
      "I0401 19:43:09.614505 134477283476608 model_lib_v2.py:705] Step 21800 per-step time 0.107s\r\n",
      "I0401 19:43:09.614817 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.0570004,\r\n",
      " 'Loss/localization_loss': 0.023890661,\r\n",
      " 'Loss/regularization_loss': 0.08399609,\r\n",
      " 'Loss/total_loss': 0.16488715,\r\n",
      " 'learning_rate': 0.0025428808}\r\n",
      "I0401 19:43:20.277193 134477283476608 model_lib_v2.py:705] Step 21900 per-step time 0.107s\r\n",
      "I0401 19:43:20.277513 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.048833556,\r\n",
      " 'Loss/localization_loss': 0.004222761,\r\n",
      " 'Loss/regularization_loss': 0.08398073,\r\n",
      " 'Loss/total_loss': 0.13703705,\r\n",
      " 'learning_rate': 0.002530271}\r\n",
      "I0401 19:43:31.002564 134477283476608 model_lib_v2.py:705] Step 22000 per-step time 0.107s\r\n",
      "I0401 19:43:31.002893 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.03642667,\r\n",
      " 'Loss/localization_loss': 0.042420384,\r\n",
      " 'Loss/regularization_loss': 0.08396563,\r\n",
      " 'Loss/total_loss': 0.16281268,\r\n",
      " 'learning_rate': 0.002517638}\r\n",
      "I0401 19:43:42.332555 134477283476608 model_lib_v2.py:705] Step 22100 per-step time 0.113s\r\n",
      "I0401 19:43:42.332903 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.030009562,\r\n",
      " 'Loss/localization_loss': 0.0039116032,\r\n",
      " 'Loss/regularization_loss': 0.0839507,\r\n",
      " 'Loss/total_loss': 0.117871866,\r\n",
      " 'learning_rate': 0.002504983}\r\n",
      "I0401 19:43:52.949571 134477283476608 model_lib_v2.py:705] Step 22200 per-step time 0.106s\r\n",
      "I0401 19:43:52.949874 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.031377807,\r\n",
      " 'Loss/localization_loss': 0.0058570406,\r\n",
      " 'Loss/regularization_loss': 0.08393587,\r\n",
      " 'Loss/total_loss': 0.121170714,\r\n",
      " 'learning_rate': 0.0024923065}\r\n",
      "I0401 19:44:03.685301 134477283476608 model_lib_v2.py:705] Step 22300 per-step time 0.107s\r\n",
      "I0401 19:44:03.685636 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.10649843,\r\n",
      " 'Loss/localization_loss': 0.051018525,\r\n",
      " 'Loss/regularization_loss': 0.08392078,\r\n",
      " 'Loss/total_loss': 0.24143773,\r\n",
      " 'learning_rate': 0.002479609}\r\n",
      "I0401 19:44:14.348999 134477283476608 model_lib_v2.py:705] Step 22400 per-step time 0.107s\r\n",
      "I0401 19:44:14.349294 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.0403334,\r\n",
      " 'Loss/localization_loss': 0.021091154,\r\n",
      " 'Loss/regularization_loss': 0.08390673,\r\n",
      " 'Loss/total_loss': 0.1453313,\r\n",
      " 'learning_rate': 0.0024668907}\r\n",
      "I0401 19:44:24.967261 134477283476608 model_lib_v2.py:705] Step 22500 per-step time 0.106s\r\n",
      "I0401 19:44:24.967553 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07899228,\r\n",
      " 'Loss/localization_loss': 0.025123427,\r\n",
      " 'Loss/regularization_loss': 0.08389258,\r\n",
      " 'Loss/total_loss': 0.18800828,\r\n",
      " 'learning_rate': 0.0024541528}\r\n",
      "I0401 19:44:35.685096 134477283476608 model_lib_v2.py:705] Step 22600 per-step time 0.107s\r\n",
      "I0401 19:44:35.685419 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.067757785,\r\n",
      " 'Loss/localization_loss': 0.007856016,\r\n",
      " 'Loss/regularization_loss': 0.08387798,\r\n",
      " 'Loss/total_loss': 0.15949178,\r\n",
      " 'learning_rate': 0.0024413948}\r\n",
      "I0401 19:44:46.301674 134477283476608 model_lib_v2.py:705] Step 22700 per-step time 0.106s\r\n",
      "I0401 19:44:46.302006 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.028871521,\r\n",
      " 'Loss/localization_loss': 0.0045020552,\r\n",
      " 'Loss/regularization_loss': 0.08386393,\r\n",
      " 'Loss/total_loss': 0.11723751,\r\n",
      " 'learning_rate': 0.0024286183}\r\n",
      "I0401 19:44:56.908307 134477283476608 model_lib_v2.py:705] Step 22800 per-step time 0.106s\r\n",
      "I0401 19:44:56.908651 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.044398595,\r\n",
      " 'Loss/localization_loss': 0.013241039,\r\n",
      " 'Loss/regularization_loss': 0.08384998,\r\n",
      " 'Loss/total_loss': 0.14148961,\r\n",
      " 'learning_rate': 0.0024158233}\r\n",
      "I0401 19:45:07.650147 134477283476608 model_lib_v2.py:705] Step 22900 per-step time 0.107s\r\n",
      "I0401 19:45:07.650473 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.031063342,\r\n",
      " 'Loss/localization_loss': 0.008463556,\r\n",
      " 'Loss/regularization_loss': 0.08383571,\r\n",
      " 'Loss/total_loss': 0.123362616,\r\n",
      " 'learning_rate': 0.0024030106}\r\n",
      "I0401 19:45:18.248881 134477283476608 model_lib_v2.py:705] Step 23000 per-step time 0.106s\r\n",
      "I0401 19:45:18.249217 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.04844185,\r\n",
      " 'Loss/localization_loss': 0.0061963364,\r\n",
      " 'Loss/regularization_loss': 0.083821766,\r\n",
      " 'Loss/total_loss': 0.13845995,\r\n",
      " 'learning_rate': 0.0023901807}\r\n",
      "I0401 19:45:28.875643 134477283476608 model_lib_v2.py:705] Step 23100 per-step time 0.106s\r\n",
      "I0401 19:45:28.876011 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.035847493,\r\n",
      " 'Loss/localization_loss': 0.006000459,\r\n",
      " 'Loss/regularization_loss': 0.083807655,\r\n",
      " 'Loss/total_loss': 0.1256556,\r\n",
      " 'learning_rate': 0.002377334}\r\n",
      "I0401 19:45:39.597883 134477283476608 model_lib_v2.py:705] Step 23200 per-step time 0.107s\r\n",
      "I0401 19:45:39.598207 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.032713424,\r\n",
      " 'Loss/localization_loss': 0.005774898,\r\n",
      " 'Loss/regularization_loss': 0.08379361,\r\n",
      " 'Loss/total_loss': 0.12228193,\r\n",
      " 'learning_rate': 0.002364471}\r\n",
      "I0401 19:45:50.234115 134477283476608 model_lib_v2.py:705] Step 23300 per-step time 0.106s\r\n",
      "I0401 19:45:50.234449 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.085908875,\r\n",
      " 'Loss/localization_loss': 0.017367775,\r\n",
      " 'Loss/regularization_loss': 0.0837808,\r\n",
      " 'Loss/total_loss': 0.18705745,\r\n",
      " 'learning_rate': 0.0023515928}\r\n",
      "I0401 19:46:00.922368 134477283476608 model_lib_v2.py:705] Step 23400 per-step time 0.107s\r\n",
      "I0401 19:46:00.922693 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07639824,\r\n",
      " 'Loss/localization_loss': 0.008240981,\r\n",
      " 'Loss/regularization_loss': 0.083766595,\r\n",
      " 'Loss/total_loss': 0.16840582,\r\n",
      " 'learning_rate': 0.002338699}\r\n",
      "I0401 19:46:11.634543 134477283476608 model_lib_v2.py:705] Step 23500 per-step time 0.107s\r\n",
      "I0401 19:46:11.634869 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.038281027,\r\n",
      " 'Loss/localization_loss': 0.0071373587,\r\n",
      " 'Loss/regularization_loss': 0.08375417,\r\n",
      " 'Loss/total_loss': 0.12917255,\r\n",
      " 'learning_rate': 0.002325791}\r\n",
      "I0401 19:46:22.278822 134477283476608 model_lib_v2.py:705] Step 23600 per-step time 0.106s\r\n",
      "I0401 19:46:22.279179 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.053016555,\r\n",
      " 'Loss/localization_loss': 0.0076327347,\r\n",
      " 'Loss/regularization_loss': 0.08374036,\r\n",
      " 'Loss/total_loss': 0.14438966,\r\n",
      " 'learning_rate': 0.0023128688}\r\n",
      "I0401 19:46:32.983601 134477283476608 model_lib_v2.py:705] Step 23700 per-step time 0.107s\r\n",
      "I0401 19:46:32.983980 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.041332737,\r\n",
      " 'Loss/localization_loss': 0.0060703624,\r\n",
      " 'Loss/regularization_loss': 0.083725676,\r\n",
      " 'Loss/total_loss': 0.13112877,\r\n",
      " 'learning_rate': 0.0022999335}\r\n",
      "I0401 19:46:43.685510 134477283476608 model_lib_v2.py:705] Step 23800 per-step time 0.107s\r\n",
      "I0401 19:46:43.685823 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.038060457,\r\n",
      " 'Loss/localization_loss': 0.0060924315,\r\n",
      " 'Loss/regularization_loss': 0.08371275,\r\n",
      " 'Loss/total_loss': 0.12786564,\r\n",
      " 'learning_rate': 0.0022869853}\r\n",
      "I0401 19:46:54.320208 134477283476608 model_lib_v2.py:705] Step 23900 per-step time 0.106s\r\n",
      "I0401 19:46:54.320503 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07661495,\r\n",
      " 'Loss/localization_loss': 0.007287006,\r\n",
      " 'Loss/regularization_loss': 0.08369936,\r\n",
      " 'Loss/total_loss': 0.16760132,\r\n",
      " 'learning_rate': 0.0022740245}\r\n",
      "I0401 19:47:05.003932 134477283476608 model_lib_v2.py:705] Step 24000 per-step time 0.107s\r\n",
      "I0401 19:47:05.004275 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.042502537,\r\n",
      " 'Loss/localization_loss': 0.0102981925,\r\n",
      " 'Loss/regularization_loss': 0.08368567,\r\n",
      " 'Loss/total_loss': 0.1364864,\r\n",
      " 'learning_rate': 0.0022610521}\r\n",
      "I0401 19:47:16.409212 134477283476608 model_lib_v2.py:705] Step 24100 per-step time 0.114s\r\n",
      "I0401 19:47:16.409545 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.040316362,\r\n",
      " 'Loss/localization_loss': 0.0052382187,\r\n",
      " 'Loss/regularization_loss': 0.083671875,\r\n",
      " 'Loss/total_loss': 0.12922646,\r\n",
      " 'learning_rate': 0.0022480686}\r\n",
      "I0401 19:47:27.040874 134477283476608 model_lib_v2.py:705] Step 24200 per-step time 0.106s\r\n",
      "I0401 19:47:27.041213 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.075647786,\r\n",
      " 'Loss/localization_loss': 0.027835578,\r\n",
      " 'Loss/regularization_loss': 0.083658874,\r\n",
      " 'Loss/total_loss': 0.18714224,\r\n",
      " 'learning_rate': 0.0022350748}\r\n",
      "I0401 19:47:37.671073 134477283476608 model_lib_v2.py:705] Step 24300 per-step time 0.106s\r\n",
      "I0401 19:47:37.671449 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.057092015,\r\n",
      " 'Loss/localization_loss': 0.012208926,\r\n",
      " 'Loss/regularization_loss': 0.083645925,\r\n",
      " 'Loss/total_loss': 0.15294686,\r\n",
      " 'learning_rate': 0.0022220707}\r\n",
      "I0401 19:47:48.366894 134477283476608 model_lib_v2.py:705] Step 24400 per-step time 0.107s\r\n",
      "I0401 19:47:48.367258 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.045198824,\r\n",
      " 'Loss/localization_loss': 0.0064368392,\r\n",
      " 'Loss/regularization_loss': 0.08363248,\r\n",
      " 'Loss/total_loss': 0.13526814,\r\n",
      " 'learning_rate': 0.0022090569}\r\n",
      "I0401 19:47:59.005915 134477283476608 model_lib_v2.py:705] Step 24500 per-step time 0.106s\r\n",
      "I0401 19:47:59.006266 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05711188,\r\n",
      " 'Loss/localization_loss': 0.006757356,\r\n",
      " 'Loss/regularization_loss': 0.083618976,\r\n",
      " 'Loss/total_loss': 0.1474882,\r\n",
      " 'learning_rate': 0.0021960342}\r\n",
      "I0401 19:48:09.723281 134477283476608 model_lib_v2.py:705] Step 24600 per-step time 0.107s\r\n",
      "I0401 19:48:09.723703 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.034835886,\r\n",
      " 'Loss/localization_loss': 0.013943331,\r\n",
      " 'Loss/regularization_loss': 0.083606124,\r\n",
      " 'Loss/total_loss': 0.13238534,\r\n",
      " 'learning_rate': 0.0021830036}\r\n",
      "I0401 19:48:20.486988 134477283476608 model_lib_v2.py:705] Step 24700 per-step time 0.108s\r\n",
      "I0401 19:48:20.487385 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.037804216,\r\n",
      " 'Loss/localization_loss': 0.007631324,\r\n",
      " 'Loss/regularization_loss': 0.08359361,\r\n",
      " 'Loss/total_loss': 0.12902915,\r\n",
      " 'learning_rate': 0.0021699644}\r\n",
      "I0401 19:48:31.223524 134477283476608 model_lib_v2.py:705] Step 24800 per-step time 0.107s\r\n",
      "I0401 19:48:31.223846 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07289483,\r\n",
      " 'Loss/localization_loss': 0.01932672,\r\n",
      " 'Loss/regularization_loss': 0.08358107,\r\n",
      " 'Loss/total_loss': 0.17580262,\r\n",
      " 'learning_rate': 0.0021569182}\r\n",
      "I0401 19:48:41.843268 134477283476608 model_lib_v2.py:705] Step 24900 per-step time 0.106s\r\n",
      "I0401 19:48:41.843605 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.027868472,\r\n",
      " 'Loss/localization_loss': 0.005632922,\r\n",
      " 'Loss/regularization_loss': 0.083568655,\r\n",
      " 'Loss/total_loss': 0.11707005,\r\n",
      " 'learning_rate': 0.0021438652}\r\n",
      "I0401 19:48:52.493282 134477283476608 model_lib_v2.py:705] Step 25000 per-step time 0.107s\r\n",
      "I0401 19:48:52.493605 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07590675,\r\n",
      " 'Loss/localization_loss': 0.009182777,\r\n",
      " 'Loss/regularization_loss': 0.08355629,\r\n",
      " 'Loss/total_loss': 0.16864583,\r\n",
      " 'learning_rate': 0.0021308062}\r\n",
      "I0401 19:49:03.161360 134477283476608 model_lib_v2.py:705] Step 25100 per-step time 0.107s\r\n",
      "I0401 19:49:03.161713 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.08044095,\r\n",
      " 'Loss/localization_loss': 0.0067059905,\r\n",
      " 'Loss/regularization_loss': 0.08354345,\r\n",
      " 'Loss/total_loss': 0.17069039,\r\n",
      " 'learning_rate': 0.0021177416}\r\n",
      "I0401 19:49:13.737386 134477283476608 model_lib_v2.py:705] Step 25200 per-step time 0.106s\r\n",
      "I0401 19:49:13.737737 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.06333659,\r\n",
      " 'Loss/localization_loss': 0.01917163,\r\n",
      " 'Loss/regularization_loss': 0.08353082,\r\n",
      " 'Loss/total_loss': 0.16603905,\r\n",
      " 'learning_rate': 0.002104672}\r\n",
      "I0401 19:49:24.405440 134477283476608 model_lib_v2.py:705] Step 25300 per-step time 0.107s\r\n",
      "I0401 19:49:24.405756 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.042437427,\r\n",
      " 'Loss/localization_loss': 0.008973712,\r\n",
      " 'Loss/regularization_loss': 0.08351838,\r\n",
      " 'Loss/total_loss': 0.13492951,\r\n",
      " 'learning_rate': 0.0020915978}\r\n",
      "I0401 19:49:35.085445 134477283476608 model_lib_v2.py:705] Step 25400 per-step time 0.107s\r\n",
      "I0401 19:49:35.085806 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07817292,\r\n",
      " 'Loss/localization_loss': 0.012069558,\r\n",
      " 'Loss/regularization_loss': 0.08350641,\r\n",
      " 'Loss/total_loss': 0.1737489,\r\n",
      " 'learning_rate': 0.0020785194}\r\n",
      "I0401 19:49:45.743437 134477283476608 model_lib_v2.py:705] Step 25500 per-step time 0.107s\r\n",
      "I0401 19:49:45.743761 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.052141573,\r\n",
      " 'Loss/localization_loss': 0.013161498,\r\n",
      " 'Loss/regularization_loss': 0.08349363,\r\n",
      " 'Loss/total_loss': 0.1487967,\r\n",
      " 'learning_rate': 0.0020654383}\r\n",
      "I0401 19:49:56.412515 134477283476608 model_lib_v2.py:705] Step 25600 per-step time 0.107s\r\n",
      "I0401 19:49:56.412864 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.045301154,\r\n",
      " 'Loss/localization_loss': 0.008568085,\r\n",
      " 'Loss/regularization_loss': 0.0834811,\r\n",
      " 'Loss/total_loss': 0.13735035,\r\n",
      " 'learning_rate': 0.0020523542}\r\n",
      "I0401 19:50:07.104567 134477283476608 model_lib_v2.py:705] Step 25700 per-step time 0.107s\r\n",
      "I0401 19:50:07.104901 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.088279486,\r\n",
      " 'Loss/localization_loss': 0.011750038,\r\n",
      " 'Loss/regularization_loss': 0.083468966,\r\n",
      " 'Loss/total_loss': 0.18349849,\r\n",
      " 'learning_rate': 0.0020392674}\r\n",
      "I0401 19:50:17.756493 134477283476608 model_lib_v2.py:705] Step 25800 per-step time 0.107s\r\n",
      "I0401 19:50:17.756827 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.030700976,\r\n",
      " 'Loss/localization_loss': 0.004214802,\r\n",
      " 'Loss/regularization_loss': 0.083456516,\r\n",
      " 'Loss/total_loss': 0.11837229,\r\n",
      " 'learning_rate': 0.0020261793}\r\n",
      "I0401 19:50:28.479693 134477283476608 model_lib_v2.py:705] Step 25900 per-step time 0.107s\r\n",
      "I0401 19:50:28.480082 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.055212736,\r\n",
      " 'Loss/localization_loss': 0.008728681,\r\n",
      " 'Loss/regularization_loss': 0.08344445,\r\n",
      " 'Loss/total_loss': 0.14738587,\r\n",
      " 'learning_rate': 0.0020130898}\r\n",
      "I0401 19:50:39.126552 134477283476608 model_lib_v2.py:705] Step 26000 per-step time 0.106s\r\n",
      "I0401 19:50:39.126869 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.06760297,\r\n",
      " 'Loss/localization_loss': 0.005456348,\r\n",
      " 'Loss/regularization_loss': 0.08343254,\r\n",
      " 'Loss/total_loss': 0.15649186,\r\n",
      " 'learning_rate': 0.0019999999}\r\n",
      "I0401 19:50:50.453587 134477283476608 model_lib_v2.py:705] Step 26100 per-step time 0.113s\r\n",
      "I0401 19:50:50.453937 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.067277305,\r\n",
      " 'Loss/localization_loss': 0.011734565,\r\n",
      " 'Loss/regularization_loss': 0.083420224,\r\n",
      " 'Loss/total_loss': 0.1624321,\r\n",
      " 'learning_rate': 0.0019869101}\r\n",
      "I0401 19:51:01.202543 134477283476608 model_lib_v2.py:705] Step 26200 per-step time 0.107s\r\n",
      "I0401 19:51:01.202864 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.073111884,\r\n",
      " 'Loss/localization_loss': 0.03915895,\r\n",
      " 'Loss/regularization_loss': 0.08340842,\r\n",
      " 'Loss/total_loss': 0.19567925,\r\n",
      " 'learning_rate': 0.0019738209}\r\n",
      "I0401 19:51:11.852566 134477283476608 model_lib_v2.py:705] Step 26300 per-step time 0.107s\r\n",
      "I0401 19:51:11.852924 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.070155345,\r\n",
      " 'Loss/localization_loss': 0.009463436,\r\n",
      " 'Loss/regularization_loss': 0.08339718,\r\n",
      " 'Loss/total_loss': 0.16301596,\r\n",
      " 'learning_rate': 0.0019607325}\r\n",
      "I0401 19:51:22.565809 134477283476608 model_lib_v2.py:705] Step 26400 per-step time 0.107s\r\n",
      "I0401 19:51:22.566178 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07837455,\r\n",
      " 'Loss/localization_loss': 0.0036438713,\r\n",
      " 'Loss/regularization_loss': 0.08338537,\r\n",
      " 'Loss/total_loss': 0.16540378,\r\n",
      " 'learning_rate': 0.0019476461}\r\n",
      "I0401 19:51:33.219053 134477283476608 model_lib_v2.py:705] Step 26500 per-step time 0.107s\r\n",
      "I0401 19:51:33.219394 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.098725446,\r\n",
      " 'Loss/localization_loss': 0.019823797,\r\n",
      " 'Loss/regularization_loss': 0.0833737,\r\n",
      " 'Loss/total_loss': 0.20192295,\r\n",
      " 'learning_rate': 0.0019345616}\r\n",
      "I0401 19:51:43.901430 134477283476608 model_lib_v2.py:705] Step 26600 per-step time 0.107s\r\n",
      "I0401 19:51:43.901768 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05301448,\r\n",
      " 'Loss/localization_loss': 0.014113292,\r\n",
      " 'Loss/regularization_loss': 0.08336196,\r\n",
      " 'Loss/total_loss': 0.15048973,\r\n",
      " 'learning_rate': 0.0019214804}\r\n",
      "I0401 19:51:54.501586 134477283476608 model_lib_v2.py:705] Step 26700 per-step time 0.106s\r\n",
      "I0401 19:51:54.501989 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.04929783,\r\n",
      " 'Loss/localization_loss': 0.0104995845,\r\n",
      " 'Loss/regularization_loss': 0.0833509,\r\n",
      " 'Loss/total_loss': 0.1431483,\r\n",
      " 'learning_rate': 0.0019084021}\r\n",
      "I0401 19:52:05.211589 134477283476608 model_lib_v2.py:705] Step 26800 per-step time 0.107s\r\n",
      "I0401 19:52:05.211961 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.044030026,\r\n",
      " 'Loss/localization_loss': 0.006366093,\r\n",
      " 'Loss/regularization_loss': 0.08333939,\r\n",
      " 'Loss/total_loss': 0.13373551,\r\n",
      " 'learning_rate': 0.001895328}\r\n",
      "I0401 19:52:15.837397 134477283476608 model_lib_v2.py:705] Step 26900 per-step time 0.106s\r\n",
      "I0401 19:52:15.837722 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.048639067,\r\n",
      " 'Loss/localization_loss': 0.0049209828,\r\n",
      " 'Loss/regularization_loss': 0.083327465,\r\n",
      " 'Loss/total_loss': 0.13688752,\r\n",
      " 'learning_rate': 0.0018822586}\r\n",
      "I0401 19:52:26.489719 134477283476608 model_lib_v2.py:705] Step 27000 per-step time 0.107s\r\n",
      "I0401 19:52:26.490086 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.036046535,\r\n",
      " 'Loss/localization_loss': 0.0142851835,\r\n",
      " 'Loss/regularization_loss': 0.083317414,\r\n",
      " 'Loss/total_loss': 0.13364914,\r\n",
      " 'learning_rate': 0.0018691937}\r\n",
      "I0401 19:52:37.150317 134477283476608 model_lib_v2.py:705] Step 27100 per-step time 0.107s\r\n",
      "I0401 19:52:37.150651 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.03221793,\r\n",
      " 'Loss/localization_loss': 0.0053655766,\r\n",
      " 'Loss/regularization_loss': 0.08330612,\r\n",
      " 'Loss/total_loss': 0.12088963,\r\n",
      " 'learning_rate': 0.0018561347}\r\n",
      "I0401 19:52:47.752857 134477283476608 model_lib_v2.py:705] Step 27200 per-step time 0.106s\r\n",
      "I0401 19:52:47.753181 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.03336424,\r\n",
      " 'Loss/localization_loss': 0.004011633,\r\n",
      " 'Loss/regularization_loss': 0.08329506,\r\n",
      " 'Loss/total_loss': 0.12067094,\r\n",
      " 'learning_rate': 0.0018430818}\r\n",
      "I0401 19:52:58.410256 134477283476608 model_lib_v2.py:705] Step 27300 per-step time 0.107s\r\n",
      "I0401 19:52:58.410595 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.04924954,\r\n",
      " 'Loss/localization_loss': 0.009856556,\r\n",
      " 'Loss/regularization_loss': 0.08328427,\r\n",
      " 'Loss/total_loss': 0.14239037,\r\n",
      " 'learning_rate': 0.0018300357}\r\n",
      "I0401 19:53:09.128514 134477283476608 model_lib_v2.py:705] Step 27400 per-step time 0.107s\r\n",
      "I0401 19:53:09.128875 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.035328317,\r\n",
      " 'Loss/localization_loss': 0.0060966425,\r\n",
      " 'Loss/regularization_loss': 0.083273634,\r\n",
      " 'Loss/total_loss': 0.124698594,\r\n",
      " 'learning_rate': 0.001816997}\r\n",
      "I0401 19:53:19.794293 134477283476608 model_lib_v2.py:705] Step 27500 per-step time 0.107s\r\n",
      "I0401 19:53:19.794597 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.070189066,\r\n",
      " 'Loss/localization_loss': 0.0075825616,\r\n",
      " 'Loss/regularization_loss': 0.08326288,\r\n",
      " 'Loss/total_loss': 0.16103451,\r\n",
      " 'learning_rate': 0.0018039657}\r\n",
      "I0401 19:53:30.440257 134477283476608 model_lib_v2.py:705] Step 27600 per-step time 0.106s\r\n",
      "I0401 19:53:30.440600 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.04993389,\r\n",
      " 'Loss/localization_loss': 0.011765261,\r\n",
      " 'Loss/regularization_loss': 0.083252355,\r\n",
      " 'Loss/total_loss': 0.1449515,\r\n",
      " 'learning_rate': 0.0017909431}\r\n",
      "I0401 19:53:41.162114 134477283476608 model_lib_v2.py:705] Step 27700 per-step time 0.107s\r\n",
      "I0401 19:53:41.162428 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.038034216,\r\n",
      " 'Loss/localization_loss': 0.009240368,\r\n",
      " 'Loss/regularization_loss': 0.08324122,\r\n",
      " 'Loss/total_loss': 0.1305158,\r\n",
      " 'learning_rate': 0.0017779294}\r\n",
      "I0401 19:53:51.843668 134477283476608 model_lib_v2.py:705] Step 27800 per-step time 0.107s\r\n",
      "I0401 19:53:51.844022 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.0690844,\r\n",
      " 'Loss/localization_loss': 0.0038412998,\r\n",
      " 'Loss/regularization_loss': 0.08323047,\r\n",
      " 'Loss/total_loss': 0.15615618,\r\n",
      " 'learning_rate': 0.0017649251}\r\n",
      "I0401 19:54:02.432857 134477283476608 model_lib_v2.py:705] Step 27900 per-step time 0.106s\r\n",
      "I0401 19:54:02.433206 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.10596282,\r\n",
      " 'Loss/localization_loss': 0.01892198,\r\n",
      " 'Loss/regularization_loss': 0.083219916,\r\n",
      " 'Loss/total_loss': 0.20810471,\r\n",
      " 'learning_rate': 0.001751931}\r\n",
      "I0401 19:54:13.135597 134477283476608 model_lib_v2.py:705] Step 28000 per-step time 0.107s\r\n",
      "I0401 19:54:13.135919 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.038580235,\r\n",
      " 'Loss/localization_loss': 0.0027521225,\r\n",
      " 'Loss/regularization_loss': 0.08320962,\r\n",
      " 'Loss/total_loss': 0.124541976,\r\n",
      " 'learning_rate': 0.0017389475}\r\n",
      "I0401 19:54:24.473389 134477283476608 model_lib_v2.py:705] Step 28100 per-step time 0.113s\r\n",
      "I0401 19:54:24.473746 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.047159728,\r\n",
      " 'Loss/localization_loss': 0.010667724,\r\n",
      " 'Loss/regularization_loss': 0.08319936,\r\n",
      " 'Loss/total_loss': 0.14102681,\r\n",
      " 'learning_rate': 0.0017259752}\r\n",
      "I0401 19:54:35.125577 134477283476608 model_lib_v2.py:705] Step 28200 per-step time 0.107s\r\n",
      "I0401 19:54:35.125875 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.04996229,\r\n",
      " 'Loss/localization_loss': 0.003543949,\r\n",
      " 'Loss/regularization_loss': 0.08318912,\r\n",
      " 'Loss/total_loss': 0.13669536,\r\n",
      " 'learning_rate': 0.0017130149}\r\n",
      "I0401 19:54:45.811140 134477283476608 model_lib_v2.py:705] Step 28300 per-step time 0.107s\r\n",
      "I0401 19:54:45.811468 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05560515,\r\n",
      " 'Loss/localization_loss': 0.02288864,\r\n",
      " 'Loss/regularization_loss': 0.083179094,\r\n",
      " 'Loss/total_loss': 0.16167289,\r\n",
      " 'learning_rate': 0.0017000665}\r\n",
      "I0401 19:54:56.479257 134477283476608 model_lib_v2.py:705] Step 28400 per-step time 0.107s\r\n",
      "I0401 19:54:56.479617 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.068323605,\r\n",
      " 'Loss/localization_loss': 0.021228613,\r\n",
      " 'Loss/regularization_loss': 0.08316849,\r\n",
      " 'Loss/total_loss': 0.1727207,\r\n",
      " 'learning_rate': 0.0016871311}\r\n",
      "I0401 19:55:07.145166 134477283476608 model_lib_v2.py:705] Step 28500 per-step time 0.107s\r\n",
      "I0401 19:55:07.145492 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.064717785,\r\n",
      " 'Loss/localization_loss': 0.011242538,\r\n",
      " 'Loss/regularization_loss': 0.083158165,\r\n",
      " 'Loss/total_loss': 0.15911849,\r\n",
      " 'learning_rate': 0.0016742089}\r\n",
      "I0401 19:55:17.892604 134477283476608 model_lib_v2.py:705] Step 28600 per-step time 0.107s\r\n",
      "I0401 19:55:17.893003 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.03580572,\r\n",
      " 'Loss/localization_loss': 0.004303315,\r\n",
      " 'Loss/regularization_loss': 0.083147995,\r\n",
      " 'Loss/total_loss': 0.123257026,\r\n",
      " 'learning_rate': 0.001661301}\r\n",
      "I0401 19:55:28.524165 134477283476608 model_lib_v2.py:705] Step 28700 per-step time 0.106s\r\n",
      "I0401 19:55:28.524492 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.050829258,\r\n",
      " 'Loss/localization_loss': 0.006828307,\r\n",
      " 'Loss/regularization_loss': 0.08313772,\r\n",
      " 'Loss/total_loss': 0.14079529,\r\n",
      " 'learning_rate': 0.0016484075}\r\n",
      "I0401 19:55:39.127921 134477283476608 model_lib_v2.py:705] Step 28800 per-step time 0.106s\r\n",
      "I0401 19:55:39.128259 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.03877609,\r\n",
      " 'Loss/localization_loss': 0.0094434265,\r\n",
      " 'Loss/regularization_loss': 0.08312831,\r\n",
      " 'Loss/total_loss': 0.13134784,\r\n",
      " 'learning_rate': 0.0016355289}\r\n",
      "I0401 19:55:49.857363 134477283476608 model_lib_v2.py:705] Step 28900 per-step time 0.107s\r\n",
      "I0401 19:55:49.857725 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.055652507,\r\n",
      " 'Loss/localization_loss': 0.013423193,\r\n",
      " 'Loss/regularization_loss': 0.08311808,\r\n",
      " 'Loss/total_loss': 0.15219378,\r\n",
      " 'learning_rate': 0.001622666}\r\n",
      "I0401 19:56:00.483975 134477283476608 model_lib_v2.py:705] Step 29000 per-step time 0.106s\r\n",
      "I0401 19:56:00.484314 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.12881938,\r\n",
      " 'Loss/localization_loss': 0.044321902,\r\n",
      " 'Loss/regularization_loss': 0.083107986,\r\n",
      " 'Loss/total_loss': 0.25624925,\r\n",
      " 'learning_rate': 0.0016098192}\r\n",
      "I0401 19:56:11.149812 134477283476608 model_lib_v2.py:705] Step 29100 per-step time 0.107s\r\n",
      "I0401 19:56:11.150186 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.098045275,\r\n",
      " 'Loss/localization_loss': 0.01615337,\r\n",
      " 'Loss/regularization_loss': 0.08309886,\r\n",
      " 'Loss/total_loss': 0.1972975,\r\n",
      " 'learning_rate': 0.0015969892}\r\n",
      "I0401 19:56:21.907888 134477283476608 model_lib_v2.py:705] Step 29200 per-step time 0.108s\r\n",
      "I0401 19:56:21.908256 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05484928,\r\n",
      " 'Loss/localization_loss': 0.012814291,\r\n",
      " 'Loss/regularization_loss': 0.08308952,\r\n",
      " 'Loss/total_loss': 0.15075308,\r\n",
      " 'learning_rate': 0.0015841767}\r\n",
      "I0401 19:56:32.523698 134477283476608 model_lib_v2.py:705] Step 29300 per-step time 0.106s\r\n",
      "I0401 19:56:32.524130 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07027877,\r\n",
      " 'Loss/localization_loss': 0.010334699,\r\n",
      " 'Loss/regularization_loss': 0.083079934,\r\n",
      " 'Loss/total_loss': 0.1636934,\r\n",
      " 'learning_rate': 0.0015713816}\r\n",
      "I0401 19:56:43.198514 134477283476608 model_lib_v2.py:705] Step 29400 per-step time 0.107s\r\n",
      "I0401 19:56:43.198838 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.084531,\r\n",
      " 'Loss/localization_loss': 0.0056183184,\r\n",
      " 'Loss/regularization_loss': 0.08307066,\r\n",
      " 'Loss/total_loss': 0.17321998,\r\n",
      " 'learning_rate': 0.001558605}\r\n",
      "I0401 19:56:53.919932 134477283476608 model_lib_v2.py:705] Step 29500 per-step time 0.107s\r\n",
      "I0401 19:56:53.920261 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.017457834,\r\n",
      " 'Loss/localization_loss': 0.0031079198,\r\n",
      " 'Loss/regularization_loss': 0.083060995,\r\n",
      " 'Loss/total_loss': 0.10362675,\r\n",
      " 'learning_rate': 0.0015458477}\r\n",
      "I0401 19:57:04.642689 134477283476608 model_lib_v2.py:705] Step 29600 per-step time 0.107s\r\n",
      "I0401 19:57:04.643010 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.047873817,\r\n",
      " 'Loss/localization_loss': 0.008102183,\r\n",
      " 'Loss/regularization_loss': 0.08305145,\r\n",
      " 'Loss/total_loss': 0.13902745,\r\n",
      " 'learning_rate': 0.0015331092}\r\n",
      "I0401 19:57:15.327563 134477283476608 model_lib_v2.py:705] Step 29700 per-step time 0.107s\r\n",
      "I0401 19:57:15.327900 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.0349054,\r\n",
      " 'Loss/localization_loss': 0.0074779536,\r\n",
      " 'Loss/regularization_loss': 0.08304218,\r\n",
      " 'Loss/total_loss': 0.12542553,\r\n",
      " 'learning_rate': 0.0015203912}\r\n",
      "I0401 19:57:26.091222 134477283476608 model_lib_v2.py:705] Step 29800 per-step time 0.108s\r\n",
      "I0401 19:57:26.091550 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.065202236,\r\n",
      " 'Loss/localization_loss': 0.005921776,\r\n",
      " 'Loss/regularization_loss': 0.08303356,\r\n",
      " 'Loss/total_loss': 0.15415758,\r\n",
      " 'learning_rate': 0.0015076933}\r\n",
      "I0401 19:57:36.693437 134477283476608 model_lib_v2.py:705] Step 29900 per-step time 0.106s\r\n",
      "I0401 19:57:36.693749 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.054977532,\r\n",
      " 'Loss/localization_loss': 0.008742065,\r\n",
      " 'Loss/regularization_loss': 0.083023824,\r\n",
      " 'Loss/total_loss': 0.14674342,\r\n",
      " 'learning_rate': 0.0014950169}\r\n",
      "I0401 19:57:47.363288 134477283476608 model_lib_v2.py:705] Step 30000 per-step time 0.107s\r\n",
      "I0401 19:57:47.363609 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.04692214,\r\n",
      " 'Loss/localization_loss': 0.0027811478,\r\n",
      " 'Loss/regularization_loss': 0.08301536,\r\n",
      " 'Loss/total_loss': 0.13271865,\r\n",
      " 'learning_rate': 0.0014823622}\r\n",
      "I0401 19:57:58.763718 134477283476608 model_lib_v2.py:705] Step 30100 per-step time 0.114s\r\n",
      "I0401 19:57:58.764094 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.085894436,\r\n",
      " 'Loss/localization_loss': 0.014611946,\r\n",
      " 'Loss/regularization_loss': 0.08300608,\r\n",
      " 'Loss/total_loss': 0.18351245,\r\n",
      " 'learning_rate': 0.001469729}\r\n",
      "I0401 19:58:09.469336 134477283476608 model_lib_v2.py:705] Step 30200 per-step time 0.107s\r\n",
      "I0401 19:58:09.469626 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.02374574,\r\n",
      " 'Loss/localization_loss': 0.003495589,\r\n",
      " 'Loss/regularization_loss': 0.08299722,\r\n",
      " 'Loss/total_loss': 0.110238545,\r\n",
      " 'learning_rate': 0.001457119}\r\n",
      "I0401 19:58:20.130053 134477283476608 model_lib_v2.py:705] Step 30300 per-step time 0.107s\r\n",
      "I0401 19:58:20.130360 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.047385663,\r\n",
      " 'Loss/localization_loss': 0.0047641248,\r\n",
      " 'Loss/regularization_loss': 0.08298898,\r\n",
      " 'Loss/total_loss': 0.13513876,\r\n",
      " 'learning_rate': 0.0014445322}\r\n",
      "I0401 19:58:30.832832 134477283476608 model_lib_v2.py:705] Step 30400 per-step time 0.107s\r\n",
      "I0401 19:58:30.833162 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.033463348,\r\n",
      " 'Loss/localization_loss': 0.005734784,\r\n",
      " 'Loss/regularization_loss': 0.08298024,\r\n",
      " 'Loss/total_loss': 0.12217837,\r\n",
      " 'learning_rate': 0.0014319692}\r\n",
      "I0401 19:58:41.454838 134477283476608 model_lib_v2.py:705] Step 30500 per-step time 0.106s\r\n",
      "I0401 19:58:41.455230 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.035233043,\r\n",
      " 'Loss/localization_loss': 0.0028752913,\r\n",
      " 'Loss/regularization_loss': 0.08297118,\r\n",
      " 'Loss/total_loss': 0.12107951,\r\n",
      " 'learning_rate': 0.0014194307}\r\n",
      "I0401 19:58:52.060222 134477283476608 model_lib_v2.py:705] Step 30600 per-step time 0.106s\r\n",
      "I0401 19:58:52.060556 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.037368063,\r\n",
      " 'Loss/localization_loss': 0.006573518,\r\n",
      " 'Loss/regularization_loss': 0.08296289,\r\n",
      " 'Loss/total_loss': 0.12690447,\r\n",
      " 'learning_rate': 0.0014069167}\r\n",
      "I0401 19:59:02.795550 134477283476608 model_lib_v2.py:705] Step 30700 per-step time 0.107s\r\n",
      "I0401 19:59:02.795857 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.034046073,\r\n",
      " 'Loss/localization_loss': 0.0035645922,\r\n",
      " 'Loss/regularization_loss': 0.08295386,\r\n",
      " 'Loss/total_loss': 0.12056453,\r\n",
      " 'learning_rate': 0.0013944283}\r\n",
      "I0401 19:59:13.499425 134477283476608 model_lib_v2.py:705] Step 30800 per-step time 0.107s\r\n",
      "I0401 19:59:13.499825 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.042664025,\r\n",
      " 'Loss/localization_loss': 0.009303729,\r\n",
      " 'Loss/regularization_loss': 0.0829455,\r\n",
      " 'Loss/total_loss': 0.13491327,\r\n",
      " 'learning_rate': 0.0013819662}\r\n",
      "I0401 19:59:24.223323 134477283476608 model_lib_v2.py:705] Step 30900 per-step time 0.107s\r\n",
      "I0401 19:59:24.223671 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07486675,\r\n",
      " 'Loss/localization_loss': 0.011346359,\r\n",
      " 'Loss/regularization_loss': 0.082937054,\r\n",
      " 'Loss/total_loss': 0.16915017,\r\n",
      " 'learning_rate': 0.00136953}\r\n",
      "I0401 19:59:34.935961 134477283476608 model_lib_v2.py:705] Step 31000 per-step time 0.107s\r\n",
      "I0401 19:59:34.936257 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.02535757,\r\n",
      " 'Loss/localization_loss': 0.0052424166,\r\n",
      " 'Loss/regularization_loss': 0.082929276,\r\n",
      " 'Loss/total_loss': 0.113529265,\r\n",
      " 'learning_rate': 0.0013571212}\r\n",
      "I0401 19:59:45.579531 134477283476608 model_lib_v2.py:705] Step 31100 per-step time 0.106s\r\n",
      "I0401 19:59:45.579875 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.045482554,\r\n",
      " 'Loss/localization_loss': 0.0077229873,\r\n",
      " 'Loss/regularization_loss': 0.082921356,\r\n",
      " 'Loss/total_loss': 0.1361269,\r\n",
      " 'learning_rate': 0.0013447396}\r\n",
      "I0401 19:59:56.213261 134477283476608 model_lib_v2.py:705] Step 31200 per-step time 0.106s\r\n",
      "I0401 19:59:56.213612 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.039951902,\r\n",
      " 'Loss/localization_loss': 0.00523212,\r\n",
      " 'Loss/regularization_loss': 0.08291258,\r\n",
      " 'Loss/total_loss': 0.12809661,\r\n",
      " 'learning_rate': 0.0013323863}\r\n",
      "I0401 20:00:06.878745 134477283476608 model_lib_v2.py:705] Step 31300 per-step time 0.107s\r\n",
      "I0401 20:00:06.879078 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.08221016,\r\n",
      " 'Loss/localization_loss': 0.036327988,\r\n",
      " 'Loss/regularization_loss': 0.08290483,\r\n",
      " 'Loss/total_loss': 0.20144299,\r\n",
      " 'learning_rate': 0.0013200616}\r\n",
      "I0401 20:00:17.560544 134477283476608 model_lib_v2.py:705] Step 31400 per-step time 0.107s\r\n",
      "I0401 20:00:17.560889 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.040150013,\r\n",
      " 'Loss/localization_loss': 0.0071145557,\r\n",
      " 'Loss/regularization_loss': 0.08289681,\r\n",
      " 'Loss/total_loss': 0.13016137,\r\n",
      " 'learning_rate': 0.0013077658}\r\n",
      "I0401 20:00:28.280484 134477283476608 model_lib_v2.py:705] Step 31500 per-step time 0.107s\r\n",
      "I0401 20:00:28.280819 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.027805755,\r\n",
      " 'Loss/localization_loss': 0.0026094408,\r\n",
      " 'Loss/regularization_loss': 0.0828886,\r\n",
      " 'Loss/total_loss': 0.113303795,\r\n",
      " 'learning_rate': 0.0012954999}\r\n",
      "I0401 20:00:38.979878 134477283476608 model_lib_v2.py:705] Step 31600 per-step time 0.107s\r\n",
      "I0401 20:00:38.980235 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.03969208,\r\n",
      " 'Loss/localization_loss': 0.009831042,\r\n",
      " 'Loss/regularization_loss': 0.08288124,\r\n",
      " 'Loss/total_loss': 0.13240436,\r\n",
      " 'learning_rate': 0.001283264}\r\n",
      "I0401 20:00:49.547180 134477283476608 model_lib_v2.py:705] Step 31700 per-step time 0.106s\r\n",
      "I0401 20:00:49.547525 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.047198664,\r\n",
      " 'Loss/localization_loss': 0.010815403,\r\n",
      " 'Loss/regularization_loss': 0.08287357,\r\n",
      " 'Loss/total_loss': 0.14088763,\r\n",
      " 'learning_rate': 0.0012710588}\r\n",
      "I0401 20:01:00.225026 134477283476608 model_lib_v2.py:705] Step 31800 per-step time 0.107s\r\n",
      "I0401 20:01:00.225437 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.053656008,\r\n",
      " 'Loss/localization_loss': 0.011843794,\r\n",
      " 'Loss/regularization_loss': 0.08286634,\r\n",
      " 'Loss/total_loss': 0.14836615,\r\n",
      " 'learning_rate': 0.0012588853}\r\n",
      "I0401 20:01:10.904496 134477283476608 model_lib_v2.py:705] Step 31900 per-step time 0.107s\r\n",
      "I0401 20:01:10.904860 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.03939062,\r\n",
      " 'Loss/localization_loss': 0.003016419,\r\n",
      " 'Loss/regularization_loss': 0.082858555,\r\n",
      " 'Loss/total_loss': 0.1252656,\r\n",
      " 'learning_rate': 0.0012467428}\r\n",
      "I0401 20:01:21.733878 134477283476608 model_lib_v2.py:705] Step 32000 per-step time 0.108s\r\n",
      "I0401 20:01:21.734244 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.086883985,\r\n",
      " 'Loss/localization_loss': 0.009858204,\r\n",
      " 'Loss/regularization_loss': 0.082851,\r\n",
      " 'Loss/total_loss': 0.17959319,\r\n",
      " 'learning_rate': 0.001234633}\r\n",
      "I0401 20:01:33.573538 134477283476608 model_lib_v2.py:705] Step 32100 per-step time 0.118s\r\n",
      "I0401 20:01:33.573879 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.040198263,\r\n",
      " 'Loss/localization_loss': 0.006408218,\r\n",
      " 'Loss/regularization_loss': 0.08284309,\r\n",
      " 'Loss/total_loss': 0.12944958,\r\n",
      " 'learning_rate': 0.0012225558}\r\n",
      "I0401 20:01:44.214609 134477283476608 model_lib_v2.py:705] Step 32200 per-step time 0.106s\r\n",
      "I0401 20:01:44.214983 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.075744554,\r\n",
      " 'Loss/localization_loss': 0.0071470197,\r\n",
      " 'Loss/regularization_loss': 0.08283536,\r\n",
      " 'Loss/total_loss': 0.16572693,\r\n",
      " 'learning_rate': 0.0012105122}\r\n",
      "I0401 20:01:54.818880 134477283476608 model_lib_v2.py:705] Step 32300 per-step time 0.106s\r\n",
      "I0401 20:01:54.819280 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.15690489,\r\n",
      " 'Loss/localization_loss': 0.029899681,\r\n",
      " 'Loss/regularization_loss': 0.082828104,\r\n",
      " 'Loss/total_loss': 0.2696327,\r\n",
      " 'learning_rate': 0.0011985025}\r\n",
      "I0401 20:02:05.547063 134477283476608 model_lib_v2.py:705] Step 32400 per-step time 0.107s\r\n",
      "I0401 20:02:05.547400 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.059451178,\r\n",
      " 'Loss/localization_loss': 0.018690836,\r\n",
      " 'Loss/regularization_loss': 0.08282063,\r\n",
      " 'Loss/total_loss': 0.16096264,\r\n",
      " 'learning_rate': 0.0011865267}\r\n",
      "I0401 20:02:16.259422 134477283476608 model_lib_v2.py:705] Step 32500 per-step time 0.107s\r\n",
      "I0401 20:02:16.259767 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.02274663,\r\n",
      " 'Loss/localization_loss': 0.0064720446,\r\n",
      " 'Loss/regularization_loss': 0.08281352,\r\n",
      " 'Loss/total_loss': 0.1120322,\r\n",
      " 'learning_rate': 0.001174586}\r\n",
      "I0401 20:02:26.919586 134477283476608 model_lib_v2.py:705] Step 32600 per-step time 0.107s\r\n",
      "I0401 20:02:26.919907 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07582795,\r\n",
      " 'Loss/localization_loss': 0.02393428,\r\n",
      " 'Loss/regularization_loss': 0.082806215,\r\n",
      " 'Loss/total_loss': 0.18256845,\r\n",
      " 'learning_rate': 0.0011626804}\r\n",
      "I0401 20:02:37.691309 134477283476608 model_lib_v2.py:705] Step 32700 per-step time 0.108s\r\n",
      "I0401 20:02:37.691599 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05691922,\r\n",
      " 'Loss/localization_loss': 0.009478008,\r\n",
      " 'Loss/regularization_loss': 0.082799174,\r\n",
      " 'Loss/total_loss': 0.1491964,\r\n",
      " 'learning_rate': 0.0011508107}\r\n",
      "I0401 20:02:48.362551 134477283476608 model_lib_v2.py:705] Step 32800 per-step time 0.107s\r\n",
      "I0401 20:02:48.362900 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.043788224,\r\n",
      " 'Loss/localization_loss': 0.006502031,\r\n",
      " 'Loss/regularization_loss': 0.082792185,\r\n",
      " 'Loss/total_loss': 0.13308245,\r\n",
      " 'learning_rate': 0.0011389778}\r\n",
      "I0401 20:02:59.082272 134477283476608 model_lib_v2.py:705] Step 32900 per-step time 0.107s\r\n",
      "I0401 20:02:59.082567 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05393902,\r\n",
      " 'Loss/localization_loss': 0.0075788684,\r\n",
      " 'Loss/regularization_loss': 0.08278534,\r\n",
      " 'Loss/total_loss': 0.14430323,\r\n",
      " 'learning_rate': 0.0011271813}\r\n",
      "I0401 20:03:09.853351 134477283476608 model_lib_v2.py:705] Step 33000 per-step time 0.108s\r\n",
      "I0401 20:03:09.853696 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.08981018,\r\n",
      " 'Loss/localization_loss': 0.011667868,\r\n",
      " 'Loss/regularization_loss': 0.082778424,\r\n",
      " 'Loss/total_loss': 0.18425646,\r\n",
      " 'learning_rate': 0.0011154228}\r\n",
      "I0401 20:03:20.513179 134477283476608 model_lib_v2.py:705] Step 33100 per-step time 0.107s\r\n",
      "I0401 20:03:20.513517 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.11694531,\r\n",
      " 'Loss/localization_loss': 0.02651654,\r\n",
      " 'Loss/regularization_loss': 0.08277189,\r\n",
      " 'Loss/total_loss': 0.22623375,\r\n",
      " 'learning_rate': 0.0011037017}\r\n",
      "I0401 20:03:31.142245 134477283476608 model_lib_v2.py:705] Step 33200 per-step time 0.106s\r\n",
      "I0401 20:03:31.142577 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.064290754,\r\n",
      " 'Loss/localization_loss': 0.0044804197,\r\n",
      " 'Loss/regularization_loss': 0.08276501,\r\n",
      " 'Loss/total_loss': 0.1515362,\r\n",
      " 'learning_rate': 0.0010920189}\r\n",
      "I0401 20:03:41.864712 134477283476608 model_lib_v2.py:705] Step 33300 per-step time 0.107s\r\n",
      "I0401 20:03:41.865041 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.04571132,\r\n",
      " 'Loss/localization_loss': 0.0036191924,\r\n",
      " 'Loss/regularization_loss': 0.08275845,\r\n",
      " 'Loss/total_loss': 0.13208896,\r\n",
      " 'learning_rate': 0.0010803755}\r\n",
      "I0401 20:03:52.536265 134477283476608 model_lib_v2.py:705] Step 33400 per-step time 0.107s\r\n",
      "I0401 20:03:52.536579 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.02709694,\r\n",
      " 'Loss/localization_loss': 0.0057560727,\r\n",
      " 'Loss/regularization_loss': 0.082751706,\r\n",
      " 'Loss/total_loss': 0.11560472,\r\n",
      " 'learning_rate': 0.0010687709}\r\n",
      "I0401 20:04:03.162719 134477283476608 model_lib_v2.py:705] Step 33500 per-step time 0.106s\r\n",
      "I0401 20:04:03.163074 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.055814527,\r\n",
      " 'Loss/localization_loss': 0.012273377,\r\n",
      " 'Loss/regularization_loss': 0.082745194,\r\n",
      " 'Loss/total_loss': 0.1508331,\r\n",
      " 'learning_rate': 0.0010572064}\r\n",
      "I0401 20:04:13.854840 134477283476608 model_lib_v2.py:705] Step 33600 per-step time 0.107s\r\n",
      "I0401 20:04:13.855198 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.071495794,\r\n",
      " 'Loss/localization_loss': 0.01987989,\r\n",
      " 'Loss/regularization_loss': 0.08273843,\r\n",
      " 'Loss/total_loss': 0.17411411,\r\n",
      " 'learning_rate': 0.0010456826}\r\n",
      "I0401 20:04:24.489876 134477283476608 model_lib_v2.py:705] Step 33700 per-step time 0.106s\r\n",
      "I0401 20:04:24.490226 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.03732201,\r\n",
      " 'Loss/localization_loss': 0.015228906,\r\n",
      " 'Loss/regularization_loss': 0.082732394,\r\n",
      " 'Loss/total_loss': 0.1352833,\r\n",
      " 'learning_rate': 0.0010341993}\r\n",
      "I0401 20:04:35.137383 134477283476608 model_lib_v2.py:705] Step 33800 per-step time 0.106s\r\n",
      "I0401 20:04:35.137715 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.055488504,\r\n",
      " 'Loss/localization_loss': 0.006749326,\r\n",
      " 'Loss/regularization_loss': 0.082726166,\r\n",
      " 'Loss/total_loss': 0.144964,\r\n",
      " 'learning_rate': 0.0010227574}\r\n",
      "I0401 20:04:45.852312 134477283476608 model_lib_v2.py:705] Step 33900 per-step time 0.107s\r\n",
      "I0401 20:04:45.852630 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05017439,\r\n",
      " 'Loss/localization_loss': 0.0060324273,\r\n",
      " 'Loss/regularization_loss': 0.082719475,\r\n",
      " 'Loss/total_loss': 0.1389263,\r\n",
      " 'learning_rate': 0.0010113576}\r\n",
      "I0401 20:04:56.484290 134477283476608 model_lib_v2.py:705] Step 34000 per-step time 0.106s\r\n",
      "I0401 20:04:56.484580 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.04526174,\r\n",
      " 'Loss/localization_loss': 0.0056299176,\r\n",
      " 'Loss/regularization_loss': 0.08271351,\r\n",
      " 'Loss/total_loss': 0.13360517,\r\n",
      " 'learning_rate': 0.0009999999}\r\n",
      "I0401 20:05:07.836204 134477283476608 model_lib_v2.py:705] Step 34100 per-step time 0.114s\r\n",
      "I0401 20:05:07.836550 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05372934,\r\n",
      " 'Loss/localization_loss': 0.014845865,\r\n",
      " 'Loss/regularization_loss': 0.082707085,\r\n",
      " 'Loss/total_loss': 0.15128228,\r\n",
      " 'learning_rate': 0.0009886854}\r\n",
      "I0401 20:05:18.558918 134477283476608 model_lib_v2.py:705] Step 34200 per-step time 0.107s\r\n",
      "I0401 20:05:18.559257 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.039295144,\r\n",
      " 'Loss/localization_loss': 0.0041321446,\r\n",
      " 'Loss/regularization_loss': 0.08270128,\r\n",
      " 'Loss/total_loss': 0.12612857,\r\n",
      " 'learning_rate': 0.0009774135}\r\n",
      "I0401 20:05:29.213814 134477283476608 model_lib_v2.py:705] Step 34300 per-step time 0.107s\r\n",
      "I0401 20:05:29.214188 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.052546386,\r\n",
      " 'Loss/localization_loss': 0.016993808,\r\n",
      " 'Loss/regularization_loss': 0.082695596,\r\n",
      " 'Loss/total_loss': 0.15223579,\r\n",
      " 'learning_rate': 0.0009661861}\r\n",
      "I0401 20:05:39.826967 134477283476608 model_lib_v2.py:705] Step 34400 per-step time 0.106s\r\n",
      "I0401 20:05:39.827267 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.038797963,\r\n",
      " 'Loss/localization_loss': 0.007031615,\r\n",
      " 'Loss/regularization_loss': 0.082689464,\r\n",
      " 'Loss/total_loss': 0.12851904,\r\n",
      " 'learning_rate': 0.0009550031}\r\n",
      "I0401 20:05:50.559382 134477283476608 model_lib_v2.py:705] Step 34500 per-step time 0.107s\r\n",
      "I0401 20:05:50.559686 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.033195227,\r\n",
      " 'Loss/localization_loss': 0.0069554634,\r\n",
      " 'Loss/regularization_loss': 0.082683705,\r\n",
      " 'Loss/total_loss': 0.1228344,\r\n",
      " 'learning_rate': 0.0009438643}\r\n",
      "I0401 20:06:01.173497 134477283476608 model_lib_v2.py:705] Step 34600 per-step time 0.106s\r\n",
      "I0401 20:06:01.173816 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.027303234,\r\n",
      " 'Loss/localization_loss': 0.0034616233,\r\n",
      " 'Loss/regularization_loss': 0.08267793,\r\n",
      " 'Loss/total_loss': 0.113442786,\r\n",
      " 'learning_rate': 0.0009327709}\r\n",
      "I0401 20:06:11.810509 134477283476608 model_lib_v2.py:705] Step 34700 per-step time 0.106s\r\n",
      "I0401 20:06:11.810840 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.025540547,\r\n",
      " 'Loss/localization_loss': 0.0038315093,\r\n",
      " 'Loss/regularization_loss': 0.0826723,\r\n",
      " 'Loss/total_loss': 0.11204436,\r\n",
      " 'learning_rate': 0.000921723}\r\n",
      "I0401 20:06:22.556180 134477283476608 model_lib_v2.py:705] Step 34800 per-step time 0.107s\r\n",
      "I0401 20:06:22.556508 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.048687905,\r\n",
      " 'Loss/localization_loss': 0.011765501,\r\n",
      " 'Loss/regularization_loss': 0.08266661,\r\n",
      " 'Loss/total_loss': 0.14312002,\r\n",
      " 'learning_rate': 0.00091072195}\r\n",
      "I0401 20:06:33.186549 134477283476608 model_lib_v2.py:705] Step 34900 per-step time 0.106s\r\n",
      "I0401 20:06:33.186867 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.08338505,\r\n",
      " 'Loss/localization_loss': 0.0073603946,\r\n",
      " 'Loss/regularization_loss': 0.08266114,\r\n",
      " 'Loss/total_loss': 0.17340657,\r\n",
      " 'learning_rate': 0.0008997671}\r\n",
      "I0401 20:06:43.882982 134477283476608 model_lib_v2.py:705] Step 35000 per-step time 0.107s\r\n",
      "I0401 20:06:43.883282 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05215216,\r\n",
      " 'Loss/localization_loss': 0.015769888,\r\n",
      " 'Loss/regularization_loss': 0.08265526,\r\n",
      " 'Loss/total_loss': 0.1505773,\r\n",
      " 'learning_rate': 0.00088885933}\r\n",
      "I0401 20:06:54.639117 134477283476608 model_lib_v2.py:705] Step 35100 per-step time 0.108s\r\n",
      "I0401 20:06:54.639446 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.023461249,\r\n",
      " 'Loss/localization_loss': 0.005162428,\r\n",
      " 'Loss/regularization_loss': 0.08264965,\r\n",
      " 'Loss/total_loss': 0.111273326,\r\n",
      " 'learning_rate': 0.00087799947}\r\n",
      "I0401 20:07:05.329741 134477283476608 model_lib_v2.py:705] Step 35200 per-step time 0.107s\r\n",
      "I0401 20:07:05.330072 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.03349053,\r\n",
      " 'Loss/localization_loss': 0.0056926063,\r\n",
      " 'Loss/regularization_loss': 0.082644336,\r\n",
      " 'Loss/total_loss': 0.12182747,\r\n",
      " 'learning_rate': 0.0008671874}\r\n",
      "I0401 20:07:16.024724 134477283476608 model_lib_v2.py:705] Step 35300 per-step time 0.107s\r\n",
      "I0401 20:07:16.025060 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05068509,\r\n",
      " 'Loss/localization_loss': 0.005801488,\r\n",
      " 'Loss/regularization_loss': 0.08263894,\r\n",
      " 'Loss/total_loss': 0.13912553,\r\n",
      " 'learning_rate': 0.00085642375}\r\n",
      "I0401 20:07:26.732883 134477283476608 model_lib_v2.py:705] Step 35400 per-step time 0.107s\r\n",
      "I0401 20:07:26.733412 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.051940583,\r\n",
      " 'Loss/localization_loss': 0.014422314,\r\n",
      " 'Loss/regularization_loss': 0.08263395,\r\n",
      " 'Loss/total_loss': 0.14899684,\r\n",
      " 'learning_rate': 0.0008457096}\r\n",
      "I0401 20:07:37.448017 134477283476608 model_lib_v2.py:705] Step 35500 per-step time 0.107s\r\n",
      "I0401 20:07:37.448350 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.04985042,\r\n",
      " 'Loss/localization_loss': 0.005662817,\r\n",
      " 'Loss/regularization_loss': 0.08262882,\r\n",
      " 'Loss/total_loss': 0.13814205,\r\n",
      " 'learning_rate': 0.0008350444}\r\n",
      "I0401 20:07:48.059676 134477283476608 model_lib_v2.py:705] Step 35600 per-step time 0.106s\r\n",
      "I0401 20:07:48.060005 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.04546127,\r\n",
      " 'Loss/localization_loss': 0.005738016,\r\n",
      " 'Loss/regularization_loss': 0.08262366,\r\n",
      " 'Loss/total_loss': 0.13382295,\r\n",
      " 'learning_rate': 0.00082442956}\r\n",
      "I0401 20:07:58.774665 134477283476608 model_lib_v2.py:705] Step 35700 per-step time 0.107s\r\n",
      "I0401 20:07:58.775028 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.03588858,\r\n",
      " 'Loss/localization_loss': 0.005327448,\r\n",
      " 'Loss/regularization_loss': 0.08261878,\r\n",
      " 'Loss/total_loss': 0.1238348,\r\n",
      " 'learning_rate': 0.00081386475}\r\n",
      "I0401 20:08:09.393812 134477283476608 model_lib_v2.py:705] Step 35800 per-step time 0.106s\r\n",
      "I0401 20:08:09.394158 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.046888907,\r\n",
      " 'Loss/localization_loss': 0.0088718785,\r\n",
      " 'Loss/regularization_loss': 0.08261359,\r\n",
      " 'Loss/total_loss': 0.13837437,\r\n",
      " 'learning_rate': 0.0008033506}\r\n",
      "I0401 20:08:20.029850 134477283476608 model_lib_v2.py:705] Step 35900 per-step time 0.106s\r\n",
      "I0401 20:08:20.030206 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.030595485,\r\n",
      " 'Loss/localization_loss': 0.005291931,\r\n",
      " 'Loss/regularization_loss': 0.082608715,\r\n",
      " 'Loss/total_loss': 0.118496135,\r\n",
      " 'learning_rate': 0.0007928882}\r\n",
      "I0401 20:08:30.815854 134477283476608 model_lib_v2.py:705] Step 36000 per-step time 0.108s\r\n",
      "I0401 20:08:30.816223 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05013296,\r\n",
      " 'Loss/localization_loss': 0.009119641,\r\n",
      " 'Loss/regularization_loss': 0.0826039,\r\n",
      " 'Loss/total_loss': 0.1418565,\r\n",
      " 'learning_rate': 0.0007824771}\r\n",
      "I0401 20:08:42.178757 134477283476608 model_lib_v2.py:705] Step 36100 per-step time 0.114s\r\n",
      "I0401 20:08:42.179129 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.038508464,\r\n",
      " 'Loss/localization_loss': 0.006199386,\r\n",
      " 'Loss/regularization_loss': 0.08259881,\r\n",
      " 'Loss/total_loss': 0.12730667,\r\n",
      " 'learning_rate': 0.0007721181}\r\n",
      "I0401 20:08:52.820488 134477283476608 model_lib_v2.py:705] Step 36200 per-step time 0.106s\r\n",
      "I0401 20:08:52.820819 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.0858201,\r\n",
      " 'Loss/localization_loss': 0.012847327,\r\n",
      " 'Loss/regularization_loss': 0.082593895,\r\n",
      " 'Loss/total_loss': 0.18126133,\r\n",
      " 'learning_rate': 0.00076181215}\r\n",
      "I0401 20:09:03.557114 134477283476608 model_lib_v2.py:705] Step 36300 per-step time 0.107s\r\n",
      "I0401 20:09:03.557451 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.047430538,\r\n",
      " 'Loss/localization_loss': 0.006782931,\r\n",
      " 'Loss/regularization_loss': 0.08258951,\r\n",
      " 'Loss/total_loss': 0.13680297,\r\n",
      " 'learning_rate': 0.0007515588}\r\n",
      "I0401 20:09:14.256555 134477283476608 model_lib_v2.py:705] Step 36400 per-step time 0.107s\r\n",
      "I0401 20:09:14.256897 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05525856,\r\n",
      " 'Loss/localization_loss': 0.011978971,\r\n",
      " 'Loss/regularization_loss': 0.082585186,\r\n",
      " 'Loss/total_loss': 0.14982271,\r\n",
      " 'learning_rate': 0.000741359}\r\n",
      "I0401 20:09:24.911706 134477283476608 model_lib_v2.py:705] Step 36500 per-step time 0.107s\r\n",
      "I0401 20:09:24.912069 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.063846216,\r\n",
      " 'Loss/localization_loss': 0.004431154,\r\n",
      " 'Loss/regularization_loss': 0.082580544,\r\n",
      " 'Loss/total_loss': 0.15085791,\r\n",
      " 'learning_rate': 0.00073121313}\r\n",
      "I0401 20:09:35.672971 134477283476608 model_lib_v2.py:705] Step 36600 per-step time 0.108s\r\n",
      "I0401 20:09:35.673343 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.048514787,\r\n",
      " 'Loss/localization_loss': 0.0060618636,\r\n",
      " 'Loss/regularization_loss': 0.08257602,\r\n",
      " 'Loss/total_loss': 0.13715267,\r\n",
      " 'learning_rate': 0.00072112196}\r\n",
      "I0401 20:09:46.340504 134477283476608 model_lib_v2.py:705] Step 36700 per-step time 0.107s\r\n",
      "I0401 20:09:46.340861 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.076690085,\r\n",
      " 'Loss/localization_loss': 0.017216545,\r\n",
      " 'Loss/regularization_loss': 0.08257175,\r\n",
      " 'Loss/total_loss': 0.17647839,\r\n",
      " 'learning_rate': 0.0007110851}\r\n",
      "I0401 20:09:57.019800 134477283476608 model_lib_v2.py:705] Step 36800 per-step time 0.107s\r\n",
      "I0401 20:09:57.020164 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.031909548,\r\n",
      " 'Loss/localization_loss': 0.0044582384,\r\n",
      " 'Loss/regularization_loss': 0.08256717,\r\n",
      " 'Loss/total_loss': 0.11893496,\r\n",
      " 'learning_rate': 0.0007011036}\r\n",
      "I0401 20:10:07.763183 134477283476608 model_lib_v2.py:705] Step 36900 per-step time 0.107s\r\n",
      "I0401 20:10:07.763513 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.039533474,\r\n",
      " 'Loss/localization_loss': 0.004815604,\r\n",
      " 'Loss/regularization_loss': 0.08256276,\r\n",
      " 'Loss/total_loss': 0.12691183,\r\n",
      " 'learning_rate': 0.000691178}\r\n",
      "I0401 20:10:18.381147 134477283476608 model_lib_v2.py:705] Step 37000 per-step time 0.106s\r\n",
      "I0401 20:10:18.381472 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.0925988,\r\n",
      " 'Loss/localization_loss': 0.036510274,\r\n",
      " 'Loss/regularization_loss': 0.08255823,\r\n",
      " 'Loss/total_loss': 0.21166731,\r\n",
      " 'learning_rate': 0.00068130856}\r\n",
      "I0401 20:10:29.066557 134477283476608 model_lib_v2.py:705] Step 37100 per-step time 0.107s\r\n",
      "I0401 20:10:29.066889 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.040529262,\r\n",
      " 'Loss/localization_loss': 0.0040331404,\r\n",
      " 'Loss/regularization_loss': 0.08255416,\r\n",
      " 'Loss/total_loss': 0.12711656,\r\n",
      " 'learning_rate': 0.0006714951}\r\n",
      "I0401 20:10:39.785652 134477283476608 model_lib_v2.py:705] Step 37200 per-step time 0.107s\r\n",
      "I0401 20:10:39.786017 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05142067,\r\n",
      " 'Loss/localization_loss': 0.0058224956,\r\n",
      " 'Loss/regularization_loss': 0.08255007,\r\n",
      " 'Loss/total_loss': 0.13979323,\r\n",
      " 'learning_rate': 0.0006617387}\r\n",
      "I0401 20:10:50.415239 134477283476608 model_lib_v2.py:705] Step 37300 per-step time 0.106s\r\n",
      "I0401 20:10:50.415565 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.033137266,\r\n",
      " 'Loss/localization_loss': 0.0050330246,\r\n",
      " 'Loss/regularization_loss': 0.08254576,\r\n",
      " 'Loss/total_loss': 0.12071605,\r\n",
      " 'learning_rate': 0.00065203954}\r\n",
      "I0401 20:11:01.108159 134477283476608 model_lib_v2.py:705] Step 37400 per-step time 0.107s\r\n",
      "I0401 20:11:01.108514 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.040876806,\r\n",
      " 'Loss/localization_loss': 0.0121234255,\r\n",
      " 'Loss/regularization_loss': 0.082542,\r\n",
      " 'Loss/total_loss': 0.13554223,\r\n",
      " 'learning_rate': 0.0006423985}\r\n",
      "I0401 20:11:11.847060 134477283476608 model_lib_v2.py:705] Step 37500 per-step time 0.107s\r\n",
      "I0401 20:11:11.847390 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.054796953,\r\n",
      " 'Loss/localization_loss': 0.009876885,\r\n",
      " 'Loss/regularization_loss': 0.08253819,\r\n",
      " 'Loss/total_loss': 0.14721203,\r\n",
      " 'learning_rate': 0.0006328153}\r\n",
      "I0401 20:11:22.492801 134477283476608 model_lib_v2.py:705] Step 37600 per-step time 0.106s\r\n",
      "I0401 20:11:22.493142 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.02122149,\r\n",
      " 'Loss/localization_loss': 0.0038583023,\r\n",
      " 'Loss/regularization_loss': 0.08253391,\r\n",
      " 'Loss/total_loss': 0.107613705,\r\n",
      " 'learning_rate': 0.00062329054}\r\n",
      "I0401 20:11:33.109914 134477283476608 model_lib_v2.py:705] Step 37700 per-step time 0.106s\r\n",
      "I0401 20:11:33.110243 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07452435,\r\n",
      " 'Loss/localization_loss': 0.014521376,\r\n",
      " 'Loss/regularization_loss': 0.08253018,\r\n",
      " 'Loss/total_loss': 0.1715759,\r\n",
      " 'learning_rate': 0.0006138252}\r\n",
      "I0401 20:11:43.872710 134477283476608 model_lib_v2.py:705] Step 37800 per-step time 0.108s\r\n",
      "I0401 20:11:43.873080 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.042212088,\r\n",
      " 'Loss/localization_loss': 0.011355955,\r\n",
      " 'Loss/regularization_loss': 0.082526386,\r\n",
      " 'Loss/total_loss': 0.13609442,\r\n",
      " 'learning_rate': 0.0006044189}\r\n",
      "I0401 20:11:54.557760 134477283476608 model_lib_v2.py:705] Step 37900 per-step time 0.107s\r\n",
      "I0401 20:11:54.558109 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.04922671,\r\n",
      " 'Loss/localization_loss': 0.011144043,\r\n",
      " 'Loss/regularization_loss': 0.08252285,\r\n",
      " 'Loss/total_loss': 0.1428936,\r\n",
      " 'learning_rate': 0.0005950724}\r\n",
      "I0401 20:12:05.254286 134477283476608 model_lib_v2.py:705] Step 38000 per-step time 0.107s\r\n",
      "I0401 20:12:05.254640 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05585741,\r\n",
      " 'Loss/localization_loss': 0.011333767,\r\n",
      " 'Loss/regularization_loss': 0.08251926,\r\n",
      " 'Loss/total_loss': 0.14971045,\r\n",
      " 'learning_rate': 0.0005857865}\r\n",
      "I0401 20:12:16.691633 134477283476608 model_lib_v2.py:705] Step 38100 per-step time 0.114s\r\n",
      "I0401 20:12:16.692142 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.043124773,\r\n",
      " 'Loss/localization_loss': 0.0028125257,\r\n",
      " 'Loss/regularization_loss': 0.0825157,\r\n",
      " 'Loss/total_loss': 0.128453,\r\n",
      " 'learning_rate': 0.00057656073}\r\n",
      "I0401 20:12:27.370167 134477283476608 model_lib_v2.py:705] Step 38200 per-step time 0.107s\r\n",
      "I0401 20:12:27.370485 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.052766193,\r\n",
      " 'Loss/localization_loss': 0.0077365404,\r\n",
      " 'Loss/regularization_loss': 0.082512096,\r\n",
      " 'Loss/total_loss': 0.14301483,\r\n",
      " 'learning_rate': 0.0005673963}\r\n",
      "I0401 20:12:38.054932 134477283476608 model_lib_v2.py:705] Step 38300 per-step time 0.107s\r\n",
      "I0401 20:12:38.055275 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.10983103,\r\n",
      " 'Loss/localization_loss': 0.010559842,\r\n",
      " 'Loss/regularization_loss': 0.08250869,\r\n",
      " 'Loss/total_loss': 0.20289956,\r\n",
      " 'learning_rate': 0.00055829244}\r\n",
      "I0401 20:12:48.814165 134477283476608 model_lib_v2.py:705] Step 38400 per-step time 0.108s\r\n",
      "I0401 20:12:48.814490 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05793497,\r\n",
      " 'Loss/localization_loss': 0.0073100743,\r\n",
      " 'Loss/regularization_loss': 0.0825052,\r\n",
      " 'Loss/total_loss': 0.14775024,\r\n",
      " 'learning_rate': 0.0005492511}\r\n",
      "I0401 20:12:59.471841 134477283476608 model_lib_v2.py:705] Step 38500 per-step time 0.107s\r\n",
      "I0401 20:12:59.472192 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.07586487,\r\n",
      " 'Loss/localization_loss': 0.017129324,\r\n",
      " 'Loss/regularization_loss': 0.082501724,\r\n",
      " 'Loss/total_loss': 0.17549592,\r\n",
      " 'learning_rate': 0.0005402719}\r\n",
      "I0401 20:13:10.104751 134477283476608 model_lib_v2.py:705] Step 38600 per-step time 0.106s\r\n",
      "I0401 20:13:10.105097 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.052192975,\r\n",
      " 'Loss/localization_loss': 0.024252357,\r\n",
      " 'Loss/regularization_loss': 0.08249833,\r\n",
      " 'Loss/total_loss': 0.15894365,\r\n",
      " 'learning_rate': 0.0005313549}\r\n",
      "I0401 20:13:20.791971 134477283476608 model_lib_v2.py:705] Step 38700 per-step time 0.107s\r\n",
      "I0401 20:13:20.792305 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.053824812,\r\n",
      " 'Loss/localization_loss': 0.009111504,\r\n",
      " 'Loss/regularization_loss': 0.08249502,\r\n",
      " 'Loss/total_loss': 0.14543134,\r\n",
      " 'learning_rate': 0.0005225009}\r\n",
      "I0401 20:13:31.447116 134477283476608 model_lib_v2.py:705] Step 38800 per-step time 0.107s\r\n",
      "I0401 20:13:31.447451 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.026738802,\r\n",
      " 'Loss/localization_loss': 0.008195515,\r\n",
      " 'Loss/regularization_loss': 0.08249171,\r\n",
      " 'Loss/total_loss': 0.11742602,\r\n",
      " 'learning_rate': 0.00051371043}\r\n",
      "I0401 20:13:42.111090 134477283476608 model_lib_v2.py:705] Step 38900 per-step time 0.107s\r\n",
      "I0401 20:13:42.111436 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05547387,\r\n",
      " 'Loss/localization_loss': 0.021649636,\r\n",
      " 'Loss/regularization_loss': 0.08248884,\r\n",
      " 'Loss/total_loss': 0.15961236,\r\n",
      " 'learning_rate': 0.00050498336}\r\n",
      "I0401 20:13:52.813101 134477283476608 model_lib_v2.py:705] Step 39000 per-step time 0.107s\r\n",
      "I0401 20:13:52.813423 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.018443426,\r\n",
      " 'Loss/localization_loss': 0.004423221,\r\n",
      " 'Loss/regularization_loss': 0.082485415,\r\n",
      " 'Loss/total_loss': 0.10535206,\r\n",
      " 'learning_rate': 0.00049632025}\r\n",
      "I0401 20:14:03.461029 134477283476608 model_lib_v2.py:705] Step 39100 per-step time 0.106s\r\n",
      "I0401 20:14:03.461341 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.08193506,\r\n",
      " 'Loss/localization_loss': 0.031264294,\r\n",
      " 'Loss/regularization_loss': 0.08248236,\r\n",
      " 'Loss/total_loss': 0.19568172,\r\n",
      " 'learning_rate': 0.00048772158}\r\n",
      "I0401 20:14:14.149836 134477283476608 model_lib_v2.py:705] Step 39200 per-step time 0.107s\r\n",
      "I0401 20:14:14.150187 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.040138993,\r\n",
      " 'Loss/localization_loss': 0.006860433,\r\n",
      " 'Loss/regularization_loss': 0.0824792,\r\n",
      " 'Loss/total_loss': 0.12947863,\r\n",
      " 'learning_rate': 0.000479188}\r\n",
      "I0401 20:14:24.889339 134477283476608 model_lib_v2.py:705] Step 39300 per-step time 0.107s\r\n",
      "I0401 20:14:24.889664 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.034583896,\r\n",
      " 'Loss/localization_loss': 0.004502872,\r\n",
      " 'Loss/regularization_loss': 0.08247627,\r\n",
      " 'Loss/total_loss': 0.12156304,\r\n",
      " 'learning_rate': 0.00047071936}\r\n",
      "I0401 20:14:35.523644 134477283476608 model_lib_v2.py:705] Step 39400 per-step time 0.106s\r\n",
      "I0401 20:14:35.523992 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.04109928,\r\n",
      " 'Loss/localization_loss': 0.008623693,\r\n",
      " 'Loss/regularization_loss': 0.082473315,\r\n",
      " 'Loss/total_loss': 0.13219629,\r\n",
      " 'learning_rate': 0.00046231606}\r\n",
      "I0401 20:14:46.114937 134477283476608 model_lib_v2.py:705] Step 39500 per-step time 0.106s\r\n",
      "I0401 20:14:46.115289 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.04706062,\r\n",
      " 'Loss/localization_loss': 0.004662215,\r\n",
      " 'Loss/regularization_loss': 0.08247062,\r\n",
      " 'Loss/total_loss': 0.13419345,\r\n",
      " 'learning_rate': 0.00045397904}\r\n",
      "I0401 20:14:56.802279 134477283476608 model_lib_v2.py:705] Step 39600 per-step time 0.107s\r\n",
      "I0401 20:14:56.802585 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.028410127,\r\n",
      " 'Loss/localization_loss': 0.008133816,\r\n",
      " 'Loss/regularization_loss': 0.082467556,\r\n",
      " 'Loss/total_loss': 0.1190115,\r\n",
      " 'learning_rate': 0.00044570793}\r\n",
      "I0401 20:15:07.494220 134477283476608 model_lib_v2.py:705] Step 39700 per-step time 0.107s\r\n",
      "I0401 20:15:07.494563 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.061711967,\r\n",
      " 'Loss/localization_loss': 0.0063103074,\r\n",
      " 'Loss/regularization_loss': 0.08246494,\r\n",
      " 'Loss/total_loss': 0.15048721,\r\n",
      " 'learning_rate': 0.0004375037}\r\n",
      "I0401 20:15:18.161344 134477283476608 model_lib_v2.py:705] Step 39800 per-step time 0.107s\r\n",
      "I0401 20:15:18.161677 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.04903825,\r\n",
      " 'Loss/localization_loss': 0.005365115,\r\n",
      " 'Loss/regularization_loss': 0.0824622,\r\n",
      " 'Loss/total_loss': 0.13686556,\r\n",
      " 'learning_rate': 0.00042936613}\r\n",
      "I0401 20:15:28.885515 134477283476608 model_lib_v2.py:705] Step 39900 per-step time 0.107s\r\n",
      "I0401 20:15:28.885935 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.039816856,\r\n",
      " 'Loss/localization_loss': 0.0061694374,\r\n",
      " 'Loss/regularization_loss': 0.08245957,\r\n",
      " 'Loss/total_loss': 0.12844586,\r\n",
      " 'learning_rate': 0.0004212958}\r\n",
      "I0401 20:15:39.510783 134477283476608 model_lib_v2.py:705] Step 40000 per-step time 0.106s\r\n",
      "I0401 20:15:39.511116 134477283476608 model_lib_v2.py:708] {'Loss/classification_loss': 0.05009875,\r\n",
      " 'Loss/localization_loss': 0.01139294,\r\n",
      " 'Loss/regularization_loss': 0.08245678,\r\n",
      " 'Loss/total_loss': 0.14394847,\r\n",
      " 'learning_rate': 0.00041329337}\r\n"
     ]
    }
   ],
   "source": [
    "!rm -rf {HOMEFOLDER}training_progress\n",
    "# Run training!\n",
    "!python {HOMEFOLDER}models/research/object_detection/model_main_tf2.py \\\n",
    "    --pipeline_config_path={pipeline_file} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --alsologtostderr \\\n",
    "    --checkpoint_every_n={checkpoint_every} \\\n",
    "    --num_train_steps={num_steps} \\\n",
    "    --num_workers=2 \\\n",
    "    --sample_1_of_n_eval_examples=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1483398d",
   "metadata": {
    "id": "WHxbX4ZpzXIv",
    "papermill": {
     "duration": 0.052635,
     "end_time": "2025-04-01T20:15:43.441344",
     "exception": false,
     "start_time": "2025-04-01T20:15:43.388709",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Feel free to stop training early. Check the 'training_progress' folder to see all training checkpoints.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a294b98",
   "metadata": {
    "id": "kPg8oMnQDYKl",
    "papermill": {
     "duration": 0.052569,
     "end_time": "2025-04-01T20:15:43.546143",
     "exception": false,
     "start_time": "2025-04-01T20:15:43.493574",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 5.&nbsp;Convert Model to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "062da402",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T20:15:43.652360Z",
     "iopub.status.busy": "2025-04-01T20:15:43.652080Z",
     "iopub.status.idle": "2025-04-01T20:16:25.254842Z",
     "shell.execute_reply": "2025-04-01T20:16:25.253970Z"
    },
    "id": "RaUU8tBlHifd",
    "papermill": {
     "duration": 41.657752,
     "end_time": "2025-04-01T20:16:25.256227",
     "exception": false,
     "start_time": "2025-04-01T20:15:43.598475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/output\n",
      "2025-04-01 20:15:44.361633: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2025-04-01 20:15:44.361687: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2025-04-01 20:15:44.364015: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "I0401 20:15:51.100952 136492190717056 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\r\n",
      "I0401 20:15:52.599168 136492190717056 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\r\n",
      "I0401 20:15:52.599447 136492190717056 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\r\n",
      "I0401 20:15:52.599619 136492190717056 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\r\n",
      "I0401 20:15:52.599761 136492190717056 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\r\n",
      "I0401 20:15:52.599893 136492190717056 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\r\n",
      "I0401 20:15:52.600040 136492190717056 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\r\n",
      "I0401 20:15:54.229846 136492190717056 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\r\n",
      "I0401 20:15:55.044283 136492190717056 signature_serialization.py:156] Function `inference_fn` contains input name(s) resource with unsupported characters which will be renamed to boxpredictor_convolutionalclasshead_5_classpredictor_biasadd_readvariableop_resource in the SavedModel.\r\n",
      "I0401 20:15:55.940784 136492190717056 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\r\n",
      "W0401 20:15:56.754731 136492190717056 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7c2316ac19f0>, because it is not built.\r\n",
      "I0401 20:16:07.904793 136492190717056 save.py:289] Found untraced functions such as BoxPredictor_layer_call_fn, BoxPredictor_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 122). These functions will not be directly callable after loading.\r\n",
      "I0401 20:16:12.780842 136492190717056 builder_impl.py:801] Assets written to: /kaggle/output/saved_model/assets\r\n",
      "I0401 20:16:13.026763 136492190717056 fingerprinting_utils.py:49] Writing fingerprint to /kaggle/output/saved_model/fingerprint.pb\r\n",
      "cp: cannot stat '/kaggle/working/models/mymodel/pipeline_file.config': No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "#remove final output folder if it exists\n",
    "if os.path.exists(FINALOUTPUTFOLDER) and os.path.isdir(FINALOUTPUTFOLDER):\n",
    "  shutil.rmtree(FINALOUTPUTFOLDER)\n",
    "\n",
    "# Make a directory to store the trained TFLite model\n",
    "!mkdir {FINALOUTPUTFOLDER}\n",
    "print(FINALOUTPUTFOLDER)\n",
    "# Export graph\n",
    "# Path to training directory (the conversion script automatically chooses the highest checkpoint file)\n",
    "last_model_path = HOMEFOLDER+'training_progress'\n",
    "exporter_path = HOMEFOLDER+'models/research/object_detection/export_tflite_graph_tf2.py'\n",
    "output_directory = FINALOUTPUTFOLDER\n",
    "\n",
    "!python $exporter_path \\\n",
    "    --trained_checkpoint_dir $last_model_path \\\n",
    "    --output_directory $output_directory \\\n",
    "    --pipeline_config_path $pipeline_file\n",
    "\n",
    "# Convert to .tflite Flatbuffer\n",
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(FINALOUTPUTFOLDER+'/saved_model')\n",
    "tflite_model = converter.convert()\n",
    "model_path_32bit = FINALOUTPUTFOLDER+'/limelight_neural_detector_32bit.tflite'\n",
    "with open(model_path_32bit, 'wb') as f:\n",
    "  f.write(tflite_model)\n",
    "\n",
    "!cp {HOMEFOLDER}limelight_neural_detector_labels.txt {FINALOUTPUTFOLDER}\n",
    "!cp {HOMEFOLDER}models/mymodel/pipeline_file.config {FINALOUTPUTFOLDER}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e66ab827",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T20:16:25.363471Z",
     "iopub.status.busy": "2025-04-01T20:16:25.363181Z",
     "iopub.status.idle": "2025-04-01T20:17:06.380182Z",
     "shell.execute_reply": "2025-04-01T20:17:06.379090Z"
    },
    "id": "gqahbHU1suBi",
    "papermill": {
     "duration": 41.072486,
     "end_time": "2025-04-01T20:17:06.381863",
     "exception": false,
     "start_time": "2025-04-01T20:16:25.309377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-01 20:16:25.933362: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\r\n",
      "2025-04-01 20:16:25.933415: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\r\n",
      "2025-04-01 20:16:25.934788: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\r\n",
      "I0401 20:16:32.517673 131960541856896 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\r\n",
      "I0401 20:16:34.012026 131960541856896 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\r\n",
      "I0401 20:16:34.012319 131960541856896 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\r\n",
      "I0401 20:16:34.012482 131960541856896 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\r\n",
      "I0401 20:16:34.012625 131960541856896 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\r\n",
      "I0401 20:16:34.012757 131960541856896 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\r\n",
      "I0401 20:16:34.012889 131960541856896 convolutional_keras_box_predictor.py:152] depth of additional conv before box predictor: 0\r\n",
      "I0401 20:16:35.480860 131960541856896 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\r\n",
      "I0401 20:16:36.476977 131960541856896 signature_serialization.py:156] Function `inference_fn` contains input name(s) resource with unsupported characters which will be renamed to boxpredictor_convolutionalclasshead_5_classpredictor_biasadd_readvariableop_resource in the SavedModel.\r\n",
      "I0401 20:16:37.410855 131960541856896 api.py:460] feature_map_spatial_dims: [(19, 19), (10, 10), (5, 5), (3, 3), (2, 2), (1, 1)]\r\n",
      "W0401 20:16:38.184352 131960541856896 save_impl.py:66] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7803f8ba62f0>, because it is not built.\r\n",
      "I0401 20:16:49.174451 131960541856896 save.py:289] Found untraced functions such as BoxPredictor_layer_call_fn, BoxPredictor_layer_call_and_return_conditional_losses, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 122). These functions will not be directly callable after loading.\r\n",
      "I0401 20:16:54.137235 131960541856896 builder_impl.py:801] Assets written to: /kaggle/output/saved_model/assets\r\n",
      "I0401 20:16:54.392770 131960541856896 fingerprinting_utils.py:49] Writing fingerprint to /kaggle/output/saved_model/fingerprint.pb\r\n"
     ]
    }
   ],
   "source": [
    "# Export graph\n",
    "# Path to training directory (the conversion script automatically chooses the highest checkpoint file)\n",
    "last_model_path = HOMEFOLDER+'training_progress'\n",
    "exporter_path = HOMEFOLDER+'models/research/object_detection/export_tflite_graph_tf2.py'\n",
    "output_directory = FINALOUTPUTFOLDER\n",
    "\n",
    "!python $exporter_path \\\n",
    "    --trained_checkpoint_dir $last_model_path \\\n",
    "    --output_directory $output_directory \\\n",
    "    --pipeline_config_path $pipeline_file\n",
    "\n",
    "# Convert to .tflite Flatbuffer\n",
    "import tensorflow as tf\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(FINALOUTPUTFOLDER+'/saved_model')\n",
    "tflite_model = converter.convert()\n",
    "model_path_32bit = FINALOUTPUTFOLDER+'/limelight_neural_detector_32bit.tflite'\n",
    "with open(model_path_32bit, 'wb') as f:\n",
    "  f.write(tflite_model)\n",
    "\n",
    "!cp {HOMEFOLDER}limelight_neural_detector_labels.txt {FINALOUTPUTFOLDER}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1893265",
   "metadata": {
    "id": "VTyqlXFTJ0Uv",
    "papermill": {
     "duration": 0.053507,
     "end_time": "2025-04-01T20:17:06.490780",
     "exception": false,
     "start_time": "2025-04-01T20:17:06.437273",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 6. Quantize model\n",
    "The \"TFLiteConverter\" module will perform [post-training quantization](https://www.tensorflow.org/lite/performance/post_training_quantization) on the model. To quantize the model, we need to provide a set of example images. We will extract 100 images from the training tfrecord and place said images into the \"extracted_samples\" folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53bf1a9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T20:17:06.614414Z",
     "iopub.status.busy": "2025-04-01T20:17:06.614101Z",
     "iopub.status.idle": "2025-04-01T20:17:25.980782Z",
     "shell.execute_reply": "2025-04-01T20:17:25.979933Z"
    },
    "id": "XSNZtfj_k3NP",
    "papermill": {
     "duration": 19.437104,
     "end_time": "2025-04-01T20:17:25.982141",
     "exception": false,
     "start_time": "2025-04-01T20:17:06.545037",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 100 images to /kaggle/working/extracted_samples\n",
      "pulling samples from /kaggle/working/extracted_samples\n",
      "samples: 100\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import io\n",
    "from PIL import Image\n",
    "\n",
    "def extract_images_from_tfrecord(tfrecord_path, output_folder, num_samples=100):\n",
    "    # Make sure the output directory exists\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Initialize a counter for the number of images saved\n",
    "    saved_images = 0\n",
    "\n",
    "    # Read the TFRecord file\n",
    "    raw_dataset = tf.data.TFRecordDataset(tfrecord_path)\n",
    "    for raw_record in raw_dataset.take(num_samples):\n",
    "        example = tf.train.Example()\n",
    "        example.ParseFromString(raw_record.numpy())\n",
    "\n",
    "        # Extract the image data (change 'image/encoded' if necessary)\n",
    "        image_data = example.features.feature['image/encoded'].bytes_list.value[0]\n",
    "\n",
    "        # Decode the image data and save as a file\n",
    "        image = Image.open(io.BytesIO(image_data))\n",
    "        image.save(os.path.join(output_folder, f'image_{saved_images}.png'))\n",
    "\n",
    "        saved_images += 1\n",
    "        if saved_images >= num_samples:\n",
    "            break\n",
    "\n",
    "    print(f\"Extracted {saved_images} images to {output_folder}\")\n",
    "\n",
    "# Set the path to your TFRecord file and the output directory\n",
    "tfrecord_path = train_record_fname\n",
    "extracted_sample_folder = HOMEFOLDER+'extracted_samples'\n",
    "\n",
    "#remove sample folder if it exists\n",
    "if os.path.exists(extracted_sample_folder) and os.path.isdir(extracted_sample_folder):\n",
    "  shutil.rmtree(extracted_sample_folder)\n",
    "\n",
    "# Extract images\n",
    "extract_images_from_tfrecord(tfrecord_path, extracted_sample_folder)\n",
    "\n",
    "\n",
    "# Get list of all images in train directory\n",
    "from google.cloud import storage\n",
    "import glob\n",
    "\n",
    "quant_image_list=[]\n",
    "if(MLENVIRONMENT==\"KAGGLE\"):\n",
    "\n",
    "    jpg_file_list = glob.glob(extracted_sample_folder + '/*.jpg')\n",
    "    jpeg_file_list = glob.glob(extracted_sample_folder + '/*.jpeg')\n",
    "    JPG_file_list = glob.glob(extracted_sample_folder + '/*.JPG')\n",
    "    png_file_list = glob.glob(extracted_sample_folder + '/*.png')\n",
    "    bmp_file_list = glob.glob(extracted_sample_folder + '/*.bmp')\n",
    "    quant_image_list = jpg_file_list + JPG_file_list + png_file_list + bmp_file_list\n",
    "\n",
    "print(\"pulling samples from \" + extracted_sample_folder)\n",
    "print(\"samples: \" + str(len(quant_image_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5276ade1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T20:17:26.092968Z",
     "iopub.status.busy": "2025-04-01T20:17:26.092438Z",
     "iopub.status.idle": "2025-04-01T20:17:26.114416Z",
     "shell.execute_reply": "2025-04-01T20:17:26.113663Z"
    },
    "id": "ORzx0XRErSLV",
    "papermill": {
     "duration": 0.077779,
     "end_time": "2025-04-01T20:17:26.115574",
     "exception": false,
     "start_time": "2025-04-01T20:17:26.037795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# A generator that provides a representative dataset\n",
    "# Code modified from https://colab.research.google.com/github/google-coral/tutorials/blob/master/retrain_classification_ptq_tf2.ipynb\n",
    "\n",
    "# First, get input details for model so we know how to preprocess images\n",
    "interpreter = tf.lite.Interpreter(model_path=model_path_32bit)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "height = input_details[0]['shape'][1]\n",
    "width = input_details[0]['shape'][2]\n",
    "\n",
    "import random\n",
    "\n",
    "def representative_data_gen():\n",
    "  dataset_list = quant_image_list\n",
    "  quant_num = 300\n",
    "  for i in range(quant_num):\n",
    "    pick_me = random.choice(dataset_list)\n",
    "    print(pick_me)\n",
    "    image = tf.io.read_file(pick_me)\n",
    "\n",
    "    if pick_me.endswith('.jpg') or pick_me.endswith('.JPG') or pick_me.endswith('.jpeg'):\n",
    "      image = tf.io.decode_jpeg(image, channels=3)\n",
    "    elif pick_me.endswith('.png'):\n",
    "      image = tf.io.decode_png(image, channels=3)\n",
    "    elif pick_me.endswith('.bmp'):\n",
    "      image = tf.io.decode_bmp(image, channels=3)\n",
    "\n",
    "    image = tf.image.resize(image, [width, height])  # TO DO: Replace 300s with an automatic way of reading network input size\n",
    "    image = tf.cast(image / 255., tf.float32)\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    yield [image]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4516590",
   "metadata": {
    "id": "wqtu98mzebEj",
    "papermill": {
     "duration": 0.05364,
     "end_time": "2025-04-01T20:17:26.224743",
     "exception": false,
     "start_time": "2025-04-01T20:17:26.171103",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Finally, we'll initialize the TFLiteConverter module, point it at the TFLite graph we generated in Step 6, and provide it with the representative dataset generator function we created in the previous code block. We'll configure the converter to quantize the model's weight values to INT8 format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8cb65b6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T20:17:26.333698Z",
     "iopub.status.busy": "2025-04-01T20:17:26.333442Z",
     "iopub.status.idle": "2025-04-01T20:18:31.420496Z",
     "shell.execute_reply": "2025-04-01T20:18:31.419642Z"
    },
    "id": "Ox0bGDWds_Ce",
    "papermill": {
     "duration": 65.142912,
     "end_time": "2025-04-01T20:18:31.421936",
     "exception": false,
     "start_time": "2025-04-01T20:17:26.279024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialized converter\n",
      "begin conversion\n",
      "/kaggle/working/extracted_samples/image_34.png\n",
      "/kaggle/working/extracted_samples/image_0.png\n",
      "/kaggle/working/extracted_samples/image_10.png\n",
      "/kaggle/working/extracted_samples/image_65.png\n",
      "/kaggle/working/extracted_samples/image_55.png\n",
      "/kaggle/working/extracted_samples/image_66.png\n",
      "/kaggle/working/extracted_samples/image_34.png\n",
      "/kaggle/working/extracted_samples/image_71.png\n",
      "/kaggle/working/extracted_samples/image_34.png\n",
      "/kaggle/working/extracted_samples/image_75.png\n",
      "/kaggle/working/extracted_samples/image_40.png\n",
      "/kaggle/working/extracted_samples/image_76.png\n",
      "/kaggle/working/extracted_samples/image_75.png\n",
      "/kaggle/working/extracted_samples/image_88.png\n",
      "/kaggle/working/extracted_samples/image_68.png\n",
      "/kaggle/working/extracted_samples/image_63.png\n",
      "/kaggle/working/extracted_samples/image_37.png\n",
      "/kaggle/working/extracted_samples/image_2.png\n",
      "/kaggle/working/extracted_samples/image_16.png\n",
      "/kaggle/working/extracted_samples/image_47.png\n",
      "/kaggle/working/extracted_samples/image_13.png\n",
      "/kaggle/working/extracted_samples/image_15.png\n",
      "/kaggle/working/extracted_samples/image_32.png\n",
      "/kaggle/working/extracted_samples/image_34.png\n",
      "/kaggle/working/extracted_samples/image_84.png\n",
      "/kaggle/working/extracted_samples/image_72.png\n",
      "/kaggle/working/extracted_samples/image_30.png\n",
      "/kaggle/working/extracted_samples/image_1.png\n",
      "/kaggle/working/extracted_samples/image_86.png\n",
      "/kaggle/working/extracted_samples/image_58.png\n",
      "/kaggle/working/extracted_samples/image_9.png\n",
      "/kaggle/working/extracted_samples/image_51.png\n",
      "/kaggle/working/extracted_samples/image_44.png\n",
      "/kaggle/working/extracted_samples/image_69.png\n",
      "/kaggle/working/extracted_samples/image_36.png\n",
      "/kaggle/working/extracted_samples/image_47.png\n",
      "/kaggle/working/extracted_samples/image_34.png\n",
      "/kaggle/working/extracted_samples/image_80.png\n",
      "/kaggle/working/extracted_samples/image_90.png\n",
      "/kaggle/working/extracted_samples/image_24.png\n",
      "/kaggle/working/extracted_samples/image_19.png\n",
      "/kaggle/working/extracted_samples/image_87.png\n",
      "/kaggle/working/extracted_samples/image_36.png\n",
      "/kaggle/working/extracted_samples/image_33.png\n",
      "/kaggle/working/extracted_samples/image_89.png\n",
      "/kaggle/working/extracted_samples/image_46.png\n",
      "/kaggle/working/extracted_samples/image_17.png\n",
      "/kaggle/working/extracted_samples/image_47.png\n",
      "/kaggle/working/extracted_samples/image_60.png\n",
      "/kaggle/working/extracted_samples/image_33.png\n",
      "/kaggle/working/extracted_samples/image_21.png\n",
      "/kaggle/working/extracted_samples/image_59.png\n",
      "/kaggle/working/extracted_samples/image_37.png\n",
      "/kaggle/working/extracted_samples/image_69.png\n",
      "/kaggle/working/extracted_samples/image_29.png\n",
      "/kaggle/working/extracted_samples/image_26.png\n",
      "/kaggle/working/extracted_samples/image_44.png\n",
      "/kaggle/working/extracted_samples/image_90.png\n",
      "/kaggle/working/extracted_samples/image_51.png\n",
      "/kaggle/working/extracted_samples/image_2.png\n",
      "/kaggle/working/extracted_samples/image_99.png\n",
      "/kaggle/working/extracted_samples/image_18.png\n",
      "/kaggle/working/extracted_samples/image_18.png\n",
      "/kaggle/working/extracted_samples/image_26.png\n",
      "/kaggle/working/extracted_samples/image_18.png\n",
      "/kaggle/working/extracted_samples/image_96.png\n",
      "/kaggle/working/extracted_samples/image_16.png\n",
      "/kaggle/working/extracted_samples/image_16.png\n",
      "/kaggle/working/extracted_samples/image_29.png\n",
      "/kaggle/working/extracted_samples/image_96.png\n",
      "/kaggle/working/extracted_samples/image_6.png\n",
      "/kaggle/working/extracted_samples/image_99.png\n",
      "/kaggle/working/extracted_samples/image_59.png\n",
      "/kaggle/working/extracted_samples/image_96.png\n",
      "/kaggle/working/extracted_samples/image_9.png\n",
      "/kaggle/working/extracted_samples/image_68.png\n",
      "/kaggle/working/extracted_samples/image_48.png\n",
      "/kaggle/working/extracted_samples/image_33.png\n",
      "/kaggle/working/extracted_samples/image_48.png\n",
      "/kaggle/working/extracted_samples/image_60.png\n",
      "/kaggle/working/extracted_samples/image_69.png\n",
      "/kaggle/working/extracted_samples/image_76.png\n",
      "/kaggle/working/extracted_samples/image_84.png\n",
      "/kaggle/working/extracted_samples/image_52.png\n",
      "/kaggle/working/extracted_samples/image_94.png\n",
      "/kaggle/working/extracted_samples/image_4.png\n",
      "/kaggle/working/extracted_samples/image_7.png\n",
      "/kaggle/working/extracted_samples/image_64.png\n",
      "/kaggle/working/extracted_samples/image_14.png\n",
      "/kaggle/working/extracted_samples/image_11.png\n",
      "/kaggle/working/extracted_samples/image_56.png\n",
      "/kaggle/working/extracted_samples/image_97.png\n",
      "/kaggle/working/extracted_samples/image_9.png\n",
      "/kaggle/working/extracted_samples/image_58.png\n",
      "/kaggle/working/extracted_samples/image_40.png\n",
      "/kaggle/working/extracted_samples/image_99.png\n",
      "/kaggle/working/extracted_samples/image_17.png\n",
      "/kaggle/working/extracted_samples/image_1.png\n",
      "/kaggle/working/extracted_samples/image_57.png\n",
      "/kaggle/working/extracted_samples/image_2.png\n",
      "/kaggle/working/extracted_samples/image_99.png\n",
      "/kaggle/working/extracted_samples/image_27.png\n",
      "/kaggle/working/extracted_samples/image_67.png\n",
      "/kaggle/working/extracted_samples/image_21.png\n",
      "/kaggle/working/extracted_samples/image_82.png\n",
      "/kaggle/working/extracted_samples/image_73.png\n",
      "/kaggle/working/extracted_samples/image_93.png\n",
      "/kaggle/working/extracted_samples/image_86.png\n",
      "/kaggle/working/extracted_samples/image_75.png\n",
      "/kaggle/working/extracted_samples/image_66.png\n",
      "/kaggle/working/extracted_samples/image_34.png\n",
      "/kaggle/working/extracted_samples/image_7.png\n",
      "/kaggle/working/extracted_samples/image_49.png\n",
      "/kaggle/working/extracted_samples/image_30.png\n",
      "/kaggle/working/extracted_samples/image_37.png\n",
      "/kaggle/working/extracted_samples/image_99.png\n",
      "/kaggle/working/extracted_samples/image_3.png\n",
      "/kaggle/working/extracted_samples/image_64.png\n",
      "/kaggle/working/extracted_samples/image_58.png\n",
      "/kaggle/working/extracted_samples/image_2.png\n",
      "/kaggle/working/extracted_samples/image_48.png\n",
      "/kaggle/working/extracted_samples/image_50.png\n",
      "/kaggle/working/extracted_samples/image_5.png\n",
      "/kaggle/working/extracted_samples/image_78.png\n",
      "/kaggle/working/extracted_samples/image_91.png\n",
      "/kaggle/working/extracted_samples/image_19.png\n",
      "/kaggle/working/extracted_samples/image_67.png\n",
      "/kaggle/working/extracted_samples/image_71.png\n",
      "/kaggle/working/extracted_samples/image_38.png\n",
      "/kaggle/working/extracted_samples/image_85.png\n",
      "/kaggle/working/extracted_samples/image_69.png\n",
      "/kaggle/working/extracted_samples/image_87.png\n",
      "/kaggle/working/extracted_samples/image_56.png\n",
      "/kaggle/working/extracted_samples/image_94.png\n",
      "/kaggle/working/extracted_samples/image_86.png\n",
      "/kaggle/working/extracted_samples/image_87.png\n",
      "/kaggle/working/extracted_samples/image_87.png\n",
      "/kaggle/working/extracted_samples/image_59.png\n",
      "/kaggle/working/extracted_samples/image_19.png\n",
      "/kaggle/working/extracted_samples/image_98.png\n",
      "/kaggle/working/extracted_samples/image_22.png\n",
      "/kaggle/working/extracted_samples/image_53.png\n",
      "/kaggle/working/extracted_samples/image_11.png\n",
      "/kaggle/working/extracted_samples/image_13.png\n",
      "/kaggle/working/extracted_samples/image_27.png\n",
      "/kaggle/working/extracted_samples/image_0.png\n",
      "/kaggle/working/extracted_samples/image_78.png\n",
      "/kaggle/working/extracted_samples/image_20.png\n",
      "/kaggle/working/extracted_samples/image_29.png\n",
      "/kaggle/working/extracted_samples/image_66.png\n",
      "/kaggle/working/extracted_samples/image_76.png\n",
      "/kaggle/working/extracted_samples/image_30.png\n",
      "/kaggle/working/extracted_samples/image_82.png\n",
      "/kaggle/working/extracted_samples/image_55.png\n",
      "/kaggle/working/extracted_samples/image_67.png\n",
      "/kaggle/working/extracted_samples/image_9.png\n",
      "/kaggle/working/extracted_samples/image_83.png\n",
      "/kaggle/working/extracted_samples/image_65.png\n",
      "/kaggle/working/extracted_samples/image_31.png\n",
      "/kaggle/working/extracted_samples/image_67.png\n",
      "/kaggle/working/extracted_samples/image_29.png\n",
      "/kaggle/working/extracted_samples/image_11.png\n",
      "/kaggle/working/extracted_samples/image_7.png\n",
      "/kaggle/working/extracted_samples/image_71.png\n",
      "/kaggle/working/extracted_samples/image_8.png\n",
      "/kaggle/working/extracted_samples/image_79.png\n",
      "/kaggle/working/extracted_samples/image_31.png\n",
      "/kaggle/working/extracted_samples/image_72.png\n",
      "/kaggle/working/extracted_samples/image_12.png\n",
      "/kaggle/working/extracted_samples/image_56.png\n",
      "/kaggle/working/extracted_samples/image_27.png\n",
      "/kaggle/working/extracted_samples/image_36.png\n",
      "/kaggle/working/extracted_samples/image_85.png\n",
      "/kaggle/working/extracted_samples/image_93.png\n",
      "/kaggle/working/extracted_samples/image_63.png\n",
      "/kaggle/working/extracted_samples/image_57.png\n",
      "/kaggle/working/extracted_samples/image_96.png\n",
      "/kaggle/working/extracted_samples/image_40.png\n",
      "/kaggle/working/extracted_samples/image_47.png\n",
      "/kaggle/working/extracted_samples/image_78.png\n",
      "/kaggle/working/extracted_samples/image_67.png\n",
      "/kaggle/working/extracted_samples/image_93.png\n",
      "/kaggle/working/extracted_samples/image_81.png\n",
      "/kaggle/working/extracted_samples/image_32.png\n",
      "/kaggle/working/extracted_samples/image_92.png\n",
      "/kaggle/working/extracted_samples/image_75.png\n",
      "/kaggle/working/extracted_samples/image_43.png\n",
      "/kaggle/working/extracted_samples/image_76.png\n",
      "/kaggle/working/extracted_samples/image_38.png\n",
      "/kaggle/working/extracted_samples/image_42.png\n",
      "/kaggle/working/extracted_samples/image_69.png\n",
      "/kaggle/working/extracted_samples/image_88.png\n",
      "/kaggle/working/extracted_samples/image_4.png\n",
      "/kaggle/working/extracted_samples/image_13.png\n",
      "/kaggle/working/extracted_samples/image_13.png\n",
      "/kaggle/working/extracted_samples/image_84.png\n",
      "/kaggle/working/extracted_samples/image_50.png\n",
      "/kaggle/working/extracted_samples/image_80.png\n",
      "/kaggle/working/extracted_samples/image_16.png\n",
      "/kaggle/working/extracted_samples/image_21.png\n",
      "/kaggle/working/extracted_samples/image_18.png\n",
      "/kaggle/working/extracted_samples/image_71.png\n",
      "/kaggle/working/extracted_samples/image_83.png\n",
      "/kaggle/working/extracted_samples/image_41.png\n",
      "/kaggle/working/extracted_samples/image_26.png\n",
      "/kaggle/working/extracted_samples/image_91.png\n",
      "/kaggle/working/extracted_samples/image_2.png\n",
      "/kaggle/working/extracted_samples/image_34.png\n",
      "/kaggle/working/extracted_samples/image_50.png\n",
      "/kaggle/working/extracted_samples/image_78.png\n",
      "/kaggle/working/extracted_samples/image_58.png\n",
      "/kaggle/working/extracted_samples/image_55.png\n",
      "/kaggle/working/extracted_samples/image_9.png\n",
      "/kaggle/working/extracted_samples/image_7.png\n",
      "/kaggle/working/extracted_samples/image_15.png\n",
      "/kaggle/working/extracted_samples/image_88.png\n",
      "/kaggle/working/extracted_samples/image_66.png\n",
      "/kaggle/working/extracted_samples/image_68.png\n",
      "/kaggle/working/extracted_samples/image_26.png\n",
      "/kaggle/working/extracted_samples/image_82.png\n",
      "/kaggle/working/extracted_samples/image_6.png\n",
      "/kaggle/working/extracted_samples/image_53.png\n",
      "/kaggle/working/extracted_samples/image_91.png\n",
      "/kaggle/working/extracted_samples/image_25.png\n",
      "/kaggle/working/extracted_samples/image_60.png\n",
      "/kaggle/working/extracted_samples/image_33.png\n",
      "/kaggle/working/extracted_samples/image_49.png\n",
      "/kaggle/working/extracted_samples/image_45.png\n",
      "/kaggle/working/extracted_samples/image_45.png\n",
      "/kaggle/working/extracted_samples/image_33.png\n",
      "/kaggle/working/extracted_samples/image_53.png\n",
      "/kaggle/working/extracted_samples/image_19.png\n",
      "/kaggle/working/extracted_samples/image_25.png\n",
      "/kaggle/working/extracted_samples/image_9.png\n",
      "/kaggle/working/extracted_samples/image_98.png\n",
      "/kaggle/working/extracted_samples/image_72.png\n",
      "/kaggle/working/extracted_samples/image_91.png\n",
      "/kaggle/working/extracted_samples/image_37.png\n",
      "/kaggle/working/extracted_samples/image_6.png\n",
      "/kaggle/working/extracted_samples/image_99.png\n",
      "/kaggle/working/extracted_samples/image_44.png\n",
      "/kaggle/working/extracted_samples/image_52.png\n",
      "/kaggle/working/extracted_samples/image_57.png\n",
      "/kaggle/working/extracted_samples/image_53.png\n",
      "/kaggle/working/extracted_samples/image_66.png\n",
      "/kaggle/working/extracted_samples/image_54.png\n",
      "/kaggle/working/extracted_samples/image_85.png\n",
      "/kaggle/working/extracted_samples/image_32.png\n",
      "/kaggle/working/extracted_samples/image_8.png\n",
      "/kaggle/working/extracted_samples/image_74.png\n",
      "/kaggle/working/extracted_samples/image_3.png\n",
      "/kaggle/working/extracted_samples/image_3.png\n",
      "/kaggle/working/extracted_samples/image_49.png\n",
      "/kaggle/working/extracted_samples/image_37.png\n",
      "/kaggle/working/extracted_samples/image_72.png\n",
      "/kaggle/working/extracted_samples/image_53.png\n",
      "/kaggle/working/extracted_samples/image_32.png\n",
      "/kaggle/working/extracted_samples/image_74.png\n",
      "/kaggle/working/extracted_samples/image_38.png\n",
      "/kaggle/working/extracted_samples/image_80.png\n",
      "/kaggle/working/extracted_samples/image_79.png\n",
      "/kaggle/working/extracted_samples/image_29.png\n",
      "/kaggle/working/extracted_samples/image_81.png\n",
      "/kaggle/working/extracted_samples/image_42.png\n",
      "/kaggle/working/extracted_samples/image_3.png\n",
      "/kaggle/working/extracted_samples/image_76.png\n",
      "/kaggle/working/extracted_samples/image_8.png\n",
      "/kaggle/working/extracted_samples/image_91.png\n",
      "/kaggle/working/extracted_samples/image_95.png\n",
      "/kaggle/working/extracted_samples/image_11.png\n",
      "/kaggle/working/extracted_samples/image_36.png\n",
      "/kaggle/working/extracted_samples/image_20.png\n",
      "/kaggle/working/extracted_samples/image_27.png\n",
      "/kaggle/working/extracted_samples/image_3.png\n",
      "/kaggle/working/extracted_samples/image_9.png\n",
      "/kaggle/working/extracted_samples/image_61.png\n",
      "/kaggle/working/extracted_samples/image_12.png\n",
      "/kaggle/working/extracted_samples/image_56.png\n",
      "/kaggle/working/extracted_samples/image_73.png\n",
      "/kaggle/working/extracted_samples/image_80.png\n",
      "/kaggle/working/extracted_samples/image_82.png\n",
      "/kaggle/working/extracted_samples/image_52.png\n",
      "/kaggle/working/extracted_samples/image_65.png\n",
      "/kaggle/working/extracted_samples/image_16.png\n",
      "/kaggle/working/extracted_samples/image_34.png\n",
      "/kaggle/working/extracted_samples/image_60.png\n",
      "/kaggle/working/extracted_samples/image_35.png\n",
      "/kaggle/working/extracted_samples/image_57.png\n",
      "/kaggle/working/extracted_samples/image_13.png\n",
      "/kaggle/working/extracted_samples/image_81.png\n",
      "/kaggle/working/extracted_samples/image_28.png\n",
      "/kaggle/working/extracted_samples/image_91.png\n",
      "/kaggle/working/extracted_samples/image_89.png\n",
      "/kaggle/working/extracted_samples/image_79.png\n",
      "/kaggle/working/extracted_samples/image_69.png\n",
      "/kaggle/working/extracted_samples/image_9.png\n",
      "/kaggle/working/extracted_samples/image_26.png\n",
      "/kaggle/working/extracted_samples/image_42.png\n",
      "/kaggle/working/extracted_samples/image_93.png\n",
      "/kaggle/working/extracted_samples/image_52.png\n",
      "conversion complete\n"
     ]
    }
   ],
   "source": [
    "# Initialize converter module\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(FINALOUTPUTFOLDER+'/saved_model')\n",
    "print(\"initialized converter\")\n",
    "# This enables quantization\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# This sets the representative dataset for quantization\n",
    "converter.representative_dataset = representative_data_gen\n",
    "# This ensures that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# For full integer quantization, though supported types defaults to int8 only, we explicitly declare it for clarity.\n",
    "converter.target_spec.supported_types = [tf.int8]\n",
    "# These set the input tensors to uint8 and output tensors to float32\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.float32\n",
    "print(\"begin conversion\")\n",
    "tflite_model = converter.convert()\n",
    "print(\"conversion complete\")\n",
    "\n",
    "with open(FINALOUTPUTFOLDER+'/limelight_neural_detector_8bit.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c169c607",
   "metadata": {
    "id": "XFsuasvxFHo8",
    "papermill": {
     "duration": 0.06024,
     "end_time": "2025-04-01T20:18:31.544176",
     "exception": false,
     "start_time": "2025-04-01T20:18:31.483936",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 7. Compile Model for Limelight & Download\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6cee71",
   "metadata": {
    "id": "peawOI_z0DHt",
    "papermill": {
     "duration": 0.059914,
     "end_time": "2025-04-01T20:18:31.665455",
     "exception": false,
     "start_time": "2025-04-01T20:18:31.605541",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Install Coral Compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1f080d17",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T20:18:31.786915Z",
     "iopub.status.busy": "2025-04-01T20:18:31.786631Z",
     "iopub.status.idle": "2025-04-01T20:18:44.948995Z",
     "shell.execute_reply": "2025-04-01T20:18:44.948081Z"
    },
    "id": "mUd_SNC0JSq0",
    "papermill": {
     "duration": 13.225008,
     "end_time": "2025-04-01T20:18:44.950520",
     "exception": false,
     "start_time": "2025-04-01T20:18:31.725512",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\r\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\r\n",
      "100  1022  100  1022    0     0  12552      0 --:--:-- --:--:-- --:--:-- 12617\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "Get:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\r\n",
      "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\r\n",
      "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [69.9 kB]\r\n",
      "Get:4 https://packages.cloud.google.com/apt coral-edgetpu-stable InRelease [1,423 B]\r\n",
      "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\r\n",
      "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,381 kB]\r\n",
      "Get:7 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\r\n",
      "Get:8 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\r\n",
      "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\r\n",
      "Get:10 https://packages.cloud.google.com/apt coral-edgetpu-stable/main all Packages [1,865 B]\r\n",
      "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,793 kB]\r\n",
      "Get:12 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\r\n",
      "Get:13 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 Packages [6,888 B]\r\n",
      "Get:14 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease [24.3 kB]\r\n",
      "Get:15 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\r\n",
      "Get:16 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [3,972 kB]\r\n",
      "Hit:17 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\r\n",
      "Get:18 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [33.6 kB]\r\n",
      "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,126 kB]\r\n",
      "Get:20 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,686 kB]\r\n",
      "Get:21 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy/main amd64 Packages [46.8 kB]\r\n",
      "Get:22 http://security.ubuntu.com/ubuntu jammy-security/multiverse amd64 Packages [47.7 kB]\r\n",
      "Get:23 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,773 kB]\r\n",
      "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,081 kB]\r\n",
      "Get:25 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,241 kB]\r\n",
      "Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,540 kB]\r\n",
      "Get:27 http://archive.ubuntu.com/ubuntu jammy-updates/multiverse amd64 Packages [55.7 kB]\r\n",
      "Get:28 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\r\n",
      "Get:29 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [82.7 kB]\r\n",
      "Fetched 30.4 MB in 3s (11.2 MB/s)\r\n",
      "\r\n",
      "W: https://packages.cloud.google.com/apt/dists/coral-edgetpu-stable/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\r\n",
      "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "The following NEW packages will be installed:\r\n",
      "  edgetpu-compiler\r\n",
      "0 upgraded, 1 newly installed, 0 to remove and 175 not upgraded.\r\n",
      "Need to get 7,913 kB of archives.\r\n",
      "After this operation, 31.2 MB of additional disk space will be used.\r\n",
      "Get:1 https://packages.cloud.google.com/apt coral-edgetpu-stable/main amd64 edgetpu-compiler amd64 16.0 [7,913 kB]\r\n",
      "Fetched 7,913 kB in 1s (11.4 MB/s)\r\n",
      "debconf: unable to initialize frontend: Dialog\r\n",
      "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 1.)\r\n",
      "debconf: falling back to frontend: Readline\r\n",
      "Selecting previously unselected package edgetpu-compiler.\r\n",
      "(Reading database ... 127400 files and directories currently installed.)\r\n",
      "Preparing to unpack .../edgetpu-compiler_16.0_amd64.deb ...\r\n",
      "Unpacking edgetpu-compiler (16.0) ...\r\n",
      "Setting up edgetpu-compiler (16.0) ...\r\n",
      "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\r\n",
      "\r\n",
      "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "! curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n",
    "! echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | sudo tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
    "! sudo apt-get update\n",
    "! sudo apt-get install edgetpu-compiler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550edc54",
   "metadata": {
    "id": "usfmdtSiJuuC",
    "papermill": {
     "duration": 0.06502,
     "end_time": "2025-04-01T20:18:45.082213",
     "exception": false,
     "start_time": "2025-04-01T20:18:45.017193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Compile the previously-generated 8-bit model for Google Coral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1f800ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T20:18:45.212163Z",
     "iopub.status.busy": "2025-04-01T20:18:45.211811Z",
     "iopub.status.idle": "2025-04-01T20:18:47.430717Z",
     "shell.execute_reply": "2025-04-01T20:18:47.429831Z"
    },
    "id": "mULCY0nb0ahH",
    "papermill": {
     "duration": 2.285838,
     "end_time": "2025-04-01T20:18:47.432228",
     "exception": false,
     "start_time": "2025-04-01T20:18:45.146390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/output\r\n",
      "Edge TPU Compiler version 16.0.384591198\r\n",
      "Started a compilation timeout timer of 180 seconds.\r\n",
      "\r\n",
      "Model compiled successfully in 1955 ms.\r\n",
      "\r\n",
      "Input model: limelight_neural_detector_8bit.tflite\r\n",
      "Input size: 6.42MiB\r\n",
      "Output model: limelight_neural_detector_8bit_edgetpu.tflite\r\n",
      "Output size: 6.75MiB\r\n",
      "On-chip memory used for caching model parameters: 6.52MiB\r\n",
      "On-chip memory remaining for caching model parameters: 1.08MiB\r\n",
      "Off-chip memory used for streaming uncached model parameters: 0.00B\r\n",
      "Number of Edge TPU subgraphs: 1\r\n",
      "Total number of operations: 102\r\n",
      "Operation log: limelight_neural_detector_8bit_edgetpu.log\r\n",
      "\r\n",
      "Model successfully compiled but not all operations are supported by the Edge TPU. A percentage of the model will instead run on the CPU, which is slower. If possible, consider updating your model to use only operations supported by the Edge TPU. For details, visit g.co/coral/model-reqs.\r\n",
      "Number of operations that will run on Edge TPU: 99\r\n",
      "Number of operations that will run on CPU: 3\r\n",
      "See the operation log file for individual operation details.\r\n",
      "Compilation child process completed within timeout period.\r\n",
      "Compilation succeeded! \r\n",
      "/kaggle/output\r\n"
     ]
    }
   ],
   "source": [
    "!cd {FINALOUTPUTFOLDER} && pwd && edgetpu_compiler limelight_neural_detector_8bit.tflite && pwd && mv limelight_neural_detector_8bit_edgetpu.tflite limelight_neural_detector_coral.tflite && rm limelight_neural_detector_8bit_edgetpu.log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7978c7",
   "metadata": {
    "id": "oqGy2FgzKomN",
    "papermill": {
     "duration": 0.067341,
     "end_time": "2025-04-01T20:18:47.567650",
     "exception": false,
     "start_time": "2025-04-01T20:18:47.500309",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Zip models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0695adaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-01T20:18:47.700053Z",
     "iopub.status.busy": "2025-04-01T20:18:47.699673Z",
     "iopub.status.idle": "2025-04-01T20:18:51.130138Z",
     "shell.execute_reply": "2025-04-01T20:18:51.128995Z"
    },
    "id": "8nCdUouYJjQM",
    "papermill": {
     "duration": 3.497377,
     "end_time": "2025-04-01T20:18:51.131806",
     "exception": false,
     "start_time": "2025-04-01T20:18:47.634429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove '/kaggle/working/limelight_detectors.zip': No such file or directory\r\n",
      "  adding: kaggle/output/ (stored 0%)\r\n",
      "  adding: kaggle/output/limelight_neural_detector_32bit.tflite (deflated 7%)\r\n",
      "  adding: kaggle/output/limelight_neural_detector_labels.txt (deflated 30%)\r\n",
      "  adding: kaggle/output/limelight_neural_detector_8bit.tflite (deflated 17%)\r\n",
      "  adding: kaggle/output/limelight_neural_detector_coral.tflite (deflated 21%)\r\n",
      "  adding: kaggle/output/saved_model/ (stored 0%)\r\n",
      "  adding: kaggle/output/saved_model/assets/ (stored 0%)\r\n",
      "  adding: kaggle/output/saved_model/saved_model.pb (deflated 91%)\r\n",
      "  adding: kaggle/output/saved_model/variables/ (stored 0%)\r\n",
      "  adding: kaggle/output/saved_model/variables/variables.data-00000-of-00001 (deflated 8%)\r\n",
      "  adding: kaggle/output/saved_model/variables/variables.index (deflated 77%)\r\n",
      "  adding: kaggle/output/saved_model/fingerprint.pb (stored 0%)\r\n"
     ]
    }
   ],
   "source": [
    "!rm {HOMEFOLDER}limelight_detectors.zip\n",
    "!zip -r {HOMEFOLDER}limelight_detectors.zip /kaggle/output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d04e7f",
   "metadata": {
    "id": "vHgbpkQue-ZR",
    "papermill": {
     "duration": 0.068061,
     "end_time": "2025-04-01T20:18:51.267355",
     "exception": false,
     "start_time": "2025-04-01T20:18:51.199294",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Download"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "05N8FeXHcQp3",
    "xmROIG9zaS9G",
    "eGEUZYAMEZ6f",
    "-19zML6oEO7l",
    "kPg8oMnQDYKl",
    "VTyqlXFTJ0Uv",
    "XFsuasvxFHo8"
   ],
   "gpuClass": "premium",
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4784.549404,
   "end_time": "2025-04-01T20:18:55.003433",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-01T18:59:10.454029",
   "version": "2.6.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "dac6b1a68a930bf8a24417228a96ab80b19f2aa97bc2d428affc356154b4740f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
